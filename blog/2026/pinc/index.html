<!DOCTYPE html>
<html>

  <head>
    <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta http-equiv="X-UA-Compatible" content="IE=edge">

<title>Institute for Machine Learning @ JKU | Physics-Informed Neural Compression of High-Dimensional Plasma Data</title>
<meta name="description" content="Research blog of the Institute for Machine Learning @ JKU.
">

<!-- Open Graph -->


<!-- Bootstrap & MDB -->
<link href="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/css/bootstrap.min.css" rel="stylesheet" integrity="sha512-MoRNloxbStBcD8z3M/2BmnT+rg4IsMxPkXaGh2zD6LGNNFE80W3onsAhRcMAMrSoyWL9xD7Ert0men7vR8LUZg==" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.19.1/css/mdb.min.css" integrity="sha512-RO38pBRxYH3SoOprtPTD86JFOclM51/XTIdEPh5j8sj4tp8jmQIx26twG52UaLi//hQldfrh7e51WzP9wuP32Q==" crossorigin="anonymous" />

<!-- Fonts & Icons -->
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css"  integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.9.0/css/academicons.min.css" integrity="sha512-W4yqoT1+8NLkinBLBZko+dFB2ZbHsYLDdr50VElllRcNt2Q4/GSs6u71UHKxB7S6JEMCp5Ve4xjh3eGQl/HRvg==" crossorigin="anonymous">
<link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">

<!-- Code Syntax Highlighting -->
<link rel="stylesheet" href="https://gitcdn.link/repo/jwarby/jekyll-pygments-themes/master/github.css" />

<!-- Styles -->
<link rel="shortcut icon" href="/assets/img/favicon.ico">
<link rel="stylesheet" href="/assets/css/main.css">

<link rel="canonical" href="/blog/2026/pinc/">

<!-- Theming-->



  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-KC0VGMCD6W"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag() { dataLayer.push(arguments); }
    gtag('js', new Date());

    gtag('config', 'G-KC0VGMCD6W');
  </script>


    
<!-- MathJax -->
<script type="text/javascript">
  window.MathJax = {
    tex: {
      tags: 'ams'
    }
  };
</script>
<script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.1.2/es5/tex-mml-chtml.js"></script>
<script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>


  </head>

  <body class="fixed-top-nav ">

    <!-- Header -->

    <header>

    <!-- Nav Bar -->
    <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top">
      <a class="navbar-brand title font-weight-lighter" href="ml-jku.github.io/">
       <!-- <span>Institute</span> for Machine  Learning @ JKU -->
       <img class="rounded" src="/assets/img/jku_ml_1.svg" width=100px height=45px>
       <img class="rounded" src="/assets/img/ellis_linz.jpeg" width=200px height=45px>
      </a>
    <div class="container">
      
      <!-- Navbar Toogle -->
      <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar top-bar"></span>
        <span class="icon-bar middle-bar"></span>
        <span class="icon-bar bottom-bar"></span>
      </button>
      <div class="collapse navbar-collapse text-right" id="navbarNav">
        <ul class="navbar-nav ml-auto flex-nowrap">
          <!-- About -->
          <li class="nav-item ">
            <a class="nav-link" href="/">
              about
              
            </a>
          </li>
          
          <!-- Blog -->
          <li class="nav-item active">
            <a class="nav-link" href="/blog/">
              blog
              
            </a>
          </li>
          
          <!-- Other pages -->
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          <li class="nav-item ">
                
                    <div class="dropdown">
                      <a class="nav-link" href="/research/">
                        research
                        
                      </a>
                        <div class="dropdown-content">
                          <a href="/research/deep_learning">Deep Learning</a>
                          <a href="/research/ai_healthcare">AI in Health Care</a>
                          <a href="/research/ai_drug">AI in Drug Discovery</a>
                          <a href="/research/reinforcement_learning">Reinforcement Learning</a>
                          <a href="/research/hopfield_networks">Modern Hopfield Networks</a>
                          <a href="/research/ai4earth">AI 4 Earth</a>
                          <a href="/research/ai4drive">AI 4 Driving</a>
                        </div>
                      </div>
                    
                
          </li>
          
          
          
          
          
          
          
          <li class="nav-item ">
                
                <a class="nav-link" href="/publications/">
                  publications
                  
                </a>
                
          </li>
          
          
          
          
          
          
          
          
          
          
          
          <li class="nav-item ">
                
                <a class="nav-link" href="/talks/">
                  talks
                  
                </a>
                
          </li>
          
          
          
          
          
          
          
          <li class="nav-item ">
              <a class="nav-link" href="https://www.jku.at/en/institute-for-machine-learning/about-us/team/" target="_blank" rel="noopener noreferrer">
                people
                
              </a>
          </li>
          
          
          
          
          
          <li class="nav-item ">
                
                <a class="nav-link" href="/software/">
                  software
                  
                </a>
                
          </li>
          
          
          
          
          
          <li class="nav-item ">
              <a class="nav-link" href="https://www.jku.at/en/institute-for-machine-learning/" target="_blank" rel="noopener noreferrer">
                contact
                
              </a>
          </li>
          
          
          
          
        </ul>
      </div>
    </div>
  </nav>

</header>


    <!-- Content -->

    <div class="container mt-5">
      

<div class="post">

  <header class="post-header">
    <h1 class="post-title">Physics-Informed Neural Compression of High-Dimensional Plasma Data</h1>
    <p class="post-meta">February 5, 2026</p>
  </header>

  <article class="post-content">
    <div style="text-align: center;">
  <a href="https://github.com/ml-jku/neural-gyrokinetics" target="_blank">
    <img src="https://img.shields.io/badge/GitHub-181717?style=for-the-badge&amp;logo=GitHub&amp;logoColor=FFFFFF" alt="code" />
  </a>
  &nbsp;&nbsp;
  <a href="https://arxiv.org/abs/2602.04758" target="_blank">
    <img src="https://img.shields.io/badge/arXiv-B31B1B?style=for-the-badge&amp;logo=arXiv&amp;logoColor=FFFFFF" alt="paper" />
  </a>
  &nbsp;&nbsp;
  <a href="https://huggingface.co/datasets/gerkone/pinc_gkw" target="_blank">
    <img src="https://huggingface.co/datasets/huggingface/badges/resolve/main/dataset-on-hf-md.svg" />
  </a>
</div>

<hr />

<h2 id="tldr">TL;DR</h2>
<div style="border-left: 4px solid #5e4931ff; background-color: #e8cfcfff; padding: 12px 16px; margin: 1em 0; border-radius: 4px;">

<strong>Modern scientific simulations produce massive amounts of data</strong>.
Storing and analyzing this data has become a bottleneck, forcing researchers to throw away valuable information and limiting machine learning training. Plasma turbulence modeled by the gyrokinetic equation is a top example of this.
We introduce <img src="/assets/img/pinc/pinc_icon.png" alt="GyroSwin Icon" height="14px" /> <strong>Physics-Inspired Neural Compression (PINC)</strong> for plasma turbulence. We explore various learned compression techniques, like Neural Fields and VQ-VAEs, and train them with novel plasma-specific physics-informed losses, achieving <strong>70,000x</strong> size reduction while maintaining key physical characteristics.
<strong>We share a reduced 50GB validation set <a href="https://huggingface.co/datasets/gerkone/pinc_gkw" target="_blank"> on huggingface </a> for future compression benchmarking efforts.</strong>
</div>

<h2 id="introduction">Introduction</h2>
<p>In the <a href="https://ml-jku.github.io/blog/2025/gyroswin/">previous blogpost</a> we introduced <img src="/assets/img/pinc/gyroswin_icon.png" alt="GyroSwin Icon" height="12px" /> <strong>GyroSwin</strong> [<a href="#ref-gyroswin">1</a>], a scalable 5D vision transformer able to reliably capture the full nonlinear dynamics of gyrokinetic plasma turbulence. In this post, we present a direction orthogonal to GyroSwin, tackling one of the main challenges that emerged from large-scale training on high-dimensional data: <strong>storage!</strong></p>

<p>Indeed, to achieve its impressive results GyroSwin was trained on a “simple” dataset that consisted already of <strong>terabytes of plasma data</strong>. “Production” gyrokinetic simulations are orders of magnitude more expensive, both in terms of compute and storage required. From a machine learning perspective this would make it unfeasible to package a complete and diverse gyrokinetic dataset.
On the <em>plasma scientist</em> side of the coin, entire simulations can never be stored at full resolution, and practictioners base their analysis on simpler integrated quantities, time traces and spectra.</p>

<p>Our attempt to ease both concerns is <img src="/assets/img/pinc/pinc_icon.png" alt="GyroSwin Icon" height="14px" /> <strong>Physics-Inspired Neural Compression (PINC)</strong>: we explore <strong>neural compression</strong> models (neural implicit fields [<a href="#ref-nerf">2</a>] and Vector Quantized VAEs [<a href="#ref-vqvae">3</a>]) equipped with plasma-specific <strong>physics-informed losses</strong> [<a href="#ref-pinn">4</a>], and achieve impressive results in terms of reconstruction quality, physics preservation and compression rates (with VQ-VAEs, up to <strong>70,000x</strong>!).</p>

<h2 id="our-approach">Our Approach</h2>
<figure style="text-align: center;">
    <img src="/assets/img/pinc/pinc.png" alt="PINC training" width="80%" />
    <figcaption style="color: black; font-family: monospace; font-size: 14px; margin-top: 8px;">
    Figure 1: Sketch of the training and evaluation for PINC models. Training is done at individual time snapshots for scalability, while evaluation considers turbulence characteristics, taking both spatial and temporal information into account.
    </figcaption>
</figure>

<h3 id="evaluating-plasma-turbulence">Evaluating Plasma Turbulence</h3>
<p>As described in the previous blogpost, the full representation of gyrokinetics is the 5D phase space distribution function \(\boldsymbol{f}\).
To check whether compression keeps the physics intact, we look at both <em>spatial</em> and <em>temporal</em> measures of turbulence.
Two core quantities come from integrating \(\boldsymbol{f}\) to obtain the <strong>electrostatic potential</strong> \(\boldsymbol{\phi}\) and <strong>heat flux</strong> \(Q\):</p>

\[\boldsymbol{\phi} = \mathbf{A} \int \mathbf{J_{0}} \boldsymbol{f} \: \mathrm{d}v_{\parallel}\,\mathrm{d}\mu,
\quad
Q = \int \mathbf{B} \int \mathbf{v}^2 \boldsymbol{\phi} \boldsymbol{f} \: \mathrm{d}v_{\parallel}\mathrm{d}\mu \:\: \mathrm{d}x\,\mathrm{d}y\,\mathrm{d}s.\]

<p>Additionally, turbulence is interpreted by looking at how energy distributes across spatial modes, using wave-space diagnostics like \(k_y^{\text{spec}}\) and \(Q^{\text{spec}}\).</p>

<h3 id="neural-compression">Neural Compression</h3>
<p>We experiment with two dominant techniques:</p>
<ul>
  <li><strong>Autoencoders (AEs / VQ-VAEs):</strong> explicit compression through a latent bottleneck, <strong>parameters are shared across data</strong>.</li>
  <li><strong>Neural Implicit Fields (NFs):</strong> store each snapshot as a tiny <strong>independent</strong> coordinate-based network, with compression happening implicitly in weight space.</li>
</ul>

<p>Both optimize a complex MSE loss on the 5D distribution \(\boldsymbol{f}\)</p>

\[\mathcal{L}_{\text{recon}} =
\sum_{v_{\parallel}\mu s x y} \left[ \Re(\boldsymbol{f}_{\text{pred}} - \boldsymbol{f}_{\text{GT}})^2 +
\Im(\boldsymbol{f}_{\text{pred}} - \boldsymbol{f}_{\text{GT}})^2 \right].\]

<h3 id="physics-inspired-neural-compression">Physics-Inspired Neural Compression</h3>
<p>Plain reconstruction loss isn’t enough, and high reconstruction quality does not always reflect in the physical fidelity.
PINC adds penalties on the ground truth physical quantities \(\boldsymbol{\phi}\) and \(Q\), as well as the diagnostic spectra \(k_y^{\text{spec}}\) and \(Q^{\text{spec}}\).
Moreover, monotonicity of the energy cascade is enforced as a knowledge-driven physical constraint.</p>

<p>As a side note, while PINC-neural fields can be comfortably trained with <em>off-the-shelf</em> optimizers, the story is different for the more complex autoencoders. 
Instead, naively training them on all PINC losses often leads to severe instabilities and catastrophic forgetting. We solve this complication by pretraining the larger autoencoders on the distribution \(\boldsymbol{f}\), and subsequently using Explained Variance Adaptation [<a href="#ref-eva">5</a>] to finetune the model on the PINC losses.</p>

<h2 id="results">Results</h2>
<h3 id="quantitative">Quantitative</h3>
<p>Learned compression shows strong performance on all metrics in our dataset. Neural fields and autoencoders with PINC losses considerably improve the conservation of physical quantities, compared to the unregularized counterparts. For neural fields, training on physics-informed losses degrades reconstruction quality slightly and introduces some temporal inconsistencies, and we speculate this is caused by <a href="https://arxiv.org/abs/2001.06782">conflict gradients</a>.</p>

<table>
  <thead>
    <tr>
      <th>Method</th>
      <th>CR</th>
      <th>PSNR ↑</th>
      <th>EPE ↓</th>
      <th>L1(Q) ↓</th>
      <th>PSNR(\(\phi\)) ↑</th>
      <th>WD(\(k_y^{\text{spec}}\)) ↓</th>
      <th>WD(\(Q^{\text{spec}}\)) ↓</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>ZFP</td>
      <td>901×</td>
      <td>28.97 ± 1.09</td>
      <td>0.175 ± 0.07</td>
      <td>107.48 ± 49.35</td>
      <td>−16.20 ± 7.09</td>
      <td>0.020 ± 0.01</td>
      <td>0.116 ± 0.20</td>
    </tr>
    <tr>
      <td>Wavelet</td>
      <td>936×</td>
      <td>33.07 ± 1.18</td>
      <td>0.064 ± 0.03</td>
      <td>107.74 ± 49.51</td>
      <td>−13.24 ± 9.20</td>
      <td>0.020 ± 0.01</td>
      <td><strong>0.010 ± 0.00</strong></td>
    </tr>
    <tr>
      <td>PCA</td>
      <td>1020×</td>
      <td>32.09 ± 0.98</td>
      <td>0.123 ± 0.07</td>
      <td>67.60 ± 36.08</td>
      <td>−10.22 ± 6.89</td>
      <td>0.020 ± 0.01</td>
      <td>0.011 ± 0.00</td>
    </tr>
    <tr>
      <td>JPEG2000</td>
      <td>1000×</td>
      <td>34.33 ± 0.95</td>
      <td>0.046 ± 0.02</td>
      <td>103.91 ± 44.12</td>
      <td>−20.85 ± 6.50</td>
      <td>0.020 ± 0.01</td>
      <td>0.035 ± 0.03</td>
    </tr>
    <tr>
      <td>NF</td>
      <td>1167×</td>
      <td><strong>36.91 ± 0.93</strong></td>
      <td><strong>0.031 ± 0.02</strong></td>
      <td>61.50 ± 16.91</td>
      <td>1.24 ± 5.99</td>
      <td>0.017 ± 0.01</td>
      <td>0.017 ± 0.00</td>
    </tr>
    <tr>
      <td>PINC-NF</td>
      <td>1167×</td>
      <td>35.76 ± 1.38</td>
      <td>0.037 ± 0.02</td>
      <td><strong>2.18 ± 8.33</strong></td>
      <td><strong>13.50 ± 4.44</strong></td>
      <td><strong>0.006 ± 0.00</strong></td>
      <td>0.015 ± 0.00</td>
    </tr>
    <tr>
      <td>AE + EVA</td>
      <td>716×</td>
      <td>35.64 ± 2.03</td>
      <td>0.063 ± 0.05</td>
      <td>15.01 ± 16.42</td>
      <td>6.72 ± 4.98</td>
      <td>0.016 ± 0.01</td>
      <td>0.012 ± 0.01</td>
    </tr>
    <tr>
      <td>VQ-VAE + EVA</td>
      <td>301×</td>
      <td>32.61 ± 1.58</td>
      <td>0.095 ± 0.07</td>
      <td>44.26 ± 40.97</td>
      <td>7.66 ± 3.75</td>
      <td>0.015 ± 0.01</td>
      <td>0.013 ± 0.01</td>
    </tr>
  </tbody>
</table>

<p>This table is obtained from the public 50GB dataset, and can be reproduced with the evaluation notebook <a href="https://github.com/ml-jku/neural-gyrokinetics/blob/git-release/notebooks/01_pinc_evaluation_hf.ipynb"><code class="language-plaintext highlighter-rouge">01_pinc_evaluation_hf.ipynb</code></a>.</p>

<h3 id="qualitative">Qualitative</h3>
<div style="display:flex; justify-content:center; gap:12px; align-items:flex-start; flex-wrap:wrap;">
  <figure style="margin:0; text-align:center; width:45%;">
    <img src="/assets/img/pinc/df_recon.png" alt="Density reconstruction" style="width:100%; height:auto; display:block;" />
    <figcaption style="color:black; font-size:13px;">
      (a) <strong>f</strong>
    </figcaption>
  </figure>

  <figure style="margin:0; text-align:center; width:45%;">
    <img src="/assets/img/pinc/phi_recon.png" alt="Electrostatic potential reconstruction" style="width:100%; height:auto; display:block;" />
    <figcaption style="color:black; font-size:13px;">
      (b) <strong>ϕ</strong>
    </figcaption>
  </figure>
  <p style="text-align: center; color: black; font-family: monospace; font-size:14px;">
  Figure 2: Reconstructions for the density (a) and electrostatic potential (b) for a few randomly picked snapshots across different trajectories.
  </p>
</div>

<p>These 2D projections of the 5D (left) and 3D (right) fields demonstrate the advantage of PINC neural fields in direct density reconstruction, and even more clear for integral fidelity for the electrostatic potential. This is reflected in the higher \(\boldsymbol{\phi}\) PSNR in Table 1.</p>

<figure style="text-align: center;">
    <img src="/assets/img/pinc/cascade.png" alt="Bi-directional energy cascade" width="100%" />
    <figcaption style="color: black; font-family: monospace; font-size: 14px; margin-top: 8px;">
    Figure 3: Potential (ky) and flux spectra at three timesteps, sampled in the transitional phase where mode growth and energy cascade happens. LogLog plot.
    </figcaption>
</figure>

<p>Figure 3 visualizes the <strong>bi-directional energy cascade</strong> phenomenon: as turbulence develops, energy is transferred from higher to lower modes and vice-versa.
Columns are different trajectories, rows are compression methods, lines of varied colors are the \(k_y^{\text{spec}}\) and \(Q^{\text{spec}}\) at specific timesteps, and transparent dashed lines are respective ground truth.</p>

<p>While traditional compressoin techniques sometimes manage to visually capture \(k_y^{\text{spec}}\), they fail completely on \(Q^{\text{spec}}\). On the other hand, PINCs are somewhat less accurate on high frequencies, but generally capture low frequencies and magnitude pretty well.</p>

<h3 id="rate-distortion-scaling">Rate-Distortion scaling</h3>
<figure style="text-align: center;">
    <img src="/assets/img/pinc/rate_distortion.png" alt="Rate-distortion plots" width="100%" />
    <figcaption style="color: black; font-family: monospace; font-size: 14px; margin-top: 8px;">
    Figure 4: Rate-Distortion scaling for direct density <strong>f</strong> reconstruction (left) and potential <strong>ϕ</strong> and heat flux Q integrals (right).
    </figcaption>
</figure>

<p>The left figure highlights an advantageous power-law scaling for the neural fields, against a super-exponential decay for traditional compression techniques. We also notice a <em>“goldilocks compression rate”</em> , between 200x and 10,000x where neural fields outperform traditional compression on direct reconstruction.</p>

<p>The right plot shows the improvement of PINC training in terms of the integral loss gap, reported for a single VQ-VAE (blue cross \(\to\) green dot, \(\Delta \mathcal{L}\) gap displayed with an arrow).</p>

<h2 id="conclusions-and-future-work">Conclusions and Future Work</h2>
<p>PINC opens new possibilities for sharing, storing, and analyzing scientific datasets that were previously too large to handle. What’s next?</p>

<ol>
  <li><strong>Big small datasets.</strong> The initial concern that motivated this work is scaling GyroSwin to even larger data volumes, and especially higher fidelity data. With PINC, compressed representations can either be inflated <em>in-transit</em>, or directly serve as a dataset for <em>“compressed”</em> surrogate modeling. For instance, the VQ-VAE can be leveraged for latent diffusion, where turbulent solutions are generated starting from operational parameters.</li>
  <li><strong>Integration into numerical codes and workflows.</strong> Integrating PINC in the plasma scientist workflow of GKW would enable cheap, staggered <strong>on-the-fly (in-situ)</strong> compression during the simulation, making it feasible to capture transient dynamics without writing massive data dumps to disk.</li>
</ol>

<h2 id="resources">Resources</h2>

<ul>
  <li><a href="https://arxiv.org/abs/2602.04758">Paper</a></li>
  <li><a href="https://github.com/ml-jku/neural-gyrokinetics">Code</a></li>
  <li><a href="https://huggingface.co/datasets/gerkone/pinc_gkw">HuggingFace dataset and results</a></li>
  <li><a href="https://ml-jku.github.io/blog/2025/gyroswin/">GyroSwin blogpost</a></li>
</ul>

<h2 id="citation">Citation</h2>

<p>If you found our work useful, please consider citing it.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>@misc{galletti2026physicsinformedneuralcompressionhighdimensional,
      title={Physics-Informed Neural Compression of High-Dimensional Plasma Data}, 
      author={Gianluca Galletti and Gerald Gutenbrunner and Sandeep S. Cranganore and William Hornsby and Lorenzo Zanisi and Naomi Carey and Stanislas Pamela and Johannes Brandstetter and Fabian Paischer},
      year={2026},
      eprint={2602.04758},
      archivePrefix={arXiv},
      primaryClass={physics.plasm-ph},
      url={https://arxiv.org/abs/2602.04758}, 
}
</code></pre></div></div>

<h2 id="references">References</h2>
<p><a name="ref-gyroswin"></a>
[1] Fabian Paischer, Gianluca Galletti, William Hornsby, Paul Setinek, Lorenzo Zanisi, Naomi Carey, Stanislas Pamela, and Johannes Brandstetter, <em>“GyroSwin: 5D Surrogates for Gyrokinetic Plasma Turbulence Simulations”</em> in <em>Advances in Neural Information Processing Systems 38 (NeurIPS 2025)</em> <a href="https://arxiv.org/abs/2510.07314">https://arxiv.org/abs/2510.07314</a></p>

<p><a name="ref-nerf"></a>
[2] Ben Mildenhall, Pratul P. Srinivasan, Matthew Tancik, Jonathan T. Barron, Ravi Ramamoorthi, and Ren Ng, <em>“NeRF: Representing Scenes as Neural Radiance Fields for View Synthesis,”</em> arXiv preprint arXiv:2003.08934, 2020. [Online]. Available: <a href="https://arxiv.org/abs/2003.08934">https://arxiv.org/abs/2003.08934</a></p>

<p><a name="ref-vqvae"></a>
[3] Aaron van den Oord, Oriol Vinyals, and Koray Kavukcuoglu, <em>“Neural Discrete Representation Learning,”</em> arXiv preprint arXiv:1711.00937, 2018. [Online]. Available: <a href="https://arxiv.org/abs/1711.00937">https://arxiv.org/abs/1711.00937</a></p>

<p><a name="ref-pinn"></a>
[4] George E. Karniadakis, Ioannis G. Kevrekidis, Lu Lu, et al., <em>“Physics-informed machine learning,”</em> <em>Nature Reviews Physics</em>, vol. 3, pp. 422–440, 2021. [Online]. Available: <a href="https://doi.org/10.1038/s42254-021-00314-5">https://doi.org/10.1038/s42254-021-00314-5</a></p>

<p><a name="ref-eva"></a>
[5] Fabian Paischer, Lukas Hauzenberger, Thomas Schmied, Benedikt Alkin, Marc Peter Deisenroth, and Sepp Hochreiter, <em>“Parameter Efficient Fine-tuning via Explained Variance Adaptation,”</em> arXiv preprint arXiv:2410.07170, in <em>Advances in Neural Information Processing Systems 38 (NeurIPS 2025)</em> <a href="https://arxiv.org/abs/2410.07170">https://arxiv.org/abs/2410.07170</a></p>

<hr />
<p>2025, Gianluca Galletti</p>

  </article>

  

</div>

    </div>

    <!-- Footer -->

    
<footer class="fixed-bottom">
  <div class="container mt-0">
    &copy; Copyright 2026 Institute for Machine Learning @ JKU.
    Powered by <a href="http://jekyllrb.com/" target="_blank">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank">GitHub Pages</a>.

    
  </div>
</footer>



  </body>

  <!-- jQuery -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script>

  <!-- Bootsrap & MDB scripts -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/2.4.4/umd/popper.min.js" integrity="sha512-eUQ9hGdLjBjY3F41CScH3UX+4JDSI9zXeroz7hJ+RteoCaY+GP/LDoM8AO+Pt+DRFw3nXqsjh9Zsts8hnYv8/A==" crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/js/bootstrap.min.js" integrity="sha512-M5KW3ztuIICmVIhjSqXe01oV2bpe248gOxqmlcYrEzAvws7Pw3z6BK0iGbrwvdrUQUhi3eXgtxp5I8PDo9YfjQ==" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.19.1/js/mdb.min.js" integrity="sha512-Mug9KHKmroQFMLm93zGrjhibM2z2Obg9l6qFG2qKjXEXkMp/VDkI4uju9m4QKPjWSwQ6O2qzZEnJDEeCw0Blcw==" crossorigin="anonymous"></script>

  
<!-- Mansory & imagesLoaded -->
<script defer src="https://unpkg.com/masonry-layout@4/dist/masonry.pkgd.min.js"></script>
<script defer src="https://unpkg.com/imagesloaded@4/imagesloaded.pkgd.min.js"></script>
<script defer src="/assets/js/mansory.js" type="text/javascript"></script>


  


<!-- Load Common JS -->
<script src="/assets/js/common.js"></script>

<!-- Load DarkMode JS -->
<script src="/assets/js/dark_mode.js"></script>


</html>
