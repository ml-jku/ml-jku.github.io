<!DOCTYPE html>
<html>

  <head>
    <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta http-equiv="X-UA-Compatible" content="IE=edge">

<title>Institute for Machine Learning @ JKU | Deep Learning</title>
<meta name="description" content="Research blog of the Institute for Machine Learning @ JKU.
">

<!-- Open Graph -->


<!-- Bootstrap & MDB -->
<link href="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/css/bootstrap.min.css" rel="stylesheet" integrity="sha512-MoRNloxbStBcD8z3M/2BmnT+rg4IsMxPkXaGh2zD6LGNNFE80W3onsAhRcMAMrSoyWL9xD7Ert0men7vR8LUZg==" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.19.1/css/mdb.min.css" integrity="sha512-RO38pBRxYH3SoOprtPTD86JFOclM51/XTIdEPh5j8sj4tp8jmQIx26twG52UaLi//hQldfrh7e51WzP9wuP32Q==" crossorigin="anonymous" />

<!-- Fonts & Icons -->
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css"  integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.9.0/css/academicons.min.css" integrity="sha512-W4yqoT1+8NLkinBLBZko+dFB2ZbHsYLDdr50VElllRcNt2Q4/GSs6u71UHKxB7S6JEMCp5Ve4xjh3eGQl/HRvg==" crossorigin="anonymous">
<link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">

<!-- Code Syntax Highlighting -->
<link rel="stylesheet" href="https://gitcdn.link/repo/jwarby/jekyll-pygments-themes/master/github.css" />

<!-- Styles -->
<link rel="shortcut icon" href="/assets/img/favicon.ico">
<link rel="stylesheet" href="/assets/css/main.css">

<link rel="canonical" href="/research/deep_learning/">

<!-- Theming-->



  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-KC0VGMCD6W"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag() { dataLayer.push(arguments); }
    gtag('js', new Date());

    gtag('config', 'G-KC0VGMCD6W');
  </script>


    
<!-- MathJax -->
<script type="text/javascript">
  window.MathJax = {
    tex: {
      tags: 'ams'
    }
  };
</script>
<script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.1.2/es5/tex-mml-chtml.js"></script>
<script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>


  </head>

  <body class="fixed-top-nav ">

    <!-- Header -->

    <header>

    <!-- Nav Bar -->
    <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top">
      <a class="navbar-brand title font-weight-lighter" href="ml-jku.github.io/">
       <!-- <span>Institute</span> for Machine  Learning @ JKU -->
       <img class="rounded" src="/assets/img/jku_ml_1.svg" width=100px height=45px>
       <img class="rounded" src="/assets/img/ellis_linz.jpeg" width=200px height=45px>
      </a>
    <div class="container">
      
      <!-- Navbar Toogle -->
      <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar top-bar"></span>
        <span class="icon-bar middle-bar"></span>
        <span class="icon-bar bottom-bar"></span>
      </button>
      <div class="collapse navbar-collapse text-right" id="navbarNav">
        <ul class="navbar-nav ml-auto flex-nowrap">
          <!-- About -->
          <li class="nav-item ">
            <a class="nav-link" href="/">
              about
              
            </a>
          </li>
          
          <!-- Blog -->
          <li class="nav-item ">
            <a class="nav-link" href="/blog/">
              blog
              
            </a>
          </li>
          
          <!-- Other pages -->
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          <li class="nav-item ">
                
                    <div class="dropdown">
                      <a class="nav-link" href="/research/">
                        research
                        
                      </a>
                        <div class="dropdown-content">
                          <a href="/research/deep_learning">Deep Learning</a>
                          <a href="/research/ai_healthcare">AI in Health Care</a>
                          <a href="/research/ai_drug">AI in Drug Discovery</a>
                          <a href="/research/reinforcement_learning">Reinforcement Learning</a>
                          <a href="/research/hopfield_networks">Modern Hopfield Networks</a>
                          <a href="/research/ai4earth">AI 4 Earth</a>
                          <a href="/research/ai4drive">AI 4 Driving</a>
                        </div>
                      </div>
                    
                
          </li>
          
          
          
          
          
          
          
          <li class="nav-item ">
                
                <a class="nav-link" href="/publications/">
                  publications
                  
                </a>
                
          </li>
          
          
          
          
          
          
          
          
          
          
          
          <li class="nav-item ">
                
                <a class="nav-link" href="/talks/">
                  talks
                  
                </a>
                
          </li>
          
          
          
          
          
          
          
          <li class="nav-item ">
              <a class="nav-link" href="https://www.jku.at/en/institute-for-machine-learning/about-us/team/" target="_blank" rel="noopener noreferrer">
                people
                
              </a>
          </li>
          
          
          
          
          
          <li class="nav-item ">
                
                <a class="nav-link" href="/software/">
                  software
                  
                </a>
                
          </li>
          
          
          
          
          
          <li class="nav-item ">
              <a class="nav-link" href="https://www.jku.at/en/institute-for-machine-learning/" target="_blank" rel="noopener noreferrer">
                contact
                
              </a>
          </li>
          
          
          
          
        </ul>
      </div>
    </div>
  </nav>

</header>


    <!-- Content -->

    <div class="container mt-5">
      <div class="post">

  <header class="post-header">
    
    <h1 class="post-title">Deep Learning</h1>
    <p class="post-description"></p>
    
  </header>

  <article>
    <div class="about-text">
    <p>
Artificial Intelligence (AI) has recently revolutionised various fields of science and has also started to pervade commercial applications in an unprecedented manner. Despite great successes, most of AI’s enormous potential is still to be realised. The recent surge of AI can be attributed to advances in the machine learning field known as “Deep Learning”, that is, large deeply-layered artificial neural networks (ANNs) trained by modern learning algorithms on massive datasets. In its core, Deep Learning discovers multiple levels of distributed representations of the input, with higher levels representing more abstract concepts. These representations led to impressive successes in different research areas. In particular, artificial neural networks considerably improved the performance in computer vision, speech recognition, and internet advertising. </p>

<div class="row justify-content-sm-center">
    <div class="col-sm-8 mt-3 mt-md-0">
        <img class="img-fluid rounded research-img" src="/assets/img/research/deep_learning/deep_learning_1.png" alt="" title="example image" />
    </div>
<p>
<a href="https://en.wikipedia.org/wiki/Sepp_Hochreiter">Sepp Hochreiter</a>, heading this research group, is considered a pioneer of Deep Learning with his discovery of the vanishing gradient problem and the invention of long-short term memory (LSTM) networks.</p>



<div class="publications">
<h4>recent publications in Deep Learning:</h4>
  <ol class="bibliography"><li><div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">ICML</abbr>
    
  
  </div>

  <div id="sanokowski2024diffusion" class="col-sm-8">
    
      <div class="title">A Diffusion Model Framework for Unsupervised Neural Combinatorial Optimization</div>
      <div class="author">
        
          
            
              
                
                  Sanokowski, S.,
                
              
            
          
        
          
            
              
                
                  Hochreiter, S.,
                
              
            
          
        
          
            
              
                
                  and Lehner, S.
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>Proceedings of the 41st International Conference on Machine Learning</em>
      
      
        2024
      
      </div>
    

    <div class="links">
    
    
    
      <a href="https://arxiv.org/abs/2406.01661" class="btn btn-sm z-depth-0" role="button" target="_blank">url</a>
    
    
    
    
    
    
      <a href="https://github.com/ml-jku/DIffUCO" class="btn btn-sm z-depth-0" role="button" target="_blank">Code</a>
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">NeurIPS</abbr>
    
  
  </div>

  <div id="sanokowski2023variational" class="col-sm-8">
    
      <div class="title">Variational annealing on graphs for combinatorial optimization</div>
      <div class="author">
        
          
            
              
                
                  Sanokowski, S.,
                
              
            
          
        
          
            
              
                
                  Berghammer, W.,
                
              
            
          
        
          
            
              
                
                  Hochreiter, S.,
                
              
            
          
        
          
            
              
                
                  and Lehner, S.
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>Advances in Neural Information Processing Systems</em>
      
      
        2023
      
      </div>
    

    <div class="links">
    
    
    
      <a href="https://arxiv.org/abs/2311.14156" class="btn btn-sm z-depth-0" role="button" target="_blank">url</a>
    
    
    
    
    
    
      <a href="https://github.com/ml-jku/VAG-CO" class="btn btn-sm z-depth-0" role="button" target="_blank">Code</a>
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">NeurIPS</abbr>
    
  
  </div>

  <div id="hoedt2023convex-init" class="col-sm-8">
    
      <div class="title">Principled Weight Initialisation for Input-Convex Neural Networks</div>
      <div class="author">
        
          
            
              
                
                  Hoedt, P.,
                
              
            
          
        
          
            
              
                
                  and Klambauer, G.
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>In Advances in Neural Information Processing Systems</em>
      
      
        2023
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
      <a href="https://proceedings.neurips.cc/paper_files/paper/2023/hash/9062b7d6e522dadf4f7d85d49b60d81e-Abstract.html" class="btn btn-sm z-depth-0" role="button" target="_blank">url</a>
    
    
    
      
      <a href="https://proceedings.neurips.cc/paper_files/paper/2023/file/9062b7d6e522dadf4f7d85d49b60d81e-Paper-Conference.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
      <a href="https://github.com/ml-jku/convex-init" class="btn btn-sm z-depth-0" role="button" target="_blank">Code</a>
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Input-Convex Neural Networks (ICNNs) are networks that guarantee convexity in their input-output mapping. These networks have been successfully applied for energy-based modelling, optimal transport problems and learning invariances.The convexity of ICNNs is achieved by using non-decreasing convex activation functions and non-negative weights. Because of these peculiarities, previous initialisation strategies, which implicitly assume centred weights, are not effective for ICNNs. By studying signal propagation through layers with non-negative weights, we are able to derive a principled weight initialisation for ICNNs. Concretely, we generalise signal propagation theory by removing the assumption that weights are sampled from a centred distribution. In a set of experiments, we demonstrate that our principled initialisation effectively accelerates learning in ICNNs and leads to better generalisation. Moreover, we find that, in contrast to common belief, ICNNs can be trained without skip-connections when initialised correctly. Finally, we apply ICNNs to a real-world drug discovery task and show that they allow for more effective molecular latent space exploration.</p>
    </div>
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">arXiv</abbr>
    
  
  </div>

  <div id="schweighofer2023quam" class="col-sm-8">
    
      <div class="title">Quantification of Uncertainty with Adversarial Models</div>
      <div class="author">
        
          
            
              
                
                  Schweighofer, K.,
                
              
            
          
        
          
            
              
                
                  Aichberger, L.,
                
              
            
          
        
          
            
              
                
                  Ielanski, M.,
                
              
            
          
        
          
            
              
                
                  Klambauer, G.,
                
              
            
          
        
          
            
              
                
                  and Hochreiter, S.
                
              
            
          
        
      </div>

      <div class="periodical">
      
      
        2023
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
      <a href="https://arxiv.org/abs/2307.03217" class="btn btn-sm z-depth-0" role="button" target="_blank">url</a>
    
    
    
    
    
    
      <a href="https://github.com/ml-jku/quam" class="btn btn-sm z-depth-0" role="button" target="_blank">Code</a>
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Quantifying uncertainty is important for actionable predictions in real-world applications. A crucial part of predictive uncertainty quantification is the estimation of epistemic uncertainty, which is defined as an integral of the product between a divergence function and the posterior. Current methods such as Deep Ensembles or MC dropout underperform at estimating the epistemic uncertainty, since they primarily consider the posterior when sampling models. We suggest Quantification of Uncertainty with Adversarial Models (QUAM) to better estimate the epistemic uncertainty. QUAM identifies regions where the whole product under the integral is large, not just the posterior. Consequently, QUAM has lower approximation error of the epistemic uncertainty compared to previous methods. Models for which the product is large correspond to adversarial models (not adversarial examples!). Adversarial models have both a high posterior as well as a high divergence between their predictions and that of a reference model. Our experiments show that QUAM excels in capturing epistemic uncertainty for deep learning models and outperforms previous methods on challenging tasks in the vision domain.</p>
    </div>
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">NeurIPS</abbr>
    
  
  </div>

  <div id="paischer2023semantic" class="col-sm-8">
    
      <div class="title">Semantic HELM: An Interpretable Memory for Reinforcement Learning</div>
      <div class="author">
        
          
            
              
                
                  Paischer, F.,
                
              
            
          
        
          
            
              
                
                  Adler, T.,
                
              
            
          
        
          
            
              
                
                  Hofmarcher, M.,
                
              
            
          
        
          
            
              
                
                  and Hochreiter, S.
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em></em>
      
      
        2023
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
      <a href="https://arxiv.org/abs/2306.09312" class="btn btn-sm z-depth-0" role="button" target="_blank">url</a>
    
    
    
    
    
    
      <a href="https://github.com/ml-jku/helm" class="btn btn-sm z-depth-0" role="button" target="_blank">Code</a>
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Reinforcement learning agents deployed in the real world often have to cope with partially observable environments. Therefore, most agents employ memory mechanisms to approximate the state of the environment. Recently, there have been impressive success stories in mastering partially observable environments, mostly in the realm of computer games like Dota 2, StarCraft II, or MineCraft. However, existing methods lack interpretability in the sense that it is not comprehensible for humans what the agent stores in its memory. In this regard, we propose a novel memory mechanism that represents past events in human language.
Our method uses CLIP to associate visual inputs with language tokens. Then we feed these tokens to a pretrained language model that serves the agent as memory and provides it with a coherent and human-readable representation of the past. We train our memory mechanism on a set of partially observable environments and find that it excels on tasks that require a memory component, while mostly attaining performance on-par with strong baselines on tasks that do not. On a challenging continuous recognition task, where memorizing the past is crucial, our memory mechanism converges two orders of magnitude faster than prior methods. Since our memory mechanism is human-readable, we can peek at an agent’s memory and check whether crucial pieces of information have been stored. This significantly enhances troubleshooting and paves the way toward more interpretable agents.</p>
    </div>
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">arXiv</abbr>
    
  
  </div>

  <div id="paischer2023sitta" class="col-sm-8">
    
      <div class="title">SITTA: A Semantic Image-Text Alignment for Image Captioning</div>
      <div class="author">
        
          
            
              
                
                  Paischer, F.,
                
              
            
          
        
          
            
              
                
                  Adler, T.,
                
              
            
          
        
          
            
              
                
                  Hofmarcher, M.,
                
              
            
          
        
          
            
              
                
                  and Hochreiter, S.
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em></em>
      
      
        2023
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
      <a href="https://arxiv.org/abs/2307.05591" class="btn btn-sm z-depth-0" role="button" target="_blank">url</a>
    
    
    
    
    
    
      <a href="https://github.com/ml-jku/semantic-image-text-alignment" class="btn btn-sm z-depth-0" role="button" target="_blank">Code</a>
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Textual and semantic comprehension of images is essential for generating proper captions. The comprehension requires detection of objects, modeling of relations between them, an assessment of the semantics of the scene and, finally, representing the extracted knowledge in a language space. To achieve rich language capabilities while ensuring good image-language mappings, pretrained language models (LMs) were conditioned on pretrained multi-modal (image-text) models that allow for image inputs. This requires an alignment of the image representation of the multi-modal model with the language representations of a generative LM. However, it is not clear how to best transfer semantics detected by the vision encoder of the multi-modal model to the LM. We introduce two novel ways of constructing a linear mapping that successfully transfers semantics between the embedding spaces of the two pretrained models. The first aligns the embedding space of the multi-modal language encoder with the embedding space of the pretrained LM via token correspondences. The latter leverages additional data that consists of image-text pairs to construct the mapping directly from vision to language space. Using our semantic mappings, we unlock image captioning for LMs without access to gradient information. By using different sources of data we achieve strong captioning performance on MS-COCO and Flickr30k datasets. Even in the face of limited data, our method partly exceeds the performance of other zero-shot and even finetuned competitors. Our ablation studies show that even LMs at a scale of merely 250M parameters can generate decent captions employing our semantic mappings. Our approach makes image captioning more accessible for institutions with restricted computational resources.</p>
    </div>
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">arXiv</abbr>
    
  
  </div>

  <div id="bib:Mayr2023_2" class="col-sm-8">
    
      <div class="title">Boundary Graph Neural Networks for 3D Simulations</div>
      <div class="author">
        
          
            
              
                
                  Mayr, A.,
                
              
            
          
        
          
            
              
                
                  Lehner, S.,
                
              
            
          
        
          
            
              
                
                  Mayrhofer, A.,
                
              
            
          
        
          
            
              
                
                  Kloss, C.,
                
              
            
          
        
          
            
              
                
                  Hochreiter, S.,
                
              
            
          
        
          
            
              
                
                  and Brandstetter, J.
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em></em>
      
      
        2023
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
      <a href="https://arxiv.org/abs/2106.11299" class="btn btn-sm z-depth-0" role="button" target="_blank">url</a>
    
    
    
    
    
      <a href="https://ml-jku.github.io/bgnn" class="btn btn-sm z-depth-0" role="button" target="_blank">Blog</a>
    
    
      <a href="https://github.com/ml-jku/bgnn" class="btn btn-sm z-depth-0" role="button" target="_blank">Code</a>
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>The abundance of data has given machine learning considerable momentum in natural sciences and engineering, though modeling of physical processes is often difficult. A particularly tough problem is the efficient representation of geometric boundaries. Triangularized geometric boundaries are well understood and ubiquitous in engineering applications. However, it is notoriously difficult to integrate them into machine learning approaches due to their heterogeneity with respect to size and orientation. In this work, we introduce an effective theory to model particle-boundary interactions, which leads to our new Boundary Graph Neural Networks (BGNNs) that dynamically modify graph structures to obey boundary conditions. The new BGNNs are tested on complex 3D granular flow processes of hoppers, rotating drums and mixers, which are all standard components of modern industrial machinery but still have complicated geometry. BGNNs are evaluated in terms of computational efficiency as well as prediction accuracy of particle flows and mixing entropies. BGNNs are able to accurately reproduce 3D granular flows within simulation uncertainties over hundreds of thousands of simulation timesteps. Most notably, in our experiments, particles stay within the geometric objects without using handcrafted conditions or restrictions.</p>
    </div>
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">arXiv</abbr>
    
  
  </div>

  <div id="lehner2023maect" class="col-sm-8">
    
      <div class="title">Contrastive Tuning: A Little Help to Make Masked Autoencoders Forget</div>
      <div class="author">
        
          
            
              
                
                  Lehner, J.,
                
              
            
          
        
          
            
              
                
                  Alkin, B.,
                
              
            
          
        
          
            
              
                
                  Fürst, A.,
                
              
            
          
        
          
            
              
                
                  Rumetshofer, E.,
                
              
            
          
        
          
            
              
                
                  Miklautz, L.,
                
              
            
          
        
          
            
              
                
                  and Hochreiter, S.
                
              
            
          
        
      </div>

      <div class="periodical">
      
      
        2023
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
      <a href="https://arxiv.org/abs/2304.10520" class="btn btn-sm z-depth-0" role="button" target="_blank">url</a>
    
    
    
    
    
    
      <a href="https://github.com/ml-jku/MAE-CT" class="btn btn-sm z-depth-0" role="button" target="_blank">Code</a>
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Masked Image Modeling (MIM) methods, like Masked Autoencoders (MAE), efficiently learn a rich representation of the input. However, for adapting to downstream tasks, they require a sufficient amount of labeled data since their rich features code not only objects but also less relevant image background. In contrast, Instance Discrimination (ID) methods focus on objects. In this work, we study how to combine the efficiency and scalability of MIM with the ability of ID to perform downstream classification in the absence of large amounts of labeled data. To this end, we introduce Masked Autoencoder Contrastive Tuning (MAE-CT), a sequential approach that utilizes the implicit clustering of the Nearest Neighbor Contrastive Learning (NNCLR) objective to induce abstraction in the topmost layers of a pre-trained MAE. MAE-CT tunes the rich features such that they form semantic clusters of objects without using any labels. Notably, MAE-CT does not rely on hand-crafted augmentations and frequently achieves its best performances while using only minimal augmentations (crop &amp; flip). Further, MAE-CT is compute efficient as it requires at most 10% overhead compared to MAE pre-training. Applied to large and huge Vision Transformer (ViT) models, MAE–CT excels over previous self-supervised methods trained on ImageNet in linear probing, k-NN and low-shot classification accuracy as well as in unsupervised clustering accuracy. With ViT-H/16 MAE–CT achieves a new state-of-the-art in linear probing of 82.2%.</p>
    </div>
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">AAAI</abbr>
    
  
  </div>

  <div id="bib:Mayr2023_1" class="col-sm-8">
    
      <div class="title">Boundary Graph Neural Networks for 3D Simulations</div>
      <div class="author">
        
          
            
              
                
                  Mayr, A.,
                
              
            
          
        
          
            
              
                
                  Lehner, S.,
                
              
            
          
        
          
            
              
                
                  Mayrhofer, A.,
                
              
            
          
        
          
            
              
                
                  Kloss, C.,
                
              
            
          
        
          
            
              
                
                  Hochreiter, S.,
                
              
            
          
        
          
            
              
                
                  and Brandstetter, J.
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>Proceedings of the AAAI Conference on Artificial Intelligence</em>
      
      
        2023
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
      <a href="https://ojs.aaai.org/index.php/AAAI/article/view/26092" class="btn btn-sm z-depth-0" role="button" target="_blank">url</a>
    
    
    
    
    
      <a href="https://ml-jku.github.io/bgnn" class="btn btn-sm z-depth-0" role="button" target="_blank">Blog</a>
    
    
      <a href="https://github.com/ml-jku/bgnn" class="btn btn-sm z-depth-0" role="button" target="_blank">Code</a>
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>The abundance of data has given machine learning considerable momentum in natural sciences and engineering, though modeling of physical processes is often difficult. A particularly tough problem is the efficient representation of geometric boundaries. Triangularized geometric boundaries are well understood and ubiquitous in engineering applications. However, it is notoriously difficult to integrate them into machine learning approaches due to their heterogeneity with respect to size and orientation. In this work, we introduce an effective theory to model particle-boundary interactions, which leads to our new Boundary Graph Neural Networks (BGNNs) that dynamically modify graph structures to obey boundary conditions. The new BGNNs are tested on complex 3D granular flow processes of hoppers, rotating drums and mixers, which are all standard components of modern industrial machinery but still have complicated geometry. BGNNs are evaluated in terms of computational efficiency as well as prediction accuracy of particle flows and mixing entropies. BGNNs are able to accurately reproduce 3D granular flows within simulation uncertainties over hundreds of thousands of simulation timesteps. Most notably, in our experiments, particles stay within the geometric objects without using handcrafted conditions or restrictions.</p>
    </div>
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">ML4PS</abbr>
    
  
  </div>

  <div id="tran2022using" class="col-sm-8">
    
      <div class="title">Using Shadows to Learn Ground State Properties of Quantum Hamiltonians</div>
      <div class="author">
        
          
            
              
                
                  Tran, V.,
                
              
            
          
        
          
            
              
                
                  Lewis, L.,
                
              
            
          
        
          
            
              
                
                  Huang, H.,
                
              
            
          
        
          
            
              
                
                  Kofler, J.,
                
              
            
          
        
          
            
              
                
                  Kueng, R.,
                
              
            
          
        
          
            
              
                
                  Hochreiter, S.,
                
              
            
          
        
          
            
              
                
                  and Lehner, S.
                
              
            
          
        
      </div>

      <div class="periodical">
      
      
        2022
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
      <a href="https://ml4physicalsciences.github.io/2022/files/NeurIPS_ML4PS_2022_184.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">url</a>
    
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Predicting properties of the ground state of a given Hamiltonian is an important task central to various fields of science. Recent theoretical results show that for this task learning algorithms enjoy an advantage over non-learning algorithms for a wide range of important Hamiltonians. This work investigates whether the graph structure of these Hamiltonians can be leveraged for the design of sample efficient machine learning models. We demonstrate that corresponding Graph Neural Networks do indeed exhibit superior sample efficiency. Our results provide guidance in the design of machine learning models that learn on experimental data from near-term quantum devices.</p>
    </div>
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">NeurIPS</abbr>
    
  
  </div>

  <div id="pmlr-v220-caggiano23a" class="col-sm-8">
    
      <div class="title">MyoChallenge 2022: Learning contact-rich manipulation using a musculoskeletal hand</div>
      <div class="author">
        
          
            
              
                
                  Caggiano, V.,
                
              
            
          
        
          
            
              
                
                  Durandau, G.,
                
              
            
          
        
          
            
              
                
                  Wang, H.,
                
              
            
          
        
          
            
              
                
                  Chiappa, A.,
                
              
            
          
        
          
            
              
                
                  Mathis, A.,
                
              
            
          
        
          
            
              
                
                  Tano, P.,
                
              
            
          
        
          
            
              
                
                  Patel, N.,
                
              
            
          
        
          
            
              
                
                  Pouget, A.,
                
              
            
          
        
          
            
              
                
                  Schumacher, P.,
                
              
            
          
        
          
            
              
                
                  Martius, G.,
                
              
            
          
        
          
            
              
                
                  Haeufle, D.,
                
              
            
          
        
          
            
              
                
                  Geng, Y.,
                
              
            
          
        
          
            
              
                
                  An, B.,
                
              
            
          
        
          
            
              
                
                  Zhong, Y.,
                
              
            
          
        
          
            
              
                
                  Ji, J.,
                
              
            
          
        
          
            
              
                
                  Chen, Y.,
                
              
            
          
        
          
            
              
                
                  Dong, H.,
                
              
            
          
        
          
            
              
                
                  Yang, Y.,
                
              
            
          
        
          
            
              
                
                  Siripurapu, R.,
                
              
            
          
        
          
            
              
                
                  Ferro Diez, L.,
                
              
            
          
        
          
            
              
                
                  Kopp, M.,
                
              
            
          
        
          
            
              
                
                  Patil, V.,
                
              
            
          
        
          
            
              
                
                  Hochreiter, S.,
                
              
            
          
        
          
            
              
                
                  Tassa, Y.,
                
              
            
          
        
          
            
              
                
                  Merel, J.,
                
              
            
          
        
          
            
              
                
                  Schultheis, R.,
                
              
            
          
        
          
            
              
                
                  Song, S.,
                
              
            
          
        
          
            
              
                
                  Sartori, M.,
                
              
            
          
        
          
            
              
                
                  and Kumar, V.
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>In Proceedings of the NeurIPS 2022 Competitions Track</em>
      
      
        2022
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
      <a href="https://proceedings.mlr.press/v220/caggiano23a.html" class="btn btn-sm z-depth-0" role="button" target="_blank">url</a>
    
    
    
      
      <a href="https://proceedings.mlr.press/v220/caggiano23a/caggiano23a.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Manual dexterity has been considered one of the critical components for human evolution. The ability to perform movements as simple as holding and rotating an object in the hand without dropping it needs the coordination of more than 35 muscles which act synergistically or antagonistically on multiple joints. This complexity in control is markedly different from typical pre-specified movements or torque based controls used in robotics. In the MyoChallenge at the NeurIPS 2022 competition track, we challenged the community to develop controllers for a realistic hand to solve a series of dexterous manipulation tasks. The MyoSuite framework was used to train and test controllers on realistic, contact rich and computation efficient virtual neuromusculoskeletal model of the hand and wrist. Two tasks were proposed: a die re-orientation and a boading ball (rotation of two spheres respect to each other) tasks. More than 40 teams participated to the challenge and submitted more than 340 solutions. The challenge was split in two phases. In the first phase, where a limited set of objectives and randomization were proposed, teams managed to achieve high performance, in particular in the boading-ball task.  In the second phase as the focus shifted towards generalization of task solutions to extensive variations of object and task properties, teams saw significant performance drop. This shows that there is still a large gap in developing agents capable of generalizable skilled manipulation. In future challenges, we will continue pursuing the generalizability both in skills and agility of the tasks exploring additional realistic neuromusculoskeletal models.</p>
    </div>
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">ML4PS</abbr>
    
  
  </div>

  <div id="sanokows2022AVA" class="col-sm-8">
    
      <div class="title">One Network to Approximate Them All: Amortized Variational Inference of Ising Ground States</div>
      <div class="author">
        
          
            
              
                
                  Sanokowski, S.,
                
              
            
          
        
          
            
              
                
                  Berghammer, W.,
                
              
            
          
        
          
            
              
                
                  Johannes, K.,
                
              
            
          
        
          
            
              
                
                  Hochreiter, S.,
                
              
            
          
        
          
            
              
                
                  and Lehner, S.
                
              
            
          
        
      </div>

      <div class="periodical">
      
      
        2022
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
      <a href="https://ml4physicalsciences.github.io/2022/files/NeurIPS_ML4PS_2022_129.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">url</a>
    
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>For a wide range of combinatorial optimization problems, finding the optimal solutions is equivalent to finding the ground states of corresponding Ising Hamiltonians. Recent work shows that these ground states are found more efficiently by variational approaches using autoregressive models than by traditional methods. In contrast to previous works, where for every problem instance a new model has to be trained, we aim at a single model that approximates the ground states for a whole family of Hamiltonians. We demonstrate that autoregregressive neural networks can be trained to achieve this goal and are able to generalize across a class of problems. We iteratively approximate the ground state based on a representation of the Hamiltonian that is provided by a graph neural network. Our experiments show that solving a large number of related problem instances by a single model can be considerably more efficient than solving them individually.</p>
    </div>
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">CoLLAs</abbr>
    
  
  </div>

  <div id="gauch2022subgd" class="col-sm-8">
    
      <div class="title">Few-Shot Learning by Dimensionality Reduction in Gradient Space</div>
      <div class="author">
        
          
            
              
                
                  Gauch, M.,
                
              
            
          
        
          
            
              
                
                  Beck, M.,
                
              
            
          
        
          
            
              
                
                  Adler, T.,
                
              
            
          
        
          
            
              
                
                  Kotsur, D.,
                
              
            
          
        
          
            
              
                
                  Fiel, S.,
                
              
            
          
        
          
            
              
                
                  Eghbal-zadeh, H.,
                
              
            
          
        
          
            
              
                
                  Brandstetter, J.,
                
              
            
          
        
          
            
              
                
                  Kofler, J.,
                
              
            
          
        
          
            
              
                
                  Holzleitner, M.,
                
              
            
          
        
          
            
              
                
                  Zellinger, W.,
                
              
            
          
        
          
            
              
                
                  Klotz, D.,
                
              
            
          
        
          
            
              
                
                  Hochreiter, S.,
                
              
            
          
        
          
            
              
                
                  and Lehner, S.
                
              
            
          
        
      </div>

      <div class="periodical">
      
      
        2022
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
      <a href="https://arxiv.org/abs/2206.03483" class="btn btn-sm z-depth-0" role="button" target="_blank">url</a>
    
    
    
    
    
      <a href="https://ml-jku.github.io/subgd/" class="btn btn-sm z-depth-0" role="button" target="_blank">Blog</a>
    
    
      <a href="https://github.com/ml-jku/subgd" class="btn btn-sm z-depth-0" role="button" target="_blank">Code</a>
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>We introduce SubGD, a novel few-shot learning method which is based on the recent finding that stochastic gradient descent updates tend to live in a low-dimensional parameter subspace. In experimental and theoretical analyses, we show that models confined to a suitable predefined subspace generalize well for few-shot learning. A suitable subspace fulfills three criteria across the given tasks: it (a) allows to reduce the training error by gradient flow, (b) leads to models that generalize well, and (c) can be identified by stochastic gradient descent. SubGD identifies these subspaces from an eigendecomposition of the auto-correlation matrix of update directions across different tasks. Demonstrably, we can identify low-dimensional suitable subspaces for few-shot learning of dynamical systems, which have varying properties described by one or few parameters of the analytical system description. Such systems are ubiquitous among real-world applications in science and engineering. We experimentally corroborate the advantages of SubGD on three distinct dynamical systems problem settings, significantly outperforming popular few-shot learning methods both in terms of sample efficiency and performance.</p>
    </div>
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">ICLR</abbr>
    
  
  </div>

  <div id="hoedt2022normalization" class="col-sm-8">
    
      <div class="title">Normalization is dead, long live normalization!</div>
      <div class="author">
        
          
            
              
                
                  Hoedt, P.,
                
              
            
          
        
          
            
              
                
                  Hochreiter, S.,
                
              
            
          
        
          
            
              
                
                  and Klambauer, G.
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>In ICLR Blog Track</em>
      
      
        2022
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
      <a href="https://iclr-blog-track.github.io/2022/03/25/unnormalized-resnets/" class="btn btn-sm z-depth-0" role="button" target="_blank">url</a>
    
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Since the advent of Batch Normalization (BN), almost every state-of-the-art (SOTA) method uses some form of normalization. After all, normalization generally speeds up learning and leads to models that generalize better than their unnormalized counterparts. This turns out to be especially useful when using some form of skip connections, which are prominent in Residual Networks (ResNets), for example. However, Brock et al. (2021a) suggest that SOTA performance can also be achieved using ResNets without normalization!</p>
    </div>
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">arXiv</abbr>
    
  
  </div>

  <div id="winterTrustedAI2021" class="col-sm-8">
    
      <div class="title">Trusted Artificial Intelligence: Towards Certification of Machine Learning Applications</div>
      <div class="author">
        
          
            
              
                
                  Winter, P.,
                
              
            
          
        
          
            
              
                
                  Eder, S.,
                
              
            
          
        
          
            
              
                
                  Weissenböck, J.,
                
              
            
          
        
          
            
              
                
                  Schwald, C.,
                
              
            
          
        
          
            
              
                
                  Doms, T.,
                
              
            
          
        
          
            
              
                
                  Vogt, T.,
                
              
            
          
        
          
            
              
                
                  Hochreiter, S.,
                
              
            
          
        
          
            
              
                
                  and Nessler, B.
                
              
            
          
        
      </div>

      <div class="periodical">
      
      
        2021
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
      <a href="https://arxiv.org/abs/2103.16910.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">url</a>
    
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Artificial Intelligence is one of the fastest growing technologies of the 21st century and accompanies us in our daily lives when interacting with technical applications. However, reliance on such technical systems is crucial for their widespread applicability and acceptance. The societal tools to express reliance are usually formalized by lawful regulations, i.e., standards, norms, accreditations, and certificates. Therefore, the TÜV AUSTRIA Group in cooperation with the Institute for Machine Learning at the Johannes Kepler University Linz, proposes a certification process and an audit catalog for Machine Learning applications. We are convinced that our approach can serve as the foundation for the certification of applications that use Machine Learning and Deep Learning, the techniques that drive the current revolution in Artificial Intelligence. While certain high-risk areas, such as fully autonomous robots in workspaces shared with humans, are still some time away from certification, we aim to cover low-risk applications with our certification procedure. Our holistic approach attempts to analyze Machine Learning applications from multiple perspectives to evaluate and verify the aspects of secure software development, functional requirements, data quality, data protection, and ethics. Inspired by existing work, we introduce four criticality levels to map the criticality of a Machine Learning application regarding the impact of its decisions on people, environment, and organizations. Currently, the audit catalog can be applied to low-risk applications within the scope of supervised learning as commonly encountered in industry. Guided by field experience, scientific developments, and market demands, the audit catalog will be extended and modified accordingly.</p>
    </div>
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">arXiv</abbr>
    
  
  </div>

  <div id="mayr2021_l3dgfs" class="col-sm-8">
    
      <div class="title">Learning 3D Granular Flow Simulations</div>
      <div class="author">
        
          
            
              
                
                  Mayr, A.,
                
              
            
          
        
          
            
              
                
                  Lehner, S.,
                
              
            
          
        
          
            
              
                
                  Mayrhofer, A.,
                
              
            
          
        
          
            
              
                
                  Kloss, C.,
                
              
            
          
        
          
            
              
                
                  Hochreiter, S.,
                
              
            
          
        
          
            
              
                
                  and Brandstetter, J.
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em></em>
      
      
        2021
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
      <a href="https://arxiv.org/abs/2105.01636" class="btn btn-sm z-depth-0" role="button" target="_blank">url</a>
    
    
    
    
    
    
    
      
      <a href="https://simdl.github.io/posters/42-supp_poster.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">Poster</a>
      
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Recently, the application of machine learning models has gained momentum in natural sciences and engineering, which is a natural fit due to the abundance of data in these fields. However, the modeling of physical processes from simulation data without first principle solutions remains difficult. Here, we present a Graph Neural Networks approach towards accurate modeling of complex 3D granular flow simulation processes created by the discrete element method LIGGGHTS and concentrate on simulations of physical systems found in real world applications like rotating drums and hoppers. We discuss how to implement Graph Neural Networks that deal with 3D objects, boundary conditions, particle - particle, and particle - boundary interactions such that an accurate modeling of relevant physical quantities is made possible. Finally, we compare the machine learning based trajectories to LIGGGHTS trajectories in terms of particle flows and mixing entropies.</p>
    </div>
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">ICML</abbr>
    
  
  </div>

  <div id="hoedtMCLSTM2021" class="col-sm-8">
    
      <div class="title">MC-LSTM: Mass-Conserving LSTM</div>
      <div class="author">
        
          
            
              
                
                  Hoedt, P.,
                
              
            
          
        
          
            
              
                
                  Kratzert, F.,
                
              
            
          
        
          
            
              
                
                  Klotz, D.,
                
              
            
          
        
          
            
              
                
                  Halmich, C.,
                
              
            
          
        
          
            
              
                
                  Holzleitner, M.,
                
              
            
          
        
          
            
              
                
                  Nearing, G.,
                
              
            
          
        
          
            
              
                
                  Hochreiter, S.,
                
              
            
          
        
          
            
              
                
                  and Klambauer, G.
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>In Proceedings of the 38th International Conference on Machine Learning</em>
      
      
        2021
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
      <a href="https://proceedings.mlr.press/v139/hoedt21a.html" class="btn btn-sm z-depth-0" role="button" target="_blank">url</a>
    
    
    
      
      <a href="https://proceedings.mlr.press/v139/hoedt21a/hoedt21a.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
      <a href="https://github.com/ml-jku/mc-lstm" class="btn btn-sm z-depth-0" role="button" target="_blank">Code</a>
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>The success of Convolutional Neural Networks (CNNs) in computer vision is mainly driven by their strong inductive bias, which is strong enough to allow CNNs to solve vision-related tasks with random weights, meaning without learning. Similarly, Long Short-Term Memory (LSTM) has a strong inductive bias towards storing information over time. However, many real-world systems are governed by conservation laws, which lead to the redistribution of particular quantities – e.g. in physical and economical systems. Our novel Mass-Conserving LSTM (MC-LSTM) adheres to these conservation laws by extending the inductive bias of LSTM to model the redistribution of those stored quantities. MC-LSTMs set a new state-of-the-art for neural arithmetic units at learning arithmetic operations, such as addition tasks, which have a strong conservation law, as the sum is constant over time. Further, MC-LSTM is applied to traffic forecasting, modelling a pendulum, and a large benchmark dataset in hydrology, where it sets a new state-of-the-art for predicting peak flows. In the hydrology example, we show that MC-LSTM states correlate with real-world processes and are therefore interpretable.</p>
    </div>
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">bioarXiv</abbr>
    
  
  </div>

  <div id="widrichDeepRCImmuneRepertoire2020" class="col-sm-8">
    
      <div class="title">DeepRC: Immune Repertoire Classification with Attention-Based Deep Massive Multiple Instance Learning</div>
      <div class="author">
        
          
            
              
                
                  Widrich, M.,
                
              
            
          
        
          
            
              
                
                  Schäfl, B.,
                
              
            
          
        
          
            
              
                
                  Pavlović, M.,
                
              
            
          
        
          
            
              
                
                  Sandve, G.,
                
              
            
          
        
          
            
              
                
                  Hochreiter, S.,
                
              
            
          
        
          
            
              
                
                  Greiff, V.,
                
              
            
          
        
          
            
              
                
                  and Klambauer, G.
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em></em>
      
      
        2020
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
      <a href="https://doi.org/10.1101/2020.04.12.038158" class="btn btn-sm z-depth-0" role="button" target="_blank">url</a>
    
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p><h3>Abstract</h3> <p>High-throughput immunosequencing allows reconstructing the immune repertoire of an individual, which is a unique opportunity for new immunotherapies, immunodiagnostics, and vaccine design. Since immune repertoires are shaped by past and current immune events, such as infection and disease, and thus record an individual’s state of health, immune repertoire sequencing data may enable the prediction of health and disease using machine learning. However, finding the connections between an individual’s repertoire and the individual’s disease class, with potentially hundreds of thousands to millions of short sequences per individual, poses a difficult and unique challenge for machine learning methods. In this work, we present our method DeepRC that combines a Deep Learning architecture with attentionbased multiple instance learning. To validate that DeepRC accurately predicts an individual’s disease class based on its immune repertoire and determines the associated class-specific sequence motifs, we applied DeepRC in four large-scale experiments encompassing ground-truth simulated as well as real-world virus infection data. We demonstrate that DeepRC outperforms all tested methods with respect to predictive performance and enables the extraction of those sequence motifs that are connected to a given disease class.</p></p>
    </div>
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">arXiv</abbr>
    
  
  </div>

  <div id="adler2020cross" class="col-sm-8">
    
      <div class="title">Cross-Domain Few-Shot Learning by Representation Fusion</div>
      <div class="author">
        
          
            
              
                
                  Adler, T.,
                
              
            
          
        
          
            
              
                
                  Brandstetter, J.,
                
              
            
          
        
          
            
              
                
                  Widrich, M.,
                
              
            
          
        
          
            
              
                
                  Mayr, A.,
                
              
            
          
        
          
            
              
                
                  Kreil, D.,
                
              
            
          
        
          
            
              
                
                  Kopp, M.,
                
              
            
          
        
          
            
              
                
                  Klambauer, G.,
                
              
            
          
        
          
            
              
                
                  and Hochreiter, S.
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>arXiv preprint arXiv:2010.06498</em>
      
      
        2020
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
      <a href="https://arxiv.org/abs/2010.06498" class="btn btn-sm z-depth-0" role="button" target="_blank">url</a>
    
    
    
    
    
      <a href="https://ml-jku.github.io/chef/" class="btn btn-sm z-depth-0" role="button" target="_blank">Blog</a>
    
    
      <a href="https://github.com/ml-jku/chef" class="btn btn-sm z-depth-0" role="button" target="_blank">Code</a>
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>In order to quickly adapt to new data, few-shot learning aims at learning from few examples, often by using already acquired knowledge. The new data often differs from the previously seen data due to a domain shift, that is, a change of the input-target distribution. While several methods perform well on small domain shifts like new target classes with similar inputs, larger domain shifts are still challenging. Large domain shifts may result in high-level concepts that are not shared between the original and the new domain. However, low-level concepts like edges in images might still be shared and useful. For cross-domain few-shot learning, we suggest representation fusion to unify different abstraction levels of a deep neural network into one representation. We propose Cross-domain Hebbian Ensemble Few-shot learning (CHEF), which achieves representation fusion by an ensemble of Hebbian learners acting on different layers of a deep neural network that was trained on the original domain. On the few-shot datasets miniImagenet and tieredImagenet, where the domain shift is small, CHEF is competitive with state-of-the-art methods. On cross-domain few-shot benchmark challenges with larger domain shifts, CHEF establishes novel state-of-the-art results in all categories. We further apply CHEF on a real-world cross-domain application in drug discovery. We consider a domain shift from bioactive molecules to environmental chemicals and drugs with twelve associated toxicity prediction tasks. On these tasks, that are highly relevant for computational drug discovery, CHEF significantly outperforms all its competitors.</p>
    </div>
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
  </div>

  <div id="sewardFirstOrderGenerative2018" class="col-sm-8">
    
      <div class="title">First Order Generative Adversarial Networks</div>
      <div class="author">
        
          
            
              
                
                  Seward, C.,
                
              
            
          
        
          
            
              
                
                  Unterthiner, T.,
                
              
            
          
        
          
            
              
                
                  Bergmann, U.,
                
              
            
          
        
          
            
              
                
                  Jetchev, N.,
                
              
            
          
        
          
            
              
                
                  and Hochreiter, S.
                
              
            
          
        
      </div>

      <div class="periodical">
      
      
        2018
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
      <a href="http://arxiv.org/abs/1802.04591" class="btn btn-sm z-depth-0" role="button" target="_blank">url</a>
    
    
    
      
      <a href="https://arxiv.org/pdf/1802.04591.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>GANs excel at learning high dimensional distributions, but they can update generator parameters in directions that do not correspond to the steepest descent direction of the objective. Prominent examples of problematic update directions include those used in both Goodfellow’s original GAN and the WGAN-GP. To formally describe an optimal update direction, we introduce a theoretical framework which allows the derivation of requirements on both the divergence and corresponding method for determining an update direction, with these requirements guaranteeing unbiased mini-batch updates in the direction of steepest descent. We propose a novel divergence which approximates the Wasserstein distance while regularizing the critic’s first order information. Together with an accompanying update direction, this divergence fulfills the requirements for unbiased steepest descent updates. We verify our method, the First Order GAN, with image generation on CelebA, LSUN and CIFAR-10 and set a new state of the art on the One Billion Word language generation task. Code to reproduce experiments is available.</p>
    </div>
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
  </div>

  <div id="unterthinerCoulombGANsProvably2018" class="col-sm-8">
    
      <div class="title">Coulomb GANs: Provably Optimal Nash Equilibria via Potential Fields</div>
      <div class="author">
        
          
            
              
                
                  Unterthiner, T.,
                
              
            
          
        
          
            
              
                
                  Nessler, B.,
                
              
            
          
        
          
            
              
                
                  Seward, C.,
                
              
            
          
        
          
            
              
                
                  Klambauer, G.,
                
              
            
          
        
          
            
              
                
                  Heusel, M.,
                
              
            
          
        
          
            
              
                
                  Ramsauer, H.,
                
              
            
          
        
          
            
              
                
                  and Hochreiter, S.
                
              
            
          
        
      </div>

      <div class="periodical">
      
      
        2018
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
      <a href="http://arxiv.org/abs/1708.08819" class="btn btn-sm z-depth-0" role="button" target="_blank">url</a>
    
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Generative adversarial networks (GANs) evolved into one of the most successful unsupervised techniques for generating realistic images. Even though it has recently been shown that GAN training converges, GAN models often end up in local Nash equilibria that are associated with mode collapse or otherwise fail to model the target distribution. We introduce Coulomb GANs, which pose the GAN learning problem as a potential field of charged particles, where generated samples are attracted to training set samples but repel each other. The discriminator learns a potential field while the generator decreases the energy by moving its samples along the vector (force) field determined by the gradient of the potential field. Through decreasing the energy, the GAN model learns to generate samples according to the whole target distribution and does not only cover some of its modes. We prove that Coulomb GANs possess only one Nash equilibrium which is optimal in the sense that the model distribution equals the target distribution. We show the efficacy of Coulomb GANs on a variety of image datasets. On LSUN and celebA, Coulomb GANs set a new state of the art and produce a previously unseen variety of different samples.</p>
    </div>
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">NeurIPS</abbr>
    
  
  </div>

  <div id="klambauerSelfNormalizingNeuralNetworks2017" class="col-sm-8">
    
      <div class="title">Self-Normalizing Neural Networks</div>
      <div class="author">
        
          
            
              
                
                  Klambauer, G.,
                
              
            
          
        
          
            
              
                
                  Unterthiner, T.,
                
              
            
          
        
          
            
              
                
                  Mayr, A.,
                
              
            
          
        
          
            
              
                
                  and Hochreiter, S.
                
              
            
          
        
      </div>

      <div class="periodical">
      
      
        2017
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
      <a href="http://arxiv.org/abs/1706.02515" class="btn btn-sm z-depth-0" role="button" target="_blank">url</a>
    
    
    
      
      <a href="https://arxiv.org/pdf/1706.02515.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Deep Learning has revolutionized vision via convolutional neural networks (CNNs) and natural language processing via recurrent neural networks (RNNs). However, success stories of Deep Learning with standard feed-forward neural networks (FNNs) are rare. FNNs that perform well are typically shallow and, therefore cannot exploit many levels of abstract representations. We introduce self-normalizing neural networks (SNNs) to enable high-level abstract representations. While batch normalization requires explicit normalization, neuron activations of SNNs automatically converge towards zero mean and unit variance. The activation function of SNNs are "scaled exponential linear units" (SELUs), which induce self-normalizing properties. Using the Banach fixed-point theorem, we prove that activations close to zero mean and unit variance that are propagated through many network layers will converge towards zero mean and unit variance – even under the presence of noise and perturbations. This convergence property of SNNs allows to (1) train deep networks with many layers, (2) employ strong regularization, and (3) to make learning highly robust. Furthermore, for activations not close to unit variance, we prove an upper and lower bound on the variance, thus, vanishing and exploding gradients are impossible. We compared SNNs on (a) 121 tasks from the UCI machine learning repository, on (b) drug discovery benchmarks, and on (c) astronomy tasks with standard FNNs and other machine learning methods such as random forests and support vector machines. SNNs significantly outperformed all competing FNN methods at 121 UCI tasks, outperformed all competing methods at the Tox21 dataset, and set a new record at an astronomy data set. The winning SNN architectures are often very deep. Implementations are available at: github.com/bioinf-jku/SNNs.</p>
    </div>
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
  </div>

  <div id="heuselGANsTrainedTwo2017" class="col-sm-8">
    
      <div class="title">GANs Trained by a Two Time-Scale Update Rule Converge to a Local Nash Equilibrium</div>
      <div class="author">
        
          
            
              
                
                  Heusel, M.,
                
              
            
          
        
          
            
              
                
                  Ramsauer, H.,
                
              
            
          
        
          
            
              
                
                  Unterthiner, T.,
                
              
            
          
        
          
            
              
                
                  Nessler, B.,
                
              
            
          
        
          
            
              
                
                  and Hochreiter, S.
                
              
            
          
        
      </div>

      <div class="periodical">
      
      
        2017
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
      <a href="http://arxiv.org/abs/1706.08500" class="btn btn-sm z-depth-0" role="button" target="_blank">url</a>
    
    
    
      
      <a href="https://arxiv.org/pdf/1706.08500.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Generative Adversarial Networks (GANs) excel at creating realistic images with complex models for which maximum likelihood is infeasible. However, the convergence of GAN training has still not been proved. We propose a two time-scale update rule (TTUR) for training GANs with stochastic gradient descent on arbitrary GAN loss functions. TTUR has an individual learning rate for both the discriminator and the generator. Using the theory of stochastic approximation, we prove that the TTUR converges under mild assumptions to a stationary local Nash equilibrium. The convergence carries over to the popular Adam optimization, for which we prove that it follows the dynamics of a heavy ball with friction and thus prefers flat minima in the objective landscape. For the evaluation of the performance of GANs at image generation, we introduce the "Fr\’echet Inception Distance" (FID) which captures the similarity of generated images to real ones better than the Inception Score. In experiments, TTUR improves learning for DCGANs and Improved Wasserstein GANs (WGAN-GP) outperforming conventional GAN training on CelebA, CIFAR-10, SVHN, LSUN Bedrooms, and the One Billion Word Benchmark.</p>
    </div>
    
  </div>
</div>
</li></ol>
</div>
</div>

  </div>
  </article>

</div>

    </div>

    <!-- Footer -->

    
<footer class="fixed-bottom">
  <div class="container mt-0">
    &copy; Copyright 2025 Institute for Machine Learning @ JKU.
    Powered by <a href="http://jekyllrb.com/" target="_blank">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank">GitHub Pages</a>.

    
  </div>
</footer>



  </body>

  <!-- jQuery -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script>

  <!-- Bootsrap & MDB scripts -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/2.4.4/umd/popper.min.js" integrity="sha512-eUQ9hGdLjBjY3F41CScH3UX+4JDSI9zXeroz7hJ+RteoCaY+GP/LDoM8AO+Pt+DRFw3nXqsjh9Zsts8hnYv8/A==" crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/js/bootstrap.min.js" integrity="sha512-M5KW3ztuIICmVIhjSqXe01oV2bpe248gOxqmlcYrEzAvws7Pw3z6BK0iGbrwvdrUQUhi3eXgtxp5I8PDo9YfjQ==" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.19.1/js/mdb.min.js" integrity="sha512-Mug9KHKmroQFMLm93zGrjhibM2z2Obg9l6qFG2qKjXEXkMp/VDkI4uju9m4QKPjWSwQ6O2qzZEnJDEeCw0Blcw==" crossorigin="anonymous"></script>

  
<!-- Mansory & imagesLoaded -->
<script defer src="https://unpkg.com/masonry-layout@4/dist/masonry.pkgd.min.js"></script>
<script defer src="https://unpkg.com/imagesloaded@4/imagesloaded.pkgd.min.js"></script>
<script defer src="/assets/js/mansory.js" type="text/javascript"></script>


  


<!-- Load Common JS -->
<script src="/assets/js/common.js"></script>

<!-- Load DarkMode JS -->
<script src="/assets/js/dark_mode.js"></script>


</html>
