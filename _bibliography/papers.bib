@misc{schaefl2022hopular,
      title={Hopular: Modern Hopfield Networks for Tabular Data}, 
      author={Bernhard Sch{\"a}fl and Lukas Gruber and Angela Bitto-Nemling and Sepp Hochreiter},
      abstract={While Deep Learning excels in structured data as encountered in vision and natural language processing, it failed to meet its expectations on tabular data. For tabular data, Support Vector Machines (SVMs), Random Forests, and Gradient Boosting are the best performing techniques with Gradient Boosting in the lead. Recently, we saw a surge of Deep Learning methods that were tailored to tabular data but still underperform compared to Gradient Boosting on small-sized datasets. We suggest "Hopular", a novel Deep Learning architecture for medium- and small-sized datasets, where each layer is equipped with continuous modern Hopfield networks. The modern Hopfield networks use stored data to identify feature-feature, feature-target, and sample-sample dependencies. Hopular's novelty is that every layer can directly access the original input as well as the whole training set via stored data in the Hopfield networks. Therefore, Hopular can step-wise update its current model and the resulting prediction at every layer like standard iterative learning algorithms. In experiments on small-sized tabular datasets with less than 1,000 samples, Hopular surpasses Gradient Boosting, Random Forests, SVMs, and in particular several Deep Learning methods. In experiments on medium-sized tabular data with about 10,000 samples, Hopular outperforms XGBoost, CatBoost, LightGBM and a state-of-the art Deep Learning method designed for tabular data. Thus, Hopular is a strong alternative to these methods on tabular data.},
      year={2022},
      eprint={2206.00664},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      abbr={arXiv},
      blog={https://ml-jku.github.io/hopular/},
      url={https://arxiv.org/abs/2206.00664},
      code={https://github.com/ml-jku/hopular},
      category={hopfield},
      software={true},
      selected={true},     
      date={2022-06-01}
}


@misc{gauch2022subgd,
    title={Few-Shot Learning by Dimensionality Reduction in Gradient Space},
    author={Gauch, Martin and Beck, Maximilian and Adler, Thomas and Kotsur, Dmytro and Fiel, Stefan and Eghbal-zadeh, Hamid and Brandstetter, Johannes and Kofler, Johannes and Holzleitner, Markus and Zellinger, Werner and Klotz, Daniel and Hochreiter, Sepp and Lehner, Sebastian},
    abstract = {We introduce SubGD, a novel few-shot learning method which is based on the recent finding that stochastic gradient descent updates tend to live in a low-dimensional parameter subspace. In experimental and theoretical analyses, we show that models confined to a suitable predefined subspace generalize well for few-shot learning. A suitable subspace fulfills three criteria across the given tasks: it (a) allows to reduce the training error by gradient flow, (b) leads to models that generalize well, and (c) can be identified by stochastic gradient descent. SubGD identifies these subspaces from an eigendecomposition of the auto-correlation matrix of update directions across different tasks. Demonstrably, we can identify low-dimensional suitable subspaces for few-shot learning of dynamical systems, which have varying properties described by one or few parameters of the analytical system description. Such systems are ubiquitous among real-world applications in science and engineering. We experimentally corroborate the advantages of SubGD on three distinct dynamical systems problem settings, significantly outperforming popular few-shot learning methods both in terms of sample efficiency and performance.},
      year={2022},
      eprint={2206.03483},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      abbr={CoLLAs},
      blog={https://ml-jku.github.io/subgd/},
      url = {https://arxiv.org/abs/2206.03483},
      code = {https://github.com/ml-jku/subgd},
      category = {deep_learning},
      software = {true},
      selected = {true},
      date = {2022-06-08}
}


@inproceedings{paischer2022helm,
  doi = {10.48550/ARXIV.2205.12258},
  url = {https://arxiv.org/abs/2205.12258},
  author = {Paischer, Fabian and Adler, Thomas and Patil, Vihang and Bitto-Nemling, Angela and Holzleitner, Markus and Lehner, Sebastian and Eghbal-zadeh, Hamid and Hochreiter, Sepp},
  keywords = {Machine Learning (cs.LG), Computation and Language (cs.CL), Machine Learning (stat.ML), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {History Compression via Language Models in Reinforcement Learning},
  abbr = {ICML},
  year = {2022},
  blog = {https://ml-jku.github.io/blog/2022/helm/},
  code = {https://github.com/ml-jku/helm},
  software = {True},
  category = {reinforcement_learning},
  selected = {true},
  date = {2022-05-24},
  abstract = {In a partially observable Markov decision process (POMDP), an agent typically uses a representation of the past to approximate the underlying MDP. We propose to utilize a frozen Pretrained Language Transformer (PLT) for history representation and compression to improve sample efficiency. To avoid training of the Transformer, we introduce FrozenHopfield, which automatically associates observations with original token embeddings. To form these associations, a modern Hopfield network stores the original token embeddings, which are retrieved by queries that are obtained by a random but fixed projection of observations. Our new method, HELM, enables actor-critic network architectures that contain a pretrained language Transformer for history representation as a memory module. Since a representation of the past need not be learned, HELM is much more sample efficient than competitors. On Minigrid and Procgen environments HELM achieves new state-of-the-art results. Our code is available at https://github.com/ml-jku/helm.}
}


@article{seidlImproving2022,
author = {Seidl, Philipp and Renz, Philipp and Dyubankova, Natalia and Neves, Paulo and Verhoeven, Jonas and Wegner, Jörg K. and Segler, Marwin and Hochreiter, Sepp and Klambauer, Günter},
title = {Improving Few- and Zero-Shot Reaction Template Prediction Using Modern Hopfield Networks},
journal = {Journal of Chemical Information and Modeling},
volume = {0},
number = {0},
pages = {null},
year = {2022},
doi = {10.1021/acs.jcim.1c01065},
    note ={PMID: 35034452},
url = {https://doi.org/10.1021/acs.jcim.1c01065},
eprint = {https://doi.org/10.1021/acs.jcim.1c01065},
abstract = {Finding synthesis routes for molecules of interest is essential in the discovery of new drugs and materials. To find such routes, computer-assisted synthesis planning (CASP) methods are employed, which rely on a single-step model of chemical reactivity. In this study, we introduce a template-based single-step retrosynthesis model based on Modern Hopfield Networks, which learn an encoding of both molecules and reaction templates in order to predict the relevance of templates for a given molecule. The template representation allows generalization across different reactions and significantly improves the performance of template relevance prediction, especially for templates with few or zero training examples. With inference speed up to orders of magnitude faster than baseline methods, we improve or match the state-of-the-art performance for top-k exact match accuracy for k ≥ 3 in the retrosynthesis benchmark USPTO-50k. Code to reproduce the results is available at github.com/ml-jku/mhn-react.},
software = {true},
code = {https://github.com/ml-jku/mhn-react},
abbr={JCIM},
category = {ai_drug},
selected = {true},
date = {2022-01-15},
}

@inproceedings{seidlBenchmarking2021,
author = {Seidl, Philipp and Halmich, Christina and Mayr, Andreas and Vall, Andreu and Ruch, Peter and Hochreiter, Sepp and Klambauer, Günter},
title = {Benchmarking recent Deep Learning methods on the extended Tox21 data set},
journal = {19th International Workshop on (Quantitative) Structure-Activity Relationships in Environmental and Health Sciences},
volume = {19},
number = {Abstract nr 293},
publisher = {Computational Toxicology},
abstract = {The Tox21 data set has evolved into a standard benchmark for computational QSAR methods in toxicology. One limitation of the Tox21 data set is, however, that it only contains twelve toxic assays which strongly restricts its power to distinguish the strength of computational methods. We ameliorate this problem by benchmarking on the extended Tox21 dataset with 68 publicly available assays in order to allow for a better assessment and characterization. The broader range of assays also allows for multi-task approaches, which have been particularly successful as predictive models. Furthermore, previous publications comparing methods on Tox21 did not include recent developments in the field of machine learning, such as graph neural and modern Hopfield networks. Thus we benchmark a set of prominent machine learning methods including those new types of neural networks. The results of the benchmarking study show that the best methods are modern Hopfield networks and multi-task graph neural networks with an average area-under-ROCcurve of 0.91 ± 0.05 (standard deviation across assays), while traditional methods, such as Random Forests fall behind by a substantial margin. Our results of the full benchmark suggest that multi-task learning has a stronger effect on the predictive performance than the choice of the representation of the molecules, such as graph, descriptors, or fingerprints.},
year = {2021},
date = {2021-06-07},
url = {https://www.ascctox.org/sites/default/files/QSAR%202021%20Program.pdf},
abbr = {QSAR},
software = {false},
category = {ai_drug},
selected = {false},
}


@inproceedings{
widrich2021modern,
title={Modern Hopfield Networks for Return Decomposition for Delayed Rewards},
abstract={Delayed rewards, which are separated from their causative actions by irrelevant actions, hamper learning in reinforcement learning (RL). Especially real world problems often contain such delayed and sparse rewards. Recently, return decomposition for delayed rewards (RUDDER) employed pattern recognition to remove or reduce delay in rewards, which dramatically simplifies the learning task of the underlying RL method. RUDDER was realized using a long short-term memory (LSTM). The LSTM was trained to identify important state-action pair patterns, responsible for the return. Reward was then redistributed to these important state-action pairs. However, training the LSTM is often difficult and requires a large number of episodes. In this work, we replace the LSTM with the recently proposed continuous modern Hopfield networks (MHN) and introduce Hopfield-RUDDER. MHN are powerful trainable associative memories with large storage capacity. They require only few training samples and excel at identifying and recognizing patterns. We use this property of MHN to identify important state-action pairs that are associated with low or high return episodes and directly redistribute reward to them. However, in partially observable environments, Hopfield-RUDDER requires additional information about the history of state-action pairs. Therefore, we evaluate several methods for compressing history and introduce reset-max history, a lightweight history compression using the max-operator in combination with a reset gate. We experimentally show that Hopfield-RUDDER is able to outperform LSTM-based RUDDER on various 1D environments with small numbers of episodes. Finally, we show in preliminary experiments that Hopfield-RUDDER scales to highly complex environments with the Minecraft ObtainDiamond task from the MineRL NeurIPS challenge.},
author={Michael Widrich and Markus Hofmarcher and Vihang Prakash Patil and Angela Bitto-Nemling and Sepp Hochreiter},
booktitle={Deep RL Workshop NeurIPS 2021},
year={2021},
url={https://openreview.net/forum?id=t0PQSDcqAiy},
category={reinforcement_learning},
selected={true},
date={2021-12-09}
}

@misc{schweighofer:21,
      title={Understanding the Effects of Dataset Characteristics on Offline Reinforcement Learning}, 
      author={Kajetan Schweighofer and Markus Hofmarcher and Marius-Constantin Dinu and Philipp Renz and Angela Bitto-Nemling and Vihang Patil and Sepp Hochreiter},
      abstract={In real world, affecting the environment by a weak policy can be expensive or very risky, therefore hampers real world applications of reinforcement learning. Offline Reinforcement Learning (RL) can learn policies from a given dataset without interacting with the environment. However, the dataset is the only source of information for an Offline RL algorithm and determines the performance of the learned policy. We still lack studies on how dataset characteristics influence different Offline RL algorithms. Therefore, we conducted a comprehensive empirical analysis of how dataset characteristics effect the performance of Offline RL algorithms for discrete action environments. A dataset is characterized by two metrics: (1) the average dataset return measured by the Trajectory Quality (TQ) and (2) the coverage measured by the State-Action Coverage (SACo). We found that variants of the off-policy Deep Q-Network family require datasets with high SACo to perform well. Algorithms that constrain the learned policy towards the given dataset perform well for datasets with high TQ or SACo. For datasets with high TQ, Behavior Cloning outperforms or performs similarly to the best Offline RL algorithms.
},
      year={2021},
      eprint={2111.04714},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      abbr={arXiv},
      url = {https://arxiv.org/abs/2111.04714},
      code = {https://github.com/ml-jku/OfflineRL},
      category = {reinforcement_learning},
      software = {true},
      selected = {true},
      date = {2021-11-09}
}

@misc{fürst2021cloob,
      title={CLOOB: Modern Hopfield Networks with InfoLOOB Outperform CLIP}, 
      author={Andreas Fürst and Elisabeth Rumetshofer and Viet Tran and Hubert Ramsauer and Fei Tang and Johannes Lehner and David Kreil and Michael Kopp and Günter Klambauer and Angela Bitto-Nemling and Sepp Hochreiter},
      abstract = {Contrastive learning with the InfoNCE objective is exceptionally successful in various self-supervised learning tasks. Recently, the CLIP model yielded impressive results on zero-shot transfer learning when using InfoNCE for learning visual representations from natural language supervision. However, InfoNCE as a lower bound on the mutual information has been shown to perform poorly for high mutual information. In contrast, the InfoLOOB upper bound (leave one out bound) works well for high mutual information but suffers from large variance and instabilities. We introduce "Contrastive Leave One Out Boost" (CLOOB), where modern Hopfield networks boost learning with the InfoLOOB objective. Modern Hopfield networks replace the original embeddings by retrieved embeddings in the InfoLOOB objective. The retrieved embeddings give InfoLOOB two assets. Firstly, the retrieved embeddings stabilize InfoLOOB, since they are less noisy and more similar to one another than the original embeddings. Secondly, they are enriched by correlations, since the covariance structure of embeddings is reinforced through retrievals. We compare CLOOB to CLIP after learning on the Conceptual Captions and the YFCC dataset with respect to their zero-shot transfer learning performance on other datasets. CLOOB consistently outperforms CLIP at zero-shot transfer learning across all considered architectures and datasets.
},
      year={2021},
      eprint={2110.11316},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      abbr={arXiv},
      blog={https://ml-jku.github.io/cloob/},
      url = {https://arxiv.org/abs/2110.11316},
      code = {https://github.com/ml-jku/cloob},
      category = {hopfield},
      software = {true},
      selected = {true},
      date = {2021-10-22}
}

@article{mayr2021_l3dgfs,
abbr={arXiv},
title={Learning 3D Granular Flow Simulations},
author={Mayr, Andreas and Lehner, Sebastian and Mayrhofer, Arno and Kloss, Christoph and Hochreiter, Sepp and Brandstetter, Johannes},
abstract = {Recently, the application of machine learning models has gained momentum in natural sciences and engineering, which is a natural fit due to the abundance of data in these fields. However, the modeling of physical processes from simulation data without first principle solutions remains difficult. Here, we present a Graph Neural Networks approach towards accurate modeling of complex 3D granular flow simulation processes created by the discrete element method LIGGGHTS and concentrate on simulations of physical systems found in real world applications like rotating drums and hoppers. We discuss how to implement Graph Neural Networks that deal with 3D objects, boundary conditions, particle - particle, and particle - boundary interactions such that an accurate modeling of relevant physical quantities is made possible. Finally, we compare the machine learning based trajectories to LIGGGHTS trajectories in terms of particle flows and mixing entropies.},
booktitle = {Deep Learning for Simulation (SimDL) Workshop @ ICLR 2021},
url = {https://arxiv.org/abs/2105.01636},
poster = {https://simdl.github.io/posters/42-supp_poster.pdf},
video = {https://slideslive.de/38955315/learning-3d-granular-flow-simulations?ref=speaker-10792-latest},
selected = {true},
year = {2021},
software = {false},
category={deep_learning},
date = {2021-05-04}
}

@article{klotz2021uncertainty,
  title={Uncertainty Estimation with Deep Learning for Rainfall-Runoff Modelling},
  author={Klotz, D. and Kratzert, F. and Gauch, M. and Keefe Sampson, A. and Brandstetter, J. and Klambauer, G. and Hochreiter, S. and Nearing, G.},
  abstract = {Deep Learning is becoming an increasingly important way to produce accurate hydrological predictions across a wide range of spatial and temporal scales. Uncertainty estimations are critical for actionable hydrological forecasting, and while standardized community benchmarks are becoming an increasingly important part of hydrological model development and research, similar tools for benchmarking uncertainty estimation are lacking. This contributions demonstrates that accurate uncertainty predictions can be obtained with Deep Learning. We establish an uncertainty estimation benchmarking procedure and present four Deep Learning baselines. Three baselines are based on Mixture Density Networks and one is based on Monte Carlo dropout. The results indicate that these approaches constitute strong baselines, especially the former ones. Additionaly, we provide a post-hoc model analysis to put forward some qualitative understanding of the resulting models. This analysis extends the notion of performance and show that learn nuanced behaviors in different situations.},
    journal = {Hydrology and Earth System Sciences Discussions},
    abbr = {HESSD},
    url = {https://hess.copernicus.org/preprints/hess-2021-154/},
    year = {2021},
    selected = {true},
    software = {false},
    code = {https://github.com/neuralhydrology/neuralhydrology},
    category = {ai4earth},
    date = {2021-04-14}
}

@article{kratzert2021synergy,
    author = {Kratzert, F. and Klotz, D. and Hochreiter, S. and Nearing, G. S.},
    title = {A note on leveraging synergy in multiple meteorological datasets with deep learning for rainfall-runoff modeling},
    abstract = {A deep learning rainfall-runoff model can take multiple meteorological forcing products as inputs and learn to combine them in spatially and temporally dynamic ways. This is demonstrated using Long Short Term Memory networks (LSTMs) trained over basins in the continental US using the CAMELS data set. Using multiple precipitation products (NLDAS, Maurer, DayMet) in a single LSTM significantly improved simulation accuracy relative to using only individual precipitation products. A sensitivity analysis showed that the LSTM learned to utilize different precipitation products in different ways in different basins and for simulating different parts of the hydrograph in individual basins.},
    journal = {Hydrology and Earth System Sciences},
    abbr = {HESS},
    url = {https://hess.copernicus.org/preprints/hess-2020-221/},
    year = {2021},
    selected = {true},
    software = {false},
    code = {https://github.com/kratzert/multiple_forcing},
    category = {ai4earth},
    date = {2020-11-13}
}

@article{nearing2021opinion,
    author = {Nearing, G. and Kratzert, F. and Sampson, A. and Pelissier, C. and Klotz, D. and Frame, J. and Prieto, C. and Gupta, H.},
    title = {What Role Does Hydrological Science Play in the Age of Machine Learning?},
    abstract = {This paper is derived from a keynote talk given at the Google's 2020 Flood Forecasting Meets Machine Learning Workshop. Recent experiments applying deep learning to rainfall-runoff simulation indicate that there is significantly more information in large-scale hydrological data sets than hydrologists have been able to translate into theory or models. While there is a growing interest in machine learning in the hydrological sciences community, in many ways, our community still holds deeply subjective and nonevidence-based preferences for models based on a certain type of “process understanding” that has historically not translated into accurate theory, models, or predictions. This commentary is a call to action for the hydrology community to focus on developing a quantitative understanding of where and when hydrological process understanding is valuable in a modeling discipline increasingly dominated by machine learning. We offer some potential perspectives and preliminary examples about how this might be accomplished.},
    journal = {Water Resources Research},
    abbr = {WRR},
    url = {https://agupubs.onlinelibrary.wiley.com/doi/10.1029/2020WR028091},
    year = {2020},
    selected = {true},
    software = {false},
    category = {ai4earth},
    date = {2020-11-13}
}

@article{gauch2021mtslstm,
    author = {Gauch, M. and Kratzert, F. and Klotz, D. and Nearing, G. and Lin, J. and Hochreiter, S.},
    title = {Rainfall--runoff prediction at multiple timescales with a single Long Short-Term Memory network},
    abstract = {Long Short-Term Memory (LSTM) networks have been applied to daily discharge prediction with remarkable success. Many practical applications, however, require predictions at more granular timescales. For instance, accurate prediction of short but extreme flood peaks can make a lifesaving difference, yet such peaks may escape the coarse temporal resolution of daily predictions. Naively training an LSTM on hourly data, however, entails very long input sequences that make learning difficult and computationally expensive. In this study, we propose two multi-timescale LSTM (MTS-LSTM) architectures that jointly predict multiple timescales within one model, as they process long-past inputs at a different temporal resolution than more recent inputs. In a benchmark on 516 basins across the continental United States, these models achieved significantly higher Nash–Sutcliffe efficiency (NSE) values than the US National Water Model. Compared to naive prediction with distinct LSTMs per timescale, the multi-timescale architectures are computationally more efficient with no loss in accuracy. Beyond prediction quality, the multi-timescale LSTM can process different input variables at different timescales, which is especially relevant to operational applications where the lead time of meteorological forcings depends on their temporal resolution.},
    journal = {Hydrology and Earth System Sciences},
    abbr = {HESS},
    url = {https://hess.copernicus.org/articles/25/2045/2021/},
    year = {2021},
    selected = {true},
    software = {false},
    code = {https://github.com/gauchm/mts-lstm},
    category = {ai4earth},
    date = {2021-04-19}
}

@article{vall_promise_2021,
  abstract={Drug-induced liver injury (DILI) is a common reason for the withdrawal of a drug from the market. Early assessment of DILI risk is an essential part of drug development, but it is rendered challenging prior to clinical trials by the complex factors that give rise to liver damage. Artificial intelligence (AI) approaches, particularly those building on machine learning, range from random forests to more recent techniques such as deep learning, and provide tools that can analyze chemical compounds and accurately predict some of their properties based purely on their structure. This article reviews existing AI approaches to predicting DILI and elaborates on the challenges that arise from the as yet limited availability of data. Future directions are discussed focusing on rich data modalities, such as 3D spheroids, and the slow but steady increase in drugs annotated with DILI risk labels.},
  abbr={Frontiers in AI},
  url={https://www.frontiersin.org/articles/10.3389/frai.2021.638410},
  category={ai_drug},
  selected={true},
  date = {2021-04-14},
  title = {The Promise of {{AI}} for {{DILI}} Prediction},
  author = {Vall, Andreu and Sabnis, Yogesh and Shi, Jiye and Class, Reiner and Hochreiter, Sepp and Klambauer, G{\"u}nter},
  year = {2021},
  volume = {4},
  publisher = {{Frontiers}},
  issn = {2624-8212},
  copyright = {All rights reserved},
  journal = {Frontiers in Artificial Intelligence},
  keywords = {artificial intelligence,deep learning,drug-induced liver injury,machine learning,neural networks}
}

@article{roland2021covid,
  abbr={medRxiv},
  abstract = {We investigate machine learning models that identify COVID-19 positive patients and estimate the mortality risk based on routinely acquired blood tests in a hospital setting. However, during pandemics or new outbreaks, disease and testing characteristics change, thus we face domain shifts. Domain shifts can be caused, e.g., by changes in the disease prevalence (spreading or tested population), by refined RT-PCR testing procedures (taking samples, laboratory), or by virus mutations. Therefore, machine learning models for diagnosing COVID-19 or other diseases may not be reliable and degrade in performance over time. To countermand this effect, we propose methods that first identify domain shifts and then reverse their negative effects on the model performance. Frequent re-training and reassessment, as well as stronger weighting of more recent samples, keeps model performance and credibility at a high level over time. Our diagnosis models are constructed and tested on large-scale data sets, steadily adapt to observed domain shifts, and maintain high ROC AUC values along pandemics.},
  title={Machine Learning based COVID-19 Diagnosis from Blood Tests with Robustness to Domain Shifts},
  author={Theresa Roland, Carl Böck, Thomas Tschoellitsch, Alexander Maletzky, Sepp Hochreiter, Jens Meier, Günter Klambauer},
  journal={medRxiv preprint doi:10.1101/2021.04.06.21254997},
  year={2021},
  date = {2021-04-09},
  url = {https://www.medrxiv.org/content/10.1101/2021.04.06.21254997v1.full-text},
  category = {ai_healthcare},
  selected={true}
}

@article{seidl2021reaction,
  abbr={arXiv},
  title={Modern Hopfield Networks for Few- and Zero-Shot Reaction Prediction},
  author={Philipp Seidl, Philipp Renz, Natalia Dyubankova, Paulo Neves, Jonas Verhoeven, Jörg K. Wegner, Sepp Hochreiter, Günter Klambauer},
  abstract = {An essential step in the discovery of new drugs and materials is the synthesis of a molecule that exists so far only as an idea to test its biological and physical properties. While computer-aided design of virtual molecules has made large progress, computer-assisted synthesis planning (CASP) to realize physical molecules is still in its infancy and lacks a performance level that would enable large-scale molecule discovery. CASP supports the search for multi-step synthesis routes, which is very challenging due to high branching factors in each synthesis step and the hidden rules that govern the reactions. The central and repeatedly applied step in CASP is reaction prediction, for which machine learning methods yield the best performance. We propose a novel reaction prediction approach that uses a deep learning architecture with modern Hopfield networks (MHNs) that is optimized by contrastive learning. An MHN is an associative memory that can store and retrieve chemical reactions in each layer of a deep learning architecture. We show that our MHN contrastive learning approach enables few- and zero-shot learning for reaction prediction which, in contrast to previous methods, can deal with rare, single, or even no training example(s) for a reaction. On a well established benchmark, our MHN approach pushes the state-of-the-art performance up by a large margin as it improves the predictive top-100 accuracy from 0.858±0.004 to 0.959±0.004. This advance might pave the way to large-scale molecule discovery.},
  journal={arXiv preprint arXiv:2104.03279},
  year={2021},
  date = {2021-04-07},
  category = {ai_drug},
  selected={true}
}


@online{winterTrustedAI2021,
 abbr={arXiv},
 abstract = {Artificial Intelligence is one of the fastest growing technologies of the 21st century and accompanies us in our daily lives when interacting with technical applications. However, reliance on such technical systems is crucial for their widespread applicability and acceptance. The societal tools to express reliance are usually formalized by lawful regulations, i.e., standards, norms, accreditations, and certificates. Therefore, the TÜV AUSTRIA Group in cooperation with the Institute for Machine Learning at the Johannes Kepler University Linz, proposes a certification process and an audit catalog for Machine Learning applications. We are convinced that our approach can serve as the foundation for the certification of applications that use Machine Learning and Deep Learning, the techniques that drive the current revolution in Artificial Intelligence. While certain high-risk areas, such as fully autonomous robots in workspaces shared with humans, are still some time away from certification, we aim to cover low-risk applications with our certification procedure. Our holistic approach attempts to analyze Machine Learning applications from multiple perspectives to evaluate and verify the aspects of secure software development, functional requirements, data quality, data protection, and ethics. Inspired by existing work, we introduce four criticality levels to map the criticality of a Machine Learning application regarding the impact of its decisions on people, environment, and organizations. Currently, the audit catalog can be applied to low-risk applications within the scope of supervised learning as commonly encountered in industry. Guided by field experience, scientific developments, and market demands, the audit catalog will be extended and modified accordingly.},
 author = {Winter, Philip Matthias and Eder, Sebastian and Weissenböck, Johannes and Schwald, Christoph and Doms, Thomas and Vogt, Tom and Hochreiter, Sepp, and Nessler, Bernhard},
 date = {2021-03-31},
 eprint = {2103.16910},
 eprinttype = {arxiv},
 selected = {true},
 title = {Trusted Artificial Intelligence: Towards Certification of Machine Learning Applications},
 url = {https://arxiv.org/abs/2103.16910.pdf},
 year = {2021},
 software = {false},
 category={deep_learning}
}

@online{schimunekhERGinterpretability2021,
 abbr={QSAR2021},
 abstract = {Since many highly accurate predictive models for bioactivity and toxicity assays are based on Deep Learning methods, there has been a recent surge of interest in interpretability methods for Deep Learning approaches in drug discovery [1,2]. Interpretability methods are highly desired by human experts to enable them to make design decisions on the molecule based on the activity model. However, it is still unclear which of those interpretability methods are better identifying relevant substructures of molecules.  A method comparison is further complicated by the lack of ground truth and appropriate metrics. Here, we present the first comparative study of a set of interpretability methods for Deep Learning models for hERG inhibition. In our work, we compared layer-wise relevance propagation, feature gradients, saliency maps, integrated gradients, occlusion and Shapley values. In the quantitative analysis, known substructures which indicate hERG activity are used as ground truth [3]. Interpretability methods were compared by their ability to rank atoms, which are part of indicative substructures, first. The significantly best performing method is Shapley values with an area under-ROC-curve (AUC) of ~0.74 ± 0.12, but also runner-up methods, such as Integrated Gradients, achieved similar results. The results indicate that interpretability methods for deep activity models have the potential to identify new toxicophores.

[1] Jiménez-Luna, J., et al. (2020). Nature Machine Intelligence, 2(10), 573-584.
[2]  Preuer, K., et al. (2019). In Explainable AI: Interpreting, Explaining and Visualizing Deep Learning (pp. 331-345).
[3] Czodrowski, P. (2013). Journal of chemical information and modeling, 53, 2240–2251.},
 author = {Schimunek, Johannes and Friedrich, Lukas and Kuhn, Daniel and Hochreiter, Sepp and Rippmann, Friedrich and Klambauer, Günter},
 date = {2021-01-30},
 selected = {true},
 title = {Comparative assessment of interpretability methods of deep activity models for hERG},
 url = {https://www.ascctox.org/qsar2021},
 year = {2021},
 category={ai_drug}
}

@inproceedings{hoedtMCLSTM2021,
 abbr={ICML},
 abstract = {The success of Convolutional Neural Networks (CNNs) in computer vision is mainly driven by their strong inductive bias, which is strong enough to allow CNNs to solve vision-related tasks with random weights, meaning without learning. Similarly, Long Short-Term Memory (LSTM) has a strong inductive bias towards storing information over time. However, many real-world systems are governed by conservation laws, which lead to the redistribution of particular quantities -- e.g. in physical and economical systems. Our novel Mass-Conserving LSTM (MC-LSTM) adheres to these conservation laws by extending the inductive bias of LSTM to model the redistribution of those stored quantities. MC-LSTMs set a new state-of-the-art for neural arithmetic units at learning arithmetic operations, such as addition tasks, which have a strong conservation law, as the sum is constant over time. Further, MC-LSTM is applied to traffic forecasting, modelling a pendulum, and a large benchmark dataset in hydrology, where it sets a new state-of-the-art for predicting peak flows. In the hydrology example, we show that MC-LSTM states correlate with real-world processes and are therefore interpretable.},
 author = {Hoedt, Pieter-Jan and Kratzert, Frederik and Klotz, Daniel and Halmich, Christina and Holzleitner, Markus and Nearing, Grey and Hochreiter, Sepp and Klambauer, Günter},
 date = {2021-07-22},
 eprint = {2101.05186},
 eprinttype = {arxiv},
 selected = {true},
 title = {MC-LSTM: Mass-Conserving LSTM},
 booktitle = {Proceedings of the 38th International Conference on Machine Learning},
 pages = {4275--4286},
 year = {2021},
 volume = {139},
 series = {Proceedings of Machine Learning Research},
 publisher = {PMLR},
 url = {https://proceedings.mlr.press/v139/hoedt21a.html},
 pdf = {https://proceedings.mlr.press/v139/hoedt21a/hoedt21a.pdf},
 software = {true},
 code = {https://github.com/ml-jku/mc-lstm},
 category={deep_learning}
}


@online{ramsauerHopfieldNetworksAll2020,
 abbr={ICLR},
 abstract = {We show that the transformer attention mechanism is the update rule of a modern Hopfield network with continuous states. This new Hopfield network can store exponentially (with the dimension) many patterns, converges with one update, and has exponentially small retrieval errors. The number of stored patterns is traded off against convergence speed and retrieval error. The new Hopfield network has three types of energy minima (fixed points of the update): (1) global fixed point averaging over all patterns, (2) metastable states averaging over a subset of patterns, and (3) fixed points which store a single pattern. Transformer and BERT models operate in their first layers preferably in the global averaging regime, while they operate in higher layers in metastable states. The gradient in transformers is maximal for metastable states, is uniformly distributed for global averaging, and vanishes for a fixed point near a stored pattern. Using the Hopfield network interpretation, we analyzed learning of transformer and BERT models. Learning starts with attention heads that average and then most of them switch to metastable states. However, the majority of heads in the first layers still averages and can be replaced by averaging, e.g. our proposed Gaussian weighting. In contrast, heads in the last layers steadily learn and seem to use metastable states to collect information created in lower layers. These heads seem to be a promising target for improving transformers. Neural networks with Hopfield networks outperform other methods on immune repertoire classification, where the Hopfield net stores several hundreds of thousands of patterns. We provide a new PyTorch layer called "Hopfield", which allows to equip deep learning architectures with modern Hopfield networks as a new powerful concept comprising pooling, memory, and attention. GitHub: https://github.com/ml-jku/hopfield-layers},
 author = {Ramsauer, Hubert and Schäfl, Bernhard and Lehner, Johannes and Seidl, Philipp and Widrich, Michael and Gruber, Lukas and Holzleitner, Markus and Pavlović, Milena and Sandve, Geir Kjetil and Greiff, Victor and Kreil, David and Kopp, Michael and Klambauer, Günter and Brandstetter, Johannes and Hochreiter, Sepp},
 date = {2020-07-16},
 eprint = {2008.02217},
 eprinttype = {arxiv},
 selected = {true},
 title = {Hopfield {{Networks}} Is {{All You Need}}},
 url = {http://arxiv.org/abs/2008.02217},
 year = {2020},
 blog = {https://ml-jku.github.io/hopfield-layers/},
 software = {true},
 code = {https://github.com/ml-jku/hopfield-layers},
 category={hopfield}
}


@Article{adler2020cross,
  abbr={arXiv},
  author        = {Adler, Thomas and Brandstetter, Johannes and Widrich, Michael and Mayr, Andreas and Kreil, David and Kopp, Michael and Klambauer, G{\"u}nter and Hochreiter, Sepp},
  title         = {Cross-Domain Few-Shot Learning by Representation Fusion},
  abstract      = {In order to quickly adapt to new data, few-shot learning aims at learning from few examples, often by using already acquired knowledge. The new data often differs from the previously seen data due to a domain shift, that is, a change of the input-target distribution. While several methods perform well on small domain shifts like new target classes with similar inputs, larger domain shifts are still challenging. Large domain shifts may result in high-level concepts that are not shared between the original and the new domain. However, low-level concepts like edges in images might still be shared and useful. For cross-domain few-shot learning, we suggest representation fusion to unify different abstraction levels of a deep neural network into one representation. We propose Cross-domain Hebbian Ensemble Few-shot learning (CHEF), which achieves representation fusion by an ensemble of Hebbian learners acting on different layers of a deep neural network that was trained on the original domain. On the few-shot datasets miniImagenet and tieredImagenet, where the domain shift is small, CHEF is competitive with state-of-the-art methods. On cross-domain few-shot benchmark challenges with larger domain shifts, CHEF establishes novel state-of-the-art results in all categories. We further apply CHEF on a real-world cross-domain application in drug discovery. We consider a domain shift from bioactive molecules to environmental chemicals and drugs with twelve associated toxicity prediction tasks. On these tasks, that are highly relevant for computational drug discovery, CHEF significantly outperforms all its competitors.},
  journal       = {arXiv preprint arXiv:2010.06498},
  url           = {https://arxiv.org/abs/2010.06498},
  year          = {2020},
  __markedentry = {[gk:6]},
  blog = {https://ml-jku.github.io/chef/},
  selected={true},
  software = {true},
  code = {https://github.com/ml-jku/chef},
  category={deep_learning}
}

@misc{holzleitner2020convergence,
      title={Convergence Proof for Actor-Critic Methods Applied to PPO and RUDDER},
      author={Markus Holzleitner and Lukas Gruber and José Arjona-Medina and Johannes Brandstetter and Sepp Hochreiter},
      year={2020},
      eprint={2012.01399},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      abbr = {arXiv},
      selected = {true},
      category = {reinforcement_learning}
}


@Article{patil2020alignrudder,
  abbr          = {ICML},
  title         = {Align-RUDDER: Learning From Few Demonstrations by Reward Redistribution},
  author        = {Vihang P. Patil and Markus Hofmarcher and Marius-Constantin Dinu and Matthias Dorfer and Patrick M. Blies and Johannes Brandstetter and Jose A. Arjona-Medina and Sepp Hochreiter},
  year          = {2022},
  abstract      = {Reinforcement Learning algorithms require a large number of samples to solve complex tasks with sparse and delayed rewards. Complex tasks can often be hierarchically decomposed into sub-tasks. A step in the Q-function can be associated with solving a sub-task, where the expectation of the return increases. RUDDER has been introduced to identify these steps and then redistribute reward to them, thus immediately giving reward if sub-tasks are solved. Since the problem of delayed rewards is mitigated, learning is considerably sped up. However, for complex tasks, current exploration strategies as deployed in RUDDER struggle with discovering episodes with high rewards. Therefore, we assume that episodes with high rewards are given as demonstrations and do not have to be discovered by exploration. Typically the number of demonstrations is small and RUDDER's LSTM model as a deep learning method does not learn well. Hence, we introduce Align-RUDDER, which is RUDDER with two major modifications. First, Align-RUDDER assumes that episodes with high rewards are given as demonstrations, replacing RUDDER's safe exploration and lessons replay buffer. Second, we replace RUDDER's LSTM model by a profile model that is obtained from multiple sequence alignment of demonstrations. Profile models can be constructed from as few as two demonstrations as known from bioinformatics. Align-RUDDER inherits the concept of reward redistribution, which considerably reduces the delay of rewards, thus speeding up learning. Align-RUDDER outperforms competitors on complex artificial tasks with delayed reward and few demonstrations. On the MineCraft ObtainDiamond task, Align-RUDDER is able to mine a diamond, though not frequently.},
  journal       = {arXiv preprint arXiv:2009.14108},
  url           = {https://arxiv.org/abs/2009.14108},
  primaryClass  = {cs.LG},
  selected      = {true},
  software      = {true},
  code        = {https://github.com/ml-jku/align-rudder},
  category = {reinforcement_learning}
}

@inproceedings{widrich2020modern,
  abbr={NeurIPS},
  title={Modern Hopfield networks and attention for immune repertoire classification},
  author={Widrich, Michael and Sch{\"a}fl, Bernhard and Ramsauer, Hubert and Pavlovi{\'c}, Milena and Gruber, Lukas and Holzleitner, Markus and Brandstetter, Johannes and Sandve, Geir Kjetil and Greiff, Victor and Hochreiter, Sepp and Klambauer, G{\"u}nter},
  booktitle = {Advances in Neural Information Processing Systems},
  editor = {H. Larochelle and M. Ranzato and R. Hadsell and M.F. Balcan and H. Lin},
  publisher = {Curran Associates, Inc.},
  volume = {33 (preproceedings)},
  year = {2020},
  abstract={A central mechanism in machine learning is to identify, store, and recognize patterns. How to learn, access, and retrieve such patterns is crucial in Hopfield networks and the more recent transformer architectures. We show that the attention mechanism of transformer architectures is actually the update rule of modern Hopfield networks that can store exponentially many patterns. We exploit this high storage capacity of modern Hopfield networks to solve a challenging multiple instance learning (MIL) problem in computational biology: immune repertoire classification. In immune repertoire classification, a vast number of immune receptors are used to predict the immune status of an individual. This constitutes a MIL problem with an unprecedentedly massive number of instances, two orders of magnitude larger than currently considered problems, and with an extremely low witness rate. Accurate and interpretable machine learning methods solving this problem could pave the way towards new vaccines and therapies, which is currently a very relevant research topic intensified by the COVID-19 crisis. In this work, we present our novel method DeepRC that integrates transformer-like attention, or equivalently modern Hopfield networks, into deep learning architectures for massive MIL such as immune repertoire classification. We demonstrate that DeepRC outperforms all other methods with respect to predictive performance on large-scale experiments including simulated and real-world virus infection data and enables the extraction of sequence motifs that are connected to a given disease class. Source code and datasets: https://github.com/ml-jku/DeepRC},
  url           = {https://proceedings.neurips.cc/paper/2020/file/da4902cb0bc38210839714ebdcf0efc3-Paper.pdf},
  selected={true},
  software = {true},
  code = {https://github.com/ml-jku/DeepRC},
  video = {https://nips.cc/virtual/2020/public/poster_da4902cb0bc38210839714ebdcf0efc3.html},
  category={hopfield},
  __markedentry = {[gk:6]}
}


@inproceedings{Arjona:19,
  abbr={NeurIPS},
  title = {RUDDER: Return Decomposition for Delayed Rewards},
  author = {Arjona-Medina, Jose A. and Gillhofer, Michael and Widrich, Michael and Unterthiner, Thomas and Brandstetter, Johannes and Hochreiter, Sepp},
  booktitle = {Advances in Neural Information Processing Systems},
  editor = {H. Wallach and H. Larochelle and A. Beygelzimer and F. d\textquotesingle Alch\'{e}-Buc and E. Fox and R. Garnett},
  pages = {13566--13577},
  publisher = {Curran Associates, Inc.},
  volume = {32},
  year = {2019},
  abstract = {We propose RUDDER, a novel reinforcement learning approach for delayed rewards in finite Markov decision processes (MDPs). In MDPs the Q-values are equal to the expected immediate reward plus the expected future rewards. The latter are related to bias problems in temporal difference (TD) learning and to high variance problems in Monte Carlo (MC) learning. Both problems are even more severe when rewards are delayed. RUDDER aims at making the expected future rewards zero, which simplifies Q-value estimation to computing the mean of the immediate reward. We propose the following two new concepts to push the expected future rewards toward zero. (i) Reward redistribution that leads to return-equivalent decision processes with the same optimal policies and, when optimal, zero expected future rewards. (ii) Return decomposition via contribution analysis which transforms the reinforcement learning task into a regression task at which deep learning excels. On artificial tasks with delayed rewards, RUDDER is significantly faster than MC and exponentially faster than Monte Carlo Tree Search (MCTS), TD(\{\textbackslash lambda\}), and reward shaping approaches. At Atari games, RUDDER on top of a Proximal Policy Optimization (PPO) baseline improves the scores, which is most prominent at games with delayed rewards. Source code is available at \textbackslash url\{https://github.com/ml-jku/rudder\} and demonstration videos at \textbackslash url\{https://goo.gl/EQerZV\}.},
  url = {https://papers.nips.cc/paper/2019/file/16105fb9cc614fc29e1bda00dab60d41-Paper.pdf},
  software = {true},
  code = {https://github.com/ml-jku/rudder},
  video = {https://www.youtube.com/playlist?list=PLDfrC-Vpg-CzVTqSjxVeLQZy3f7iv9vyY},
  blog = {https://ml-jku.github.io/rudder/},
  category = {reinforcement_learning}
}

@incollection{arrasExplainingInterpretingLSTMs2019,
 abstract = {While neural networks have acted as a strong unifying force in the design of modern AI systems, the neural network architectures themselves remain highly heterogeneous due to the variety of tasks to be solved. In this chapter, we explore how to adapt the Layer-wise Relevance Propagation (LRP) technique used for explaining the predictions of feed-forward networks to the LSTM architecture used for sequential data modeling and forecasting. The special accumulators and gated interactions present in the LSTM require both a new propagation scheme and an extension of the underlying theoretical framework to deliver faithful explanations.},
 author = {Arras, Leila and Arjona-Medina, José and Widrich, Michael and Montavon, Grégoire and Gillhofer, Michael and Müller, Klaus-Robert and Hochreiter, Sepp and Samek, Wojciech},
 date = {2019},
 pages = {211--238},
 publisher = {{Springer International Publishing}},
 selected = {false},
 title = {Explaining and {{Interpreting LSTMs}}},
 url = {https://doi.org/10.1007/978-3-030-28954-6_11},
 year = {2019}
}

@article{clevertRectifiedFactorNetworks2017,
 abstract = {Biclustering has become a major tool for analyzing large datasets given as matrix of samples times features and has been successfully applied in life sciences and e-commerce for drug design and recommender systems, respectively. Factor Analysis for Bicluster Acquisition (FABIA), one of the most successful biclustering methods, is a generative model that represents each bicluster by two sparse membership vectors: one for the samples and one for the features. However, FABIA is restricted to about 20 code units because of the high computational complexity of computing the posterior. Furthermore, code units are sometimes insufficiently decorrelated and sample membership is difficult to determine. We propose to use the recently introduced unsupervised Deep Learning approach Rectified Factor Networks (RFNs) to overcome the drawbacks of existing biclustering methods. RFNs efficiently construct very sparse, non-linear, high-dimensional representations of the input via their posterior means. RFN learning is a generalized alternating minimization algorithm based on the posterior regularization method which enforces non-negative and normalized posterior means. Each code unit represents a bicluster, where samples for which the code unit is active belong to the bicluster and features that have activating weights to the code unit belong to the bicluster.On 400 benchmark datasets and on three gene expression datasets with known clusters, RFN outperformed 13 other biclustering methods including FABIA. On data of the 1000 Genomes Project, RFN could identify DNA segments which indicate, that interbreeding with other hominins starting already before ancestors of modern humans left Africa.https://github.com/bioinf-jku/librfn},
 author = {Clevert, Djork-Arné and Unterthiner, Thomas and Povysil, Gundula and Hochreiter, Sepp},
 date = {2017-07-15},
 journaltitle = {Bioinformatics},
 number = {14},
 pages = {i59-i66},
 selected = {false},
 title = {Rectified Factor Networks for Biclustering of Omics Data},
 url = {https://doi.org/10.1093/bioinformatics/btx226},
 volume = {33},
 year = {2017},
 category={ai_drug}
}

@article{fischerDefiningObjectiveClusters2018,
 abstract = {Rabies is caused by lyssaviruses, and is one of the oldest known zoonoses. In recent years, more than 21,000 nucleotide sequences of rabies viruses (RABV), from the prototype species rabies lyssavirus, have been deposited in public databases. Subsequent phylogenetic analyses in combination with metadata suggest geographic distributions of RABV. However, these analyses somewhat experience technical difficulties in defining verifiable criteria for cluster allocations in phylogenetic trees inviting for a more rational approach. Therefore, we applied a relatively new mathematical clustering algorythm named ‘affinity propagation clustering’ (AP) to propose a standardized sub-species classification utilizing full-genome RABV sequences. Because AP has the advantage that it is computationally fast and works for any meaningful measure of similarity between data samples, it has previously been applied successfully in bioinformatics, for analysis of microarray and gene expression data, however, cluster analysis of sequences is still in its infancy. Existing (516) and original (46) full genome RABV sequences were used to demonstrate the application of AP for RABV clustering. On a global scale, AP proposed four clusters, i.e. New World cluster, Arctic/Arctic-like, Cosmopolitan, and Asian as previously assigned by phylogenetic studies. By combining AP with established phylogenetic analyses, it is possible to resolve phylogenetic relationships between verifiably determined clusters and sequences. This workflow will be useful in confirming cluster distributions in a uniform transparent manner, not only for RABV, but also for other comparative sequence analyses.},
 author = {Fischer, Susanne and Freuling, Conrad M. and Müller, Thomas and Pfaff, Florian and Bodenhofer, Ulrich and Höper, Dirk and Fischer, Mareike and Marston, Denise A. and Fooks, Anthony R. and Mettenleiter, Thomas C. and Conraths, Franz J. and Homeier-Bachmann, Timo},
 date = {2018-01-22},
 journaltitle = {PLOS Neglected Tropical Diseases},
 number = {1},
 pages = {e0006182},
 publisher = {{Public Library of Science}},
 selected = {false},
 title = {Defining Objective Clusters for Rabies Virus Sequences Using Affinity Propagation Clustering},
 url = {https://doi.org/10.1371/journal.pntd.0006182},
 volume = {12},
 year = {2018}
}

@article{greiffLearningHighDimensionalImmunogenomic2017,
 abstract = {Recent studies have revealed that immune repertoires contain a substantial fraction of public clones, which may be defined as Ab or TCR clonal sequences shared across individuals. It has remained unclear whether public clones possess predictable sequence features that differentiate them from private clones, which are believed to be generated largely stochastically. This knowledge gap represents a lack of insight into the shaping of immune repertoire diversity. Leveraging a machine learning approach capable of capturing the high-dimensional compositional information of each clonal sequence (defined by CDR3), we detected predictive public clone and private clone–specific immunogenomic differences concentrated in CDR3’s N1–D–N2 region, which allowed the prediction of public and private status with 80\% accuracy in humans and mice. Our results unexpectedly demonstrate that public, as well as private, clones possess predictable high-dimensional immunogenomic features. Our support vector machine model could be trained effectively on large published datasets (3 million clonal sequences) and was sufficiently robust for public clone prediction across individuals and studies prepared with different library preparation and high-throughput sequencing protocols. In summary, we have uncovered the existence of high-dimensional immunogenomic rules that shape immune repertoire diversity in a predictable fashion. Our approach may pave the way for the construction of a comprehensive atlas of public mouse and human immune repertoires with potential applications in rational vaccine design and immunotherapeutics.},
 author = {Greiff, Victor and Weber, Cédric R. and Palme, Johannes and Bodenhofer, Ulrich and Miho, Enkelejda and Menzel, Ulrike and Reddy, Sai T.},
 date = {2017-10-15},
 journaltitle = {The Journal of Immunology},
 number = {8},
 pages = {2985--2997},
 publisher = {{American Association of Immunologists}},
 selected = {false},
 title = {Learning the {{High}}-{{Dimensional Immunogenomic Features That Predict Public}} and {{Private Antibody Repertoires}}},
 url = {https://doi.org/10.4049/jimmunol.1700594},
 volume = {199},
 year = {2017}
}

@online{heuselGANsTrainedTwo2017,
 abstract = {Generative Adversarial Networks (GANs) excel at creating realistic images with complex models for which maximum likelihood is infeasible. However, the convergence of GAN training has still not been proved. We propose a two time-scale update rule (TTUR) for training GANs with stochastic gradient descent on arbitrary GAN loss functions. TTUR has an individual learning rate for both the discriminator and the generator. Using the theory of stochastic approximation, we prove that the TTUR converges under mild assumptions to a stationary local Nash equilibrium. The convergence carries over to the popular Adam optimization, for which we prove that it follows the dynamics of a heavy ball with friction and thus prefers flat minima in the objective landscape. For the evaluation of the performance of GANs at image generation, we introduce the "Fr\textbackslash 'echet Inception Distance" (FID) which captures the similarity of generated images to real ones better than the Inception Score. In experiments, TTUR improves learning for DCGANs and Improved Wasserstein GANs (WGAN-GP) outperforming conventional GAN training on CelebA, CIFAR-10, SVHN, LSUN Bedrooms, and the One Billion Word Benchmark.},
 author = {Heusel, Martin and Ramsauer, Hubert and Unterthiner, Thomas and Nessler, Bernhard and Hochreiter, Sepp},
 date = {2017-06-26},
 eprint = {1706.08500},
 eprinttype = {arxiv},
 pdf = {https://arxiv.org/pdf/1706.08500.pdf},
 selected = {false},
 title = {{{GANs Trained}} by a {{Two Time}}-{{Scale Update Rule Converge}} to a {{Local Nash Equilibrium}}},
 url = {http://arxiv.org/abs/1706.08500},
 year = {2017},
 category={deep_learning}
}

@article{hochreiterMachineLearningDrug2018,
 author = {Hochreiter, Sepp and Klambauer, Guenter and Rarey, Matthias},
 date = {2018-09-24},
 journaltitle = {Journal of Chemical Information and Modeling},
 number = {9},
 pages = {1723--1724},
 publisher = {{American Chemical Society}},
 selected = {false},
 title = {Machine {{Learning}} in {{Drug Discovery}}},
 url = {https://doi.org/10.1021/acs.jcim.8b00478},
 volume = {58},
 year = {2018},
 category={ai_drug}
}

@online{hofmarcherLargescaleLigandbasedVirtual2020,
 abbr={arXiv},
 abstract = {Due to the current severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) pandemic, there is an urgent need for novel therapies and drugs. We conducted a large-scale virtual screening for small molecules that are potential CoV-2 inhibitors. To this end, we utilized "ChemAI", a deep neural network trained on more than 220M data points across 3.6M molecules from three public drug-discovery databases. With ChemAI, we screened and ranked one billion molecules from the ZINC database for favourable effects against CoV-2. We then reduced the result to the 30,000 top-ranked compounds, which are readily accessible and purchasable via the ZINC database. Additionally, we screened the DrugBank using ChemAI to allow for drug repurposing, which would be a fast way towards a therapy. We provide these top-ranked compounds of ZINC and DrugBank as a library for further screening with bioassays at https://github.com/ml-jku/sars-cov-inhibitors-chemai.},
 author = {Hofmarcher, Markus and Mayr, Andreas and Rumetshofer, Elisabeth and Ruch, Peter and Renz, Philipp and Schimunek, Johannes and Seidl, Philipp and Vall, Andreu and Widrich, Michael and Hochreiter, Sepp and Klambauer, Günter},
 date = {2020-08-17},
 eprint = {2004.00979},
 eprinttype = {arxiv},
 selected = {true},
 title = {Large-Scale Ligand-Based Virtual Screening for {{SARS}}-{{CoV}}-2 Inhibitors Using Deep Neural Networks},
 url = {http://arxiv.org/abs/2004.00979},
 year = {2020},
 category={ai_healthcare}
}

@incollection{hofmarcherVisualSceneUnderstanding2019,
 abbr={Springer},
 abstract = {Deep neural networks are an increasingly important technique for autonomous driving, especially as a visual perception component. Deployment in a real environment necessitates the explainability and inspectability of the algorithms controlling the vehicle. Such insightful explanations are relevant not only for legal issues and insurance matters but also for engineers and developers in order to achieve provable functional quality guarantees. This applies to all scenarios where the results of deep networks control potentially life threatening machines. We suggest the use of a tiered approach, whose main component is a semantic segmentation model, over an end-to-end approach for an autonomous driving system. In order for a system to provide meaningful explanations for its decisions it is necessary to give an explanation about the semantics that it attributes to the complex sensory inputs that it perceives. In the context of high-dimensional visual input this attribution is done as a pixel-wise classification process that assigns an object class to every pixel in the image. This process is called semantic segmentation.We propose an architecture that delivers real-time viable segmentation performance and which conforms to the limitations in computational power that is available in production vehicles. The output of such a semantic segmentation model can be used as an input for an interpretable autonomous driving system.},
 author = {Hofmarcher, Markus and Unterthiner, Thomas and Arjona-Medina, José and Klambauer, Günter and Hochreiter, Sepp and Nessler, Bernhard},
 date = {2019},
 pages = {285--296},
 publisher = {{Springer International Publishing}},
 selected = {false},
 title = {Visual {{Scene Understanding}} for {{Autonomous Driving Using Semantic Segmentation}}},
 url = {https://doi.org/10.1007/978-3-030-28954-6_15},
 year = {2019},
 category={ai4drive}
}

@online{kimeswengerDetectingCutaneousBasal2019,
 abstract = {Diagnosing basal cell carcinomas (BCC), one of the most common cutaneous malignancies in humans, is a task regularly performed by pathologists and dermato-pathologists. Improving histological diagnosis by providing diagnosis suggestions, i.e. computer-assisted diagnoses is actively researched to improve safety, quality and efficiency. Increasingly, machine learning methods are applied due to their superior performance. However, typical images obtained by scanning histological sections often have a resolution that is prohibitive for processing with current state-of-the-art neural networks. Furthermore, the data pose a problem of weak labels, since only a tiny fraction of the image is indicative of the disease class, whereas a large fraction of the image is highly similar to the non-disease class. The aim of this study is to evaluate whether it is possible to detect basal cell carcinomas in histological sections using attention-based deep learning models and to overcome the ultra-high resolution and the weak labels of whole slide images. We demonstrate that attention-based models can indeed yield almost perfect classification performance with an AUC of 0.99.},
 author = {Kimeswenger, Susanne and Rumetshofer, Elisabeth and Hofmarcher, Markus and Tschandl, Philipp and Kittler, Harald and Hochreiter, Sepp and Hötzenecker, Wolfram and Klambauer, Günter},
 date = {2019-12-02},
 eprint = {1911.06616},
 eprinttype = {arxiv},
 pdf = {https://arxiv.org/pdf/1911.06616.pdf},
 selected = {false},
 title = {Detecting Cutaneous Basal Cell Carcinomas in Ultra-High Resolution and Weakly Labelled Histopathological Images},
 url = {http://arxiv.org/abs/1911.06616},
 year = {2019},
 category={ai_healthcare}
}

@online{lehner2019patch,
 abbr={arXiv},
 abstract = {We introduce Patch Refinement a two-stage model for accurate 3D object detection and localization from point cloud data. Patch Refinement is composed of two independently trained Voxelnet-based networks, a Region Proposal Network (RPN) and a Local Refinement Network (LRN). We decompose the detection task into a preliminary Bird's Eye View (BEV) detection step and a local 3D detection step. Based on the proposed BEV locations by the RPN, we extract small point cloud subsets ("patches"), which are then processed by the LRN, which is less limited by memory constraints due to the small area of each patch. Therefore, we can apply encoding with a higher voxel resolution locally. The independence of the LRN enables the use of additional augmentation techniques and allows for an efficient, regression focused training as it uses only a small fraction of each scene. Evaluated on the KITTI 3D object detection benchmark, our submission from January 28, 2019, outperformed all previous entries on all three difficulties of the class car, using only 50 % of the available training data and only LiDAR information.},
 author = {Lehner, Johannes and Mitterecker, Andreas and Adler, Thomas  and Hofmarcher, Markus and Nessler, Bernhard and Hochreiter, Sepp },
 date = {2019-10-09},
 eprint = {1910.04093},
 eprinttype = {arxiv},
 pdf = {https://arxiv.org/pdf/1910.04093},
 selected = {false},
 title = {Patch Refinement - Localized 3D Object Detection},
 url = {https://arxiv.org/abs/1910.04093},
 year = {2019},
 category={ai4drive}
}



@article{klambauerMachineLearningDrug2019,
 author = {Klambauer, Günter and Hochreiter, Sepp and Rarey, Matthias},
 date = {2019-03-25},
 journaltitle = {Journal of Chemical Information and Modeling},
 number = {3},
 pages = {945--946},
 publisher = {{American Chemical Society}},
 selected = {false},
 title = {Machine {{Learning}} in {{Drug Discovery}}},
 url = {https://doi.org/10.1021/acs.jcim.9b00136},
 volume = {59},
 year = {2019},
 category={ai_drug}
}

@online{klambauerSelfNormalizingNeuralNetworks2017,
 abbr={NeurIPS},
 abstract = {Deep Learning has revolutionized vision via convolutional neural networks (CNNs) and natural language processing via recurrent neural networks (RNNs). However, success stories of Deep Learning with standard feed-forward neural networks (FNNs) are rare. FNNs that perform well are typically shallow and, therefore cannot exploit many levels of abstract representations. We introduce self-normalizing neural networks (SNNs) to enable high-level abstract representations. While batch normalization requires explicit normalization, neuron activations of SNNs automatically converge towards zero mean and unit variance. The activation function of SNNs are "scaled exponential linear units" (SELUs), which induce self-normalizing properties. Using the Banach fixed-point theorem, we prove that activations close to zero mean and unit variance that are propagated through many network layers will converge towards zero mean and unit variance -- even under the presence of noise and perturbations. This convergence property of SNNs allows to (1) train deep networks with many layers, (2) employ strong regularization, and (3) to make learning highly robust. Furthermore, for activations not close to unit variance, we prove an upper and lower bound on the variance, thus, vanishing and exploding gradients are impossible. We compared SNNs on (a) 121 tasks from the UCI machine learning repository, on (b) drug discovery benchmarks, and on (c) astronomy tasks with standard FNNs and other machine learning methods such as random forests and support vector machines. SNNs significantly outperformed all competing FNN methods at 121 UCI tasks, outperformed all competing methods at the Tox21 dataset, and set a new record at an astronomy data set. The winning SNN architectures are often very deep. Implementations are available at: github.com/bioinf-jku/SNNs.},
 author = {Klambauer, Günter and Unterthiner, Thomas and Mayr, Andreas and Hochreiter, Sepp},
 date = {2017-06-08},
 eprint = {1706.02515},
 eprinttype = {arxiv},
 pdf = {https://arxiv.org/pdf/1706.02515.pdf},
 selected = {false},
 title = {Self-{{Normalizing Neural Networks}}},
 url = {http://arxiv.org/abs/1706.02515},
 year = {2017},
 category={deep_learning}
}

@article{kratzertImprovedPredictionsUngauged2019,
 abstract = {Long short-term memory (LSTM) networks offer unprecedented accuracy for prediction in ungauged basins. We trained and tested several LSTMs on 531 basins from the CAMELS data set using k-fold validation, so that predictions were made in basins that supplied no training data. The training and test data set included ∼30 years of daily rainfall-runoff data from catchments in the United States ranging in size from 4 to 2,000 km2 with aridity index from 0.22 to 5.20, and including 12 of the 13 IGPB vegetated land cover classifications. This effectively “ungauged” model was benchmarked over a 15-year validation period against the Sacramento Soil Moisture Accounting (SAC-SMA) model and also against the NOAA National Water Model reanalysis. SAC-SMA was calibrated separately for each basin using 15 years of daily data. The out-of-sample LSTM had higher median Nash-Sutcliffe Efficiencies across the 531 basins (0.69) than either the calibrated SAC-SMA (0.64) or the National Water Model (0.58). This indicates that there is (typically) sufficient information in available catchment attributes data about similarities and differences between catchment-level rainfall-runoff behaviors to provide out-of-sample simulations that are generally more accurate than current models under ideal (i.e., calibrated) conditions. We found evidence that adding physical constraints to the LSTM models might improve simulations, which we suggest motivates future research related to physics-guided machine learning.},
 author = {Kratzert, Frederik and Klotz, Daniel and Herrnegger, Mathew and Sampson, Alden K. and Hochreiter, Sepp and Nearing, Grey S.},
 date = {2019},
 journaltitle = {Water Resources Research},
 number = {12},
 pages = {11344--11354},
 selected = {false},
 shorttitle = {Toward {{Improved Predictions}} in {{Ungauged Basins}}},
 title = {Toward {{Improved Predictions}} in {{Ungauged Basins}}: {{Exploiting}} the {{Power}} of {{Machine Learning}}},
 url = {https://doi.org/10.1029/2019WR026065},
 volume = {55},
 year = {2019},
 category = {ai4earth},
 abbr={WRR}
}

@article{kratzertLearningUniversalRegional2019,
 abstract = {{$<$}p{$><$}strong{$>$}Abstract.{$<$}/strong{$>$} Regional rainfall–runoff modeling is an old but still mostly outstanding problem in the hydrological sciences. The problem currently is that traditional hydrological models degrade significantly in performance when calibrated for multiple basins together instead of for a single basin alone. In this paper, we propose a novel, data-driven approach using Long Short-Term Memory networks (LSTMs) and demonstrate that under a “big data” paradigm, this is not necessarily the case. By training a single LSTM model on 531 basins from the CAMELS dataset using meteorological time series data and static catchment attributes, we were able to significantly improve performance compared to a set of several different hydrological benchmark models. Our proposed approach not only significantly outperforms hydrological models that were calibrated regionally, but also achieves better performance than hydrological models that were calibrated for each basin individually. Furthermore, we propose an adaption to the standard LSTM architecture, which we call an Entity-Aware-LSTM (EA-LSTM), that allows for learning catchment similarities as a feature layer in a deep learning model. We show that these learned catchment similarities correspond well to what we would expect from prior hydrological understanding.{$<$}/p{$>$}},
 author = {Kratzert, Frederik and Klotz, Daniel and Shalev, Guy and Klambauer, Günter and Hochreiter, Sepp and Nearing, Grey},
 date = {2019-12-17},
 journaltitle = {Hydrology and Earth System Sciences},
 number = {12},
 pages = {5089--5110},
 publisher = {{Copernicus GmbH}},
 selected = {false},
 title = {Towards Learning Universal, Regional, and Local Hydrological Behaviors via Machine Learning Applied to Large-Sample Datasets},
 url = {https://doi.org/10.5194/hess-23-5089-2019},
 volume = {23},
 year = {2019},
 category = {ai4earth},
 abbr={HESS}
}

@incollection{kratzertNeuralHydrologyInterpretingLSTMs2019,
 abstract = {Despite the huge success of Long Short-Term Memory networks, their applications in environmental sciences are scarce. We argue that one reason is the difficulty to interpret the internals of trained networks. In this study, we look at the application of LSTMs for rainfall-runoff forecasting, one of the central tasks in the field of hydrology, in which the river discharge has to be predicted from meteorological observations. LSTMs are particularly well-suited for this problem since memory cells can represent dynamic reservoirs and storages, which are essential components in state-space modelling approaches of the hydrological system. On basis of two different catchments, one with snow influence and one without, we demonstrate how the trained model can be analyzed and interpreted. In the process, we show that the network internally learns to represent patterns that are consistent with our qualitative understanding of the hydrological system.},
 author = {Kratzert, Frederik and Herrnegger, Mathew and Klotz, Daniel and Hochreiter, Sepp and Klambauer, Günter},
 date = {2019},
 pages = {347--362},
 publisher = {{Springer International Publishing}},
 selected = {false},
 title = {{{NeuralHydrology}} – {{Interpreting LSTMs}} in {{Hydrology}}},
 url = {https://doi.org/10.1007/978-3-030-28954-6_19},
 year = {2019},
 category = {ai4earth},
 abbr={Springer}
}

@article{mayrLargescaleComparisonMachine2018,
 abstract = {Deep learning is currently the most successful machine learning technique in a wide range of application areas and has recently been applied successfully in drug discovery research to predict potential drug targets and to screen for active molecules. However, due to (1) the lack of large-scale studies, (2) the compound series bias that is characteristic of drug discovery datasets and (3) the hyperparameter selection bias that comes with the high number of potential deep learning architectures, it remains unclear whether deep learning can indeed outperform existing computational methods in drug discovery tasks. We therefore assessed the performance of several deep learning methods on a large-scale drug discovery dataset and compared the results with those of other machine learning and target prediction methods. To avoid potential biases from hyperparameter selection or compound series, we used a nested cluster-cross-validation strategy. We found (1) that deep learning methods significantly outperform all competing methods and (2) that the predictive performance of deep learning is in many cases comparable to that of tests performed in wet labs (i.e., in vitro assays).},
 author = {Mayr, Andreas and Klambauer, Günter and Unterthiner, Thomas and Steijaert, Marvin and Wegner, Jörg K. and Ceulemans, Hugo and Clevert, Djork-Arné and Hochreiter, Sepp},
 date = {2018-06-06},
 journaltitle = {Chemical Science},
 selected = {false},
 title = {Large-Scale Comparison of Machine Learning Methods for Drug Target Prediction on {{ChEMBL}}},
 url = {https://doi.org/10.1039/C8SC00148K},
 year = {2018},
 category={ai_drug}
}

@article{mendenCommunityAssessmentAdvance2019,
 abstract = {The effectiveness of most cancer targeted therapies is short-lived. Tumors often develop resistance that might be overcome with drug combinations. However, the number of possible combinations is vast, necessitating data-driven approaches to find optimal patient-specific treatments. Here we report AstraZeneca’s large drug combination dataset, consisting of 11,576 experiments from 910 combinations across 85 molecularly characterized cancer cell lines, and results of a DREAM Challenge to evaluate computational strategies for predicting synergistic drug pairs and biomarkers. 160 teams participated to provide a comprehensive methodological development and benchmarking. Winning methods incorporate prior knowledge of drug-target interactions. Synergy is predicted with an accuracy matching biological replicates for {$>$}60\% of combinations. However, 20\% of drug combinations are poorly predicted by all methods. Genomic rationale for synergy predictions are identified, including ADAM17 inhibitor antagonism when combined with PIK3CB/D inhibition contrasting to synergy when combined with other PI3K-pathway inhibitors in PIK3CA mutant cells.},
 author = {Menden, Michael P. and Wang, Dennis and Mason, Mike J. and Szalai, Bence and Bulusu, Krishna C. and Guan, Yuanfang and Yu, Thomas and Kang, Jaewoo and Jeon, Minji and Wolfinger, Russ and Nguyen, Tin and Zaslavskiy, Mikhail and Jang, In Sock and Ghazoui, Zara and Ahsen, Mehmet Eren and Vogel, Robert and Neto, Elias Chaibub and Norman, Thea and Tang, Eric K. Y. and Garnett, Mathew J. and Veroli, Giovanni Y. Di and Fawell, Stephen and Stolovitzky, Gustavo and Guinney, Justin and Dry, Jonathan R. and Saez-Rodriguez, Julio},
 date = {2019-06-17},
 journaltitle = {Nature Communications},
 number = {1},
 pages = {2674},
 publisher = {{Nature Publishing Group}},
 selected = {false},
 title = {Community Assessment to Advance Computational Prediction of Cancer Drug Combinations in a Pharmacogenomic Screen},
 url = {https://doi.org/10.1038/s41467-019-09799-2},
 volume = {10},
 year = {2019},
 category={ai_drug}
}

@article{povysilPanelcnMOPSCopynumber2017,
 abstract = {Targeted next-generation-sequencing (NGS) panels have largely replaced Sanger sequencing in clinical diagnostics. They allow for the detection of copy-number variations (CNVs) in addition to single-nucleotide variants and small insertions/deletions. However, existing computational CNV detection methods have shortcomings regarding accuracy, quality control (QC), incidental findings, and user-friendliness. We developed panelcn.MOPS, a novel pipeline for detecting CNVs in targeted NGS panel data. Using data from 180 samples, we compared panelcn.MOPS with five state-of-the-art methods. With panelcn.MOPS leading the field, most methods achieved comparably high accuracy. panelcn.MOPS reliably detected CNVs ranging in size from part of a region of interest (ROI), to whole genes, which may comprise all ROIs investigated in a given sample. The latter is enabled by analyzing reads from all ROIs of the panel, but presenting results exclusively for user-selected genes, thus avoiding incidental findings. Additionally, panelcn.MOPS offers QC criteria not only for samples, but also for individual ROIs within a sample, which increases the confidence in called CNVs. panelcn.MOPS is freely available both as R package and standalone software with graphical user interface that is easy to use for clinical geneticists without any programming experience. panelcn.MOPS combines high sensitivity and specificity with user-friendliness rendering it highly suitable for routine clinical diagnostics.},
 author = {Povysil, Gundula and Tzika, Antigoni and Vogt, Julia and Haunschmid, Verena and Messiaen, Ludwine and Zschocke, Johannes and Klambauer, Günter and Hochreiter, Sepp and Wimmer, Katharina},
 date = {2017},
 journaltitle = {Human Mutation},
 number = {7},
 pages = {889--897},
 selected = {false},
 shorttitle = {Panelcn.{{MOPS}}},
 title = {Panelcn.{{MOPS}}: {{Copy}}-Number Detection in Targeted {{NGS}} Panel Data for Clinical Diagnostics},
 url = {https://doi.org/10.1002/humu.23237},
 volume = {38},
 year = {2017},
 category={ai_drug}
}

@article{preuerDeepSynergyPredictingAnticancer2018,
 abstract = {While drug combination therapies are a well-established concept in cancer treatment, identifying novel synergistic combinations is challenging due to the size of combinatorial space. However, computational approaches have emerged as a time- and cost-efficient way to prioritize combinations to test, based on recently available large-scale combination screening data. Recently, Deep Learning has had an impact in many research areas by achieving new state-of-the-art model performance. However, Deep Learning has not yet been applied to drug synergy prediction, which is the approach we present here, termed DeepSynergy. DeepSynergy uses chemical and genomic information as input information, a normalization strategy to account for input data heterogeneity, and conical layers to model drug synergies.DeepSynergy was compared to other machine learning methods such as Gradient Boosting Machines, Random Forests, Support Vector Machines and Elastic Nets on the largest publicly available synergy dataset with respect to mean squared error. DeepSynergy significantly outperformed the other methods with an improvement of 7.2\% over the second best method at the prediction of novel drug combinations within the space of explored drugs and cell lines. At this task, the mean Pearson correlation coefficient between the measured and the predicted values of DeepSynergy was 0.73. Applying DeepSynergy for classification of these novel drug combinations resulted in a high predictive performance of an AUC of 0.90. Furthermore, we found that all compared methods exhibit low predictive performance when extrapolating to unexplored drugs or cell lines, which we suggest is due to limitations in the size and diversity of the dataset. We envision that DeepSynergy could be a valuable tool for selecting novel synergistic drug combinations.DeepSynergy is available via www.bioinf.jku.at/software/DeepSynergy.Supplementary data are available at Bioinformatics online.},
 author = {Preuer, Kristina and Lewis, Richard P I and Hochreiter, Sepp and Bender, Andreas and Bulusu, Krishna C and Klambauer, Günter},
 date = {2018-05-01},
 journaltitle = {Bioinformatics},
 number = {9},
 pages = {1538--1546},
 selected = {false},
 shorttitle = {{{DeepSynergy}}},
 title = {{{DeepSynergy}}: Predicting Anti-Cancer Drug Synergy with {{Deep Learning}}},
 url = {https://doi.org/10.1093/bioinformatics/btx806},
 volume = {34},
 year = {2018},
 category={ai_drug}
}

@article{preuerFrechetChemNetDistance2018,
 abstract = {The new wave of successful generative models in machine learning has increased the interest in deep learning driven de novo drug design. However, method comparison is difficult because of various flaws of the currently employed evaluation metrics. We propose an evaluation metric for generative models called Fréchet ChemNet distance (FCD). The advantage of the FCD over previous metrics is that it can detect whether generated molecules are diverse and have similar chemical and biological properties as real molecules.},
 author = {Preuer, Kristina and Renz, Philipp and Unterthiner, Thomas and Hochreiter, Sepp and Klambauer, Günter},
 date = {2018-09-24},
 journaltitle = {Journal of Chemical Information and Modeling},
 number = {9},
 pages = {1736--1741},
 publisher = {{American Chemical Society}},
 selected = {false},
 shorttitle = {Fréchet {{ChemNet Distance}}},
 title = {Fréchet {{ChemNet Distance}}: {{A Metric}} for {{Generative Models}} for {{Molecules}} in {{Drug Discovery}}},
 url = {https://doi.org/10.1021/acs.jcim.8b00234},
 volume = {58},
 year = {2018},
 category={ai_drug}
}

@incollection{preuerInterpretableDeepLearning2019,
 abstract = {Without any means of interpretation, neural networks that predict molecular properties and bioactivities are merely black boxes. We will unravel these black boxes and will demonstrate approaches to understand the learned representations which are hidden inside these models. We show how single neurons can be interpreted as classifiers which determine the presence or absence of pharmacophore- or toxicophore-like structures, thereby generating new insights and relevant knowledge for chemistry, pharmacology and biochemistry. We further discuss how these novel pharmacophores/toxicophores can be determined from the network by identifying the most relevant components of a compound for the prediction of the network. Additionally, we propose a method which can be used to extract new pharmacophores from a model and will show that these extracted structures are consistent with literature findings. We envision that having access to such interpretable knowledge is a crucial aid in the development and design of new pharmaceutically active molecules, and helps to investigate and understand failures and successes of current methods.},
 author = {Preuer, Kristina and Klambauer, Günter and Rippmann, Friedrich and Hochreiter, Sepp and Unterthiner, Thomas},
 date = {2019},
 pages = {331--345},
 publisher = {{Springer International Publishing}},
 selected = {false},
 title = {Interpretable {{Deep Learning}} in {{Drug Discovery}}},
 url = {https://doi.org/10.1007/978-3-030-28954-6_18},
 year = {2019},
 category={ai_drug}
}

@article{renzFailureModesMolecule2020a,
 abstract = {There has been a wave of generative models for molecules triggered by advances in the field of Deep Learning. These generative models are often used to optimize chemical compounds towards particular properties or a desired biological activity. The evaluation of generative models remains challenging and suggested performance metrics or scoring functions often do not cover all relevant aspects of drug design projects. In this work, we highlight some unintended failure modes in molecular generation and optimization and how these evade detection by current performance metrics.},
 author = {Renz, Philipp and Van Rompaey, Dries and Wegner, Jörg Kurt and Hochreiter, Sepp and Klambauer, Günter},
 date = {2020-10-24},
 journaltitle = {Drug Discovery Today: Technologies},
 selected = {true},
 title = {On Failure Modes in Molecule Generation and Optimization},
 url = {https://doi.org/10.1016/j.ddtec.2020.09.003},
 year = {2020},
 code = {https://github.com/ml-jku/mgenerators-failure-modes},
 software = {true},
 category={ai_drug}
}

@article{renzUncertaintyEstimationMethods2019,
 abbr={NeurIPS},
 abstract = {It takes about a decade to develop a new drug by a process in which a large number of decisions have to be made. Those decisions are critical for the success or failure of a multi-million dollar drug discovery project, which could save many lives or increase life quality. Decisions in early phases of drug discovery, such as the selection of certain series of chemical compounds, are particularly impactful on the success rate. Machine learning models are increasingly used to inform the decision making process by predicting desired effects, undesired effects, such as toxicity, molecular properties, or which wet-lab test to perform next. Thus, accurately quantifying the uncertainties of the models’ outputs is critical, for example, in order to calculate expected utilities, to estimate the risk and the potential gain. In this work, we review, assess and compare recent uncertainty estimation methods with respect to their use in drug discovery projects. We test both, which methods give well calibrated prediction and which ones perform well at misclassification detection. For the latter, we find the entropy of the predictive distribution performs best. Finally, we discuss the problem of defining out-of-distribution samples for prediction tasks on chemical compounds.},
 author = {Renz, Philipp and Hochreiter, Sepp and Klambauer, Günter},
 date = {2019},
 journaltitle = {NeurIPS-2019 Workshop on  Safety and Robustness in Decision Making},
 selected = {false},
 title = {Uncertainty {{Estimation Methods}} to {{Support Decision}}-{{Making}} in {{Early Phases}} of {{Drug Discovery}}},
 year = {2019},
 category={ai_drug}
}

@inproceedings{rumetshoferHumanlevelProteinLocalization2018,
 abbr={ICLR},
 abstract = {Localizing a specific protein in a human cell is essential for understanding cellular functions and biological processes of underlying diseases. A promising, low-cost,and time-efficient...},
 author = {Rumetshofer, Elisabeth and Hofmarcher, Markus and Röhrl, Clemens and Hochreiter, Sepp and Klambauer, Günter},
 date = {2018-09-27},
 eventtitle = {International Conference on Learning Representations},
 selected = {false},
 title = {Human-Level {{Protein Localization}} with {{Convolutional Neural Networks}}},
 url = {https://openreview.net/forum?id=ryl5khRcKm},
 year = {2018},
 category={ai_healthcare}
}

@online{sewardFirstOrderGenerative2018,
 abstract = {GANs excel at learning high dimensional distributions, but they can update generator parameters in directions that do not correspond to the steepest descent direction of the objective. Prominent examples of problematic update directions include those used in both Goodfellow's original GAN and the WGAN-GP. To formally describe an optimal update direction, we introduce a theoretical framework which allows the derivation of requirements on both the divergence and corresponding method for determining an update direction, with these requirements guaranteeing unbiased mini-batch updates in the direction of steepest descent. We propose a novel divergence which approximates the Wasserstein distance while regularizing the critic's first order information. Together with an accompanying update direction, this divergence fulfills the requirements for unbiased steepest descent updates. We verify our method, the First Order GAN, with image generation on CelebA, LSUN and CIFAR-10 and set a new state of the art on the One Billion Word language generation task. Code to reproduce experiments is available.},
 author = {Seward, Calvin and Unterthiner, Thomas and Bergmann, Urs and Jetchev, Nikolay and Hochreiter, Sepp},
 date = {2018-06-07},
 eprint = {1802.04591},
 eprinttype = {arxiv},
 pdf = {https://arxiv.org/pdf/1802.04591.pdf},
 selected = {false},
 title = {First {{Order Generative Adversarial Networks}}},
 url = {http://arxiv.org/abs/1802.04591},
 year = {2018},
 category={deep_learning}
}

@article{steinwandterMultivariateAnalyticsChromatographic2018,
 abstract = {Chromatography is one of the most versatile unit operations in the biotechnological industry. Regulatory initiatives like Process Analytical Technology and Quality by Design led to the implementation of new chromatographic devices. Those represent an almost inexhaustible source of data. However, the analysis of large datasets is complicated, and significant amounts of information stay hidden in big data. Here we present a new, top-down approach for the systematic analysis of chromatographic datasets. It is the goal of this approach to analyze the dataset as a whole, starting with the most important, global information. The workflow should highlight interesting regions (outliers, drifts, data inconsistencies), and help to localize those regions within a multi-dimensional space in a straightforward way. Moving window factor models were used to extract the most important information, focusing on the differences between samples. The prototype was implemented as an interactive visualization tool for the explorative analysis of complex datasets. We found that the tool makes it convenient to localize variances in a multidimensional dataset and allows to differentiate between explainable and unexplainable variance. Starting with one global difference descriptor per sample, the analysis ends up with highly resolute temporally dependent difference descriptor values, thought as a starting point for the detailed analysis of the underlying raw data.},
 author = {Steinwandter, Valentin and Šišmiš, Michal and Sagmeister, Patrick and Bodenhofer, Ulrich and Herwig, Christoph},
 date = {2018-08-15},
 journaltitle = {Journal of Chromatography B},
 pages = {179--190},
 selected = {false},
 shorttitle = {Multivariate Analytics of Chromatographic Data},
 title = {Multivariate Analytics of Chromatographic Data: {{Visual}} Computing Based on Moving Window Factor Models},
 url = {https://doi.org/10.1016/j.jchromb.2018.06.010},
 volume = {1092},
 year = {2018}
}

@article{sturmIndustryscaleApplicationEvaluation2020,
 abstract = {Artificial intelligence (AI) is undergoing a revolution thanks to the breakthroughs of machine learning algorithms in computer vision, speech recognition, natural language processing and generative modelling. Recent works on publicly available pharmaceutical data showed that AI methods are highly promising for Drug Target prediction. However, the quality of public data might be different than that of industry data due to different labs reporting measurements, different measurement techniques, fewer samples and less diverse and specialized assays. As part of a European funded project (ExCAPE), that brought together expertise from pharmaceutical industry, machine learning, and high-performance computing, we investigated how well machine learning models obtained from public data can be transferred to internal pharmaceutical industry data. Our results show that machine learning models trained on public data can indeed maintain their predictive power to a large degree when applied to industry data. Moreover, we observed that deep learning derived machine learning models outperformed comparable models, which were trained by other machine learning algorithms, when applied to internal pharmaceutical company datasets. To our knowledge, this is the first large-scale study evaluating the potential of machine learning and especially deep learning directly at the level of industry-scale settings and moreover investigating the transferability of publicly learned target prediction models towards industrial bioactivity prediction pipelines.},
 author = {Sturm, Noé and Mayr, Andreas and Le Van, Thanh and Chupakhin, Vladimir and Ceulemans, Hugo and Wegner, Joerg and Golib-Dzib, Jose-Felipe and Jeliazkova, Nina and Vandriessche, Yves and Böhm, Stanislav and Cima, Vojtech and Martinovic, Jan and Greene, Nigel and Vander Aa, Tom and Ashby, Thomas J. and Hochreiter, Sepp and Engkvist, Ola and Klambauer, Günter and Chen, Hongming},
 date = {2020-11-19},
 journaltitle = {Journal of Cheminformatics},
 number = {1},
 pages = {26},
 selected = {false},
 title = {Industry-Scale Application and Evaluation of Deep Learning for Drug Target Prediction},
 url = {https://doi.org/10.1186/s13321-020-00428-5},
 volume = {12},
 year = {2020},
 category={ai_drug},
 abbr={Springer},
 selected={True}
}

@online{unterthinerCoulombGANsProvably2018,
 abstract = {Generative adversarial networks (GANs) evolved into one of the most successful unsupervised techniques for generating realistic images. Even though it has recently been shown that GAN training converges, GAN models often end up in local Nash equilibria that are associated with mode collapse or otherwise fail to model the target distribution. We introduce Coulomb GANs, which pose the GAN learning problem as a potential field of charged particles, where generated samples are attracted to training set samples but repel each other. The discriminator learns a potential field while the generator decreases the energy by moving its samples along the vector (force) field determined by the gradient of the potential field. Through decreasing the energy, the GAN model learns to generate samples according to the whole target distribution and does not only cover some of its modes. We prove that Coulomb GANs possess only one Nash equilibrium which is optimal in the sense that the model distribution equals the target distribution. We show the efficacy of Coulomb GANs on a variety of image datasets. On LSUN and celebA, Coulomb GANs set a new state of the art and produce a previously unseen variety of different samples.},
 author = {Unterthiner, Thomas and Nessler, Bernhard and Seward, Calvin and Klambauer, Günter and Heusel, Martin and Ramsauer, Hubert and Hochreiter, Sepp},
 date = {2018-01-30},
 eprint = {1708.08819},
 eprinttype = {arxiv},
 selected = {false},
 shorttitle = {Coulomb {{GANs}}},
 title = {Coulomb {{GANs}}: {{Provably Optimal Nash Equilibria}} via {{Potential Fields}}},
 url = {http://arxiv.org/abs/1708.08819},
 year = {2018},
 category={deep_learning}
}

@article{widrichDeepRCImmuneRepertoire2020,
 abbr={bioarXiv},
 abstract = {{$<$}h3{$>$}Abstract{$<$}/h3{$>$} {$<$}p{$>$}High-throughput immunosequencing allows reconstructing the immune repertoire of an individual, which is a unique opportunity for new immunotherapies, immunodiagnostics, and vaccine design. Since immune repertoires are shaped by past and current immune events, such as infection and disease, and thus record an individual’s state of health, immune repertoire sequencing data may enable the prediction of health and disease using machine learning. However, finding the connections between an individual’s repertoire and the individual’s disease class, with potentially hundreds of thousands to millions of short sequences per individual, poses a difficult and unique challenge for machine learning methods. In this work, we present our method DeepRC that combines a Deep Learning architecture with attentionbased multiple instance learning. To validate that DeepRC accurately predicts an individual’s disease class based on its immune repertoire and determines the associated class-specific sequence motifs, we applied DeepRC in four large-scale experiments encompassing ground-truth simulated as well as real-world virus infection data. We demonstrate that DeepRC outperforms all tested methods with respect to predictive performance and enables the extraction of those sequence motifs that are connected to a given disease class.{$<$}/p{$>$}},
 author = {Widrich, Michael and Schäfl, Bernhard and Pavlović, Milena and Sandve, Geir Kjetil and Hochreiter, Sepp and Greiff, Victor and Klambauer, Günter},
 date = {2020-04-13},
 journaltitle = {bioRxiv},
 pages = {2020.04.12.038158},
 publisher = {{Cold Spring Harbor Laboratory}},
 selected = {false},
 shorttitle = {{{DeepRC}}},
 title = {{{DeepRC}}: {{Immune}} Repertoire Classification with Attention-Based Deep Massive Multiple Instance Learning},
 url = {https://doi.org/10.1101/2020.04.12.038158},
 year = {2020},
 category={deep_learning}
}

@inproceedings{lehner2019,
  abbr={NeurIPS},
  title = {Patch Refinement – Localized {{3D}} Object Detection},
  booktitle = {Workshop on Machine Learning for Autonomous Driving, Neural Information Processing Systems ({{NeurIPS}})},
  author = {Lehner, Johannes and 
            Mitterecker, Andreas and 
            Adler, Thomas and 
            Hofmarcher, Markus and 
            Nessler, Bernhard and 
            Hochreiter, Sepp},
  date = {2019}
}

@inproceedings{treml2016,
  abbr={NeurIPS},
  title = {Speeding up Semantic Segmentation for Autonomous Driving},
  booktitle = {Workshop on Machine Learning for Intelligent Transport Systems, Neural Information Processing Systems ({{NIPS}})},
  author = {Treml, Michael and 
            Arjona-Medina, José and 
            Unterthiner, Thomas and 
            Durgesh, Rupesh and 
            Friedmann, Felix and 
            Schuberth, Peter and 
            Mayr, Andreas and 
            Heusel, Martin and 
            Hofmarcher, Markus and 
            Widrich, Michael and 
            Bodenhofer, Ulrich and 
            Nessler, Bernhard and 
            Hochreiter, Sepp},
  date = {2016}
}

@article{hofmarcher2019,
  abbr={JCIM},
  title = {Accurate {{Prediction}} of {{Biological Assays}} with {{High}}-{{Throughput Microscopy Images}} and {{Convolutional Networks}}},
  author = {Hofmarcher, Markus and 
            Rumetshofer, Elisabeth and 
            Clevert, Djork-Arné and 
            Hochreiter, Sepp and 
            Klambauer, Günter},
  date = {2019-03-25},
  journaltitle = {Journal of Chemical Information and Modeling},
  shortjournal = {J. Chem. Inf. Model.},
  volume = {59},
  pages = {1163--1171},
  publisher = {{American Chemical Society}},
  issn = {1549-9596},
  doi = {10.1021/acs.jcim.8b00670},
  url = {https://doi.org/10.1021/acs.jcim.8b00670},
  urldate = {2020-06-01},
  abstract = {Predicting the outcome of biological assays based on high-throughput imaging data is a highly promising task in drug discovery since it can tremendously increase hit rates and suggest novel chemical scaffolds. However, end-to-end learning with convolutional neural networks (CNNs) has not been assessed for the task biological assay prediction despite the success of these networks at visual recognition. We compared several CNNs trained directly on high-throughput imaging data to a) CNNs trained on cell-centric crops and to b) the current state-of-the-art: fully connected networks trained on precalculated morphological cell features. The comparison was performed on the Cell Painting data set, the largest publicly available data set of microscopic images of cells with approximately 30,000 compound treatments. We found that CNNs perform significantly better at predicting the outcome of assays than fully connected networks operating on precomputed morphological features of cells. Surprisingly, the best performing method could predict 32\% of the 209 biological assays at high predictive performance (AUC {$>$} 0.9) indicating that the cell morphology changes contain a large amount of information about compound activities. Our results suggest that many biological assays could be replaced by high-throughput imaging together with convolutional neural networks and that the costly cell segmentation and feature extraction step can be replaced by convolutional neural networks.},
  number = {3}
}


@article{kimeswenger2020ArtificialNeuralNetworks,
  title = {Artificial Neural Networks and Pathologists Recognize Basal Cell Carcinomas Based on Different Histological Patterns},
  author = {Kimeswenger, Susanne and 
            Tschandl, Philipp and 
            Noack, Petar and 
            Hofmarcher, Markus and 
            Rumetshofer, Elisabeth and 
            Kindermann, Harald and 
            Silye, Rene and 
            Hochreiter, Sepp and 
            Kaltenbrunner, Martin and 
            Guenova, Emmanuella and 
            Klambauer, Guenter and 
            Hoetzenecker, Wolfram},
  date = {2020-11-13},
  journaltitle = {Modern Pathology},
  pages = {1--9},
  publisher = {{Nature Publishing Group}},
  issn = {1530-0285},
  doi = {10.1038/s41379-020-00712-7},
  url = {https://www.nature.com/articles/s41379-020-00712-7},
  urldate = {2020-12-03},
  abstract = {Recent advances in artificial intelligence, particularly in the field of deep learning, have enabled researchers to create compelling algorithms for medical image analysis. Histological slides of basal cell carcinomas (BCCs), the most frequent skin tumor, are accessed by pathologists on a daily basis and are therefore well suited for automated prescreening by neural networks for the identification of cancerous regions and swift tumor classification.},
  langid = {english}
}
