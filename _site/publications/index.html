<!DOCTYPE html>
<html>

  <head>
    <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta http-equiv="X-UA-Compatible" content="IE=edge">

<title>Institute for Machine Learning @ JKU | publications</title>
<meta name="description" content="Research blog of the Institute for Machine Learning @ JKU.
">

<!-- Open Graph -->


<!-- Bootstrap & MDB -->
<link href="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/css/bootstrap.min.css" rel="stylesheet" integrity="sha512-MoRNloxbStBcD8z3M/2BmnT+rg4IsMxPkXaGh2zD6LGNNFE80W3onsAhRcMAMrSoyWL9xD7Ert0men7vR8LUZg==" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.19.1/css/mdb.min.css" integrity="sha512-RO38pBRxYH3SoOprtPTD86JFOclM51/XTIdEPh5j8sj4tp8jmQIx26twG52UaLi//hQldfrh7e51WzP9wuP32Q==" crossorigin="anonymous" />

<!-- Fonts & Icons -->
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css"  integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.9.0/css/academicons.min.css" integrity="sha512-W4yqoT1+8NLkinBLBZko+dFB2ZbHsYLDdr50VElllRcNt2Q4/GSs6u71UHKxB7S6JEMCp5Ve4xjh3eGQl/HRvg==" crossorigin="anonymous">
<link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">

<!-- Code Syntax Highlighting -->
<link rel="stylesheet" href="https://gitcdn.link/repo/jwarby/jekyll-pygments-themes/master/github.css" />

<!-- Styles -->
<link rel="shortcut icon" href="/assets/img/favicon.ico">
<link rel="stylesheet" href="/assets/css/main.css">

<link rel="canonical" href="/publications/">

<!-- Theming-->




    
<!-- MathJax -->
<script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.1.2/es5/tex-mml-chtml.js"></script>
<script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>


  </head>


  <body class="fixed-top-nav ">


    <!-- Header -->

    <!-- <div class="container-fluid mx-0 px-0">
  <div class="logo d-flex justify-content-center align-items-center">
    <img class="jku-logo img-fluid rounded" src="/assets/img/jku_ml_1.svg" width=120px height=40px>
    <img class="ellis-logo img-fluid rounded" src="/assets/img/ellis_linz.jpeg" width=250px height=40px>
  </div>
</div> -->


<header>
    <!-- Nav Bar -->

      <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top">
        <a class="navbar-brand title font-weight-lighter">
         <!-- <span>Institute</span> for Machine  Learning @ JKU -->
         <img class="rounded" src="/assets/img/jku_ml_1.svg" width=100px height=45px>
         <img class="rounded" src="/assets/img/ellis_linz.jpeg" width=200px height=45px>
        </a>
    <div class="container">
      
      <!-- Navbar Toogle -->
      <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar top-bar"></span>
        <span class="icon-bar middle-bar"></span>
        <span class="icon-bar bottom-bar"></span>
      </button>
      <div class="collapse navbar-collapse text-right" id="navbarNav">
        <ul class="navbar-nav ml-auto flex-nowrap">
          <!-- About -->
          <li class="nav-item ">
            <a class="nav-link" href="/">
              about
              
            </a>
          </li>
          
          <!-- Blog -->
          <li class="nav-item ">
            <a class="nav-link" href="/blog/">
              blog
              
            </a>
          </li>
          
          <!-- Other pages -->
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          <li class="nav-item ">
              <a class="nav-link" href="https://www.jku.at/en/institute-for-machine-learning/" target="_blank" rel="noopener noreferrer">
                contact
                
              </a>
          </li>
          
          
          
          
          
          
          
          <li class="nav-item ">
              <a class="nav-link" href="https://www.jku.at/en/institute-for-machine-learning/about-us/team/" target="_blank" rel="noopener noreferrer">
                people
                
              </a>
          </li>
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          <li class="nav-item active">
                
                <a class="nav-link" href="/publications/">
                  publications
                  
                  <span class="sr-only">(current)</span>
                  
                </a>
                
          </li>
          
          
          
          
          
          <li class="nav-item ">
                
                    <div class="dropdown">
                      <a class="nav-link" href="/research/">
                        research
                        
                      </a>
                        <div class="dropdown-content">
                          <a href="/research/deep_learning">Deep Learning</a>
                          <a href="/research/ai_healthcare">AI in Health Care</a>
                          <a href="/research/ai_drug">AI in Drug Discovery</a>
                          <a href="/research/reinforcement_learning">Reinforcement Learning</a>
                          <a href="/research/hopfield_networks">Modern Hopfield Networks</a>
                          <a href="/research/ai4earth">AI 4 Earth</a>
                          <a href="/research/ai4drive">AI 4 Drive</a>
                        </div>
                      </div>
                    
                
          </li>
          
          
          
          
          
          <li class="nav-item ">
                
                <a class="nav-link" href="/software/">
                  software
                  
                </a>
                
          </li>
          
          
          
          
          
          <li class="nav-item ">
                
                <a class="nav-link" href="/talks/">
                  talks
                  
                </a>
                
          </li>
          
          
          
          
          
          
        </ul>
      </div>
    </div>
  </nav>

</header>


    <!-- Content -->

    <div class="container mt-5">
      <div class="post">

  <header class="post-header">
    
    <h1 class="post-title">publications</h1>
    <p class="post-description">publications in reverse chronological order.</p>
    
  </header>

  <article>
    <div class="about-text">
    <div class="publications">


  <h2 class="year">2020</h2>
  <ol class="bibliography"><li><div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">bioarXiv</abbr>
    
  
  </div>

  <div id="widrichDeepRCImmuneRepertoire2020" class="col-sm-8">
    
      <div class="title">DeepRC: Immune Repertoire Classification with Attention-Based Deep Massive Multiple Instance Learning</div>
      <div class="author">
        
          
            
              
                
                  Widrich, M.,
                
              
            
          
        
          
            
              
                
                  Schäfl, B.,
                
              
            
          
        
          
            
              
                
                  Pavlović, M.,
                
              
            
          
        
          
            
              
                
                  Sandve, G.,
                
              
            
          
        
          
            
              
                
                  Hochreiter, S.,
                
              
            
          
        
          
            
              
                
                  Greiff, V.,
                
              
            
          
        
          
            
              
                
                  and Klambauer, G.
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em></em>
      
      
        2020
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
      <a href="https://doi.org/10.1101/2020.04.12.038158" class="btn btn-sm z-depth-0" role="button" target="_blank">url</a>
    
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p><h3>Abstract</h3> <p>High-throughput immunosequencing allows reconstructing the immune repertoire of an individual, which is a unique opportunity for new immunotherapies, immunodiagnostics, and vaccine design. Since immune repertoires are shaped by past and current immune events, such as infection and disease, and thus record an individual’s state of health, immune repertoire sequencing data may enable the prediction of health and disease using machine learning. However, finding the connections between an individual’s repertoire and the individual’s disease class, with potentially hundreds of thousands to millions of short sequences per individual, poses a difficult and unique challenge for machine learning methods. In this work, we present our method DeepRC that combines a Deep Learning architecture with attentionbased multiple instance learning. To validate that DeepRC accurately predicts an individual’s disease class based on its immune repertoire and determines the associated class-specific sequence motifs, we applied DeepRC in four large-scale experiments encompassing ground-truth simulated as well as real-world virus infection data. We demonstrate that DeepRC outperforms all tested methods with respect to predictive performance and enables the extraction of those sequence motifs that are connected to a given disease class.</p></p>
    </div>
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">arXiv</abbr>
    
  
  </div>

  <div id="adler2020cross" class="col-sm-8">
    
      <div class="title">Cross-Domain Few-Shot Learning by Representation Fusion</div>
      <div class="author">
        
          
            
              
                
                  Adler, T.,
                
              
            
          
        
          
            
              
                
                  Brandstetter, J.,
                
              
            
          
        
          
            
              
                
                  Widrich, M.,
                
              
            
          
        
          
            
              
                
                  Mayr, A.,
                
              
            
          
        
          
            
              
                
                  Kreil, D.,
                
              
            
          
        
          
            
              
                
                  Kopp, M.,
                
              
            
          
        
          
            
              
                
                  Klambauer, G.,
                
              
            
          
        
          
            
              
                
                  and Hochreiter, S.
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>arXiv preprint arXiv:2010.06498</em>
      
      
        2020
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
      <a href="https://arxiv.org/abs/2010.06498" class="btn btn-sm z-depth-0" role="button" target="_blank">url</a>
    
    
    
    
    
      <a href="https://ml-jku.github.io/chef/" class="btn btn-sm z-depth-0" role="button" target="_blank">Blog</a>
    
    
      <a href="https://github.com/ml-jku/chef" class="btn btn-sm z-depth-0" role="button" target="_blank">Code</a>
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>In order to quickly adapt to new data, few-shot learning aims at learning from few examples, often by using already acquired knowledge. The new data often differs from the previously seen data due to a domain shift, that is, a change of the input-target distribution. While several methods perform well on small domain shifts like new target classes with similar inputs, larger domain shifts are still challenging. Large domain shifts may result in high-level concepts that are not shared between the original and the new domain. However, low-level concepts like edges in images might still be shared and useful. For cross-domain few-shot learning, we suggest representation fusion to unify different abstraction levels of a deep neural network into one representation. We propose Cross-domain Hebbian Ensemble Few-shot learning (CHEF), which achieves representation fusion by an ensemble of Hebbian learners acting on different layers of a deep neural network that was trained on the original domain. On the few-shot datasets miniImagenet and tieredImagenet, where the domain shift is small, CHEF is competitive with state-of-the-art methods. On cross-domain few-shot benchmark challenges with larger domain shifts, CHEF establishes novel state-of-the-art results in all categories. We further apply CHEF on a real-world cross-domain application in drug discovery. We consider a domain shift from bioactive molecules to environmental chemicals and drugs with twelve associated toxicity prediction tasks. On these tasks, that are highly relevant for computational drug discovery, CHEF significantly outperforms all its competitors.</p>
    </div>
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">arXiv</abbr>
    
  
  </div>

  <div id="patil2020alignrudder" class="col-sm-8">
    
      <div class="title">Align-RUDDER: Learning From Few Demonstrations by Reward Redistribution</div>
      <div class="author">
        
          
            
              
                
                  Patil, V.,
                
              
            
          
        
          
            
              
                
                  Hofmarcher, M.,
                
              
            
          
        
          
            
              
                
                  Dinu, M.,
                
              
            
          
        
          
            
              
                
                  Dorfer, M.,
                
              
            
          
        
          
            
              
                
                  Blies, P.,
                
              
            
          
        
          
            
              
                
                  Brandstetter, J.,
                
              
            
          
        
          
            
              
                
                  Arjona-Medina, J.,
                
              
            
          
        
          
            
              
                
                  and Hochreiter, S.
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>arXiv preprint arXiv:2009.14108</em>
      
      
        2020
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
      <a href="https://arxiv.org/abs/2009.14108" class="btn btn-sm z-depth-0" role="button" target="_blank">url</a>
    
    
    
    
    
    
      <a href="https://github.com/ml-jku/align-rudder" class="btn btn-sm z-depth-0" role="button" target="_blank">Code</a>
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Reinforcement Learning algorithms require a large number of samples to solve complex tasks with sparse and delayed rewards. Complex tasks can often be hierarchically decomposed into sub-tasks. A step in the Q-function can be associated with solving a sub-task, where the expectation of the return increases. RUDDER has been introduced to identify these steps and then redistribute reward to them, thus immediately giving reward if sub-tasks are solved. Since the problem of delayed rewards is mitigated, learning is considerably sped up. However, for complex tasks, current exploration strategies as deployed in RUDDER struggle with discovering episodes with high rewards. Therefore, we assume that episodes with high rewards are given as demonstrations and do not have to be discovered by exploration. Typically the number of demonstrations is small and RUDDER’s LSTM model as a deep learning method does not learn well. Hence, we introduce Align-RUDDER, which is RUDDER with two major modifications. First, Align-RUDDER assumes that episodes with high rewards are given as demonstrations, replacing RUDDER’s safe exploration and lessons replay buffer. Second, we replace RUDDER’s LSTM model by a profile model that is obtained from multiple sequence alignment of demonstrations. Profile models can be constructed from as few as two demonstrations as known from bioinformatics. Align-RUDDER inherits the concept of reward redistribution, which considerably reduces the delay of rewards, thus speeding up learning. Align-RUDDER outperforms competitors on complex artificial tasks with delayed reward and few demonstrations. On the MineCraft ObtainDiamond task, Align-RUDDER is able to mine a diamond, though not frequently.</p>
    </div>
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">NeurIPS</abbr>
    
  
  </div>

  <div id="widrich2020modern" class="col-sm-8">
    
      <div class="title">Modern Hopfield networks and attention for immune repertoire classification</div>
      <div class="author">
        
          
            
              
                
                  Widrich, M.,
                
              
            
          
        
          
            
              
                
                  Schäfl, B.,
                
              
            
          
        
          
            
              
                
                  Ramsauer, H.,
                
              
            
          
        
          
            
              
                
                  Pavlović, M.,
                
              
            
          
        
          
            
              
                
                  Gruber, L.,
                
              
            
          
        
          
            
              
                
                  Holzleitner, M.,
                
              
            
          
        
          
            
              
                
                  Brandstetter, J.,
                
              
            
          
        
          
            
              
                
                  Sandve, G.,
                
              
            
          
        
          
            
              
                
                  Greiff, V.,
                
              
            
          
        
          
            
              
                
                  Hochreiter, S.,
                
              
            
          
        
          
            
              
                
                  and others, .
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>arXiv preprint arXiv:2007.13505</em>
      
      
        2020
      
      </div>
    

    <div class="links">
    
    
      <a href="http://arxiv.org/abs/2007.13505" class="btn btn-sm z-depth-0" role="button" target="_blank">arXiv</a>
    
    
    
    
    
    
    
      <a href="https://github.com/ml-jku/DeepRC" class="btn btn-sm z-depth-0" role="button" target="_blank">Code</a>
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">arXiv</abbr>
    
  
  </div>

  <div id="hofmarcherLargescaleLigandbasedVirtual2020" class="col-sm-8">
    
      <div class="title">Large-Scale Ligand-Based Virtual Screening for SARS-CoV-2 Inhibitors Using Deep Neural Networks</div>
      <div class="author">
        
          
            
              
                
                  Hofmarcher, M.,
                
              
            
          
        
          
            
              
                
                  Mayr, A.,
                
              
            
          
        
          
            
              
                
                  Rumetshofer, E.,
                
              
            
          
        
          
            
              
                
                  Ruch, P.,
                
              
            
          
        
          
            
              
                
                  Renz, P.,
                
              
            
          
        
          
            
              
                
                  Schimunek, J.,
                
              
            
          
        
          
            
              
                
                  Seidl, P.,
                
              
            
          
        
          
            
              
                
                  Vall, A.,
                
              
            
          
        
          
            
              
                
                  Widrich, M.,
                
              
            
          
        
          
            
              
                
                  Hochreiter, S.,
                
              
            
          
        
          
            
              
                
                  and Klambauer, G.
                
              
            
          
        
      </div>

      <div class="periodical">
      
      
        2020
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
      <a href="http://arxiv.org/abs/2004.00979" class="btn btn-sm z-depth-0" role="button" target="_blank">url</a>
    
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Due to the current severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) pandemic, there is an urgent need for novel therapies and drugs. We conducted a large-scale virtual screening for small molecules that are potential CoV-2 inhibitors. To this end, we utilized "ChemAI", a deep neural network trained on more than 220M data points across 3.6M molecules from three public drug-discovery databases. With ChemAI, we screened and ranked one billion molecules from the ZINC database for favourable effects against CoV-2. We then reduced the result to the 30,000 top-ranked compounds, which are readily accessible and purchasable via the ZINC database. Additionally, we screened the DrugBank using ChemAI to allow for drug repurposing, which would be a fast way towards a therapy. We provide these top-ranked compounds of ZINC and DrugBank as a library for further screening with bioassays at https://github.com/ml-jku/sars-cov-inhibitors-chemai.</p>
    </div>
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
  </div>

  <div id="renzFailureModesMolecule2020a" class="col-sm-8">
    
      <div class="title">On Failure Modes in Molecule Generation and Optimization</div>
      <div class="author">
        
          
            
              
                
                  Renz, P.,
                
              
            
          
        
          
            
              
                
                  Van Rompaey, D.,
                
              
            
          
        
          
            
              
                
                  Wegner, J.,
                
              
            
          
        
          
            
              
                
                  Hochreiter, S.,
                
              
            
          
        
          
            
              
                
                  and Klambauer, G.
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em></em>
      
      
        2020
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
      <a href="https://doi.org/10.1016/j.ddtec.2020.09.003" class="btn btn-sm z-depth-0" role="button" target="_blank">url</a>
    
    
    
    
    
    
      <a href="https://github.com/ml-jku/mgenerators-failure-modes" class="btn btn-sm z-depth-0" role="button" target="_blank">Code</a>
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>There has been a wave of generative models for molecules triggered by advances in the field of Deep Learning. These generative models are often used to optimize chemical compounds towards particular properties or a desired biological activity. The evaluation of generative models remains challenging and suggested performance metrics or scoring functions often do not cover all relevant aspects of drug design projects. In this work, we highlight some unintended failure modes in molecular generation and optimization and how these evade detection by current performance metrics.</p>
    </div>
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
  </div>

  <div id="sturmIndustryscaleApplicationEvaluation2020" class="col-sm-8">
    
      <div class="title">Industry-Scale Application and Evaluation of Deep Learning for Drug Target Prediction</div>
      <div class="author">
        
          
            
              
                
                  Sturm, N.,
                
              
            
          
        
          
            
              
                
                  Mayr, A.,
                
              
            
          
        
          
            
              
                
                  Le Van, T.,
                
              
            
          
        
          
            
              
                
                  Chupakhin, V.,
                
              
            
          
        
          
            
              
                
                  Ceulemans, H.,
                
              
            
          
        
          
            
              
                
                  Wegner, J.,
                
              
            
          
        
          
            
              
                
                  Golib-Dzib, J.,
                
              
            
          
        
          
            
              
                
                  Jeliazkova, N.,
                
              
            
          
        
          
            
              
                
                  Vandriessche, Y.,
                
              
            
          
        
          
            
              
                
                  Böhm, S.,
                
              
            
          
        
          
            
              
                
                  Cima, V.,
                
              
            
          
        
          
            
              
                
                  Martinovic, J.,
                
              
            
          
        
          
            
              
                
                  Greene, N.,
                
              
            
          
        
          
            
              
                
                  Vander Aa, T.,
                
              
            
          
        
          
            
              
                
                  Ashby, T.,
                
              
            
          
        
          
            
              
                
                  Hochreiter, S.,
                
              
            
          
        
          
            
              
                
                  Engkvist, O.,
                
              
            
          
        
          
            
              
                
                  Klambauer, G.,
                
              
            
          
        
          
            
              
                
                  and Chen, H.
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em></em>
      
      
        2020
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
      <a href="https://doi.org/10.1186/s13321-020-00428-5" class="btn btn-sm z-depth-0" role="button" target="_blank">url</a>
    
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Artificial intelligence (AI) is undergoing a revolution thanks to the breakthroughs of machine learning algorithms in computer vision, speech recognition, natural language processing and generative modelling. Recent works on publicly available pharmaceutical data showed that AI methods are highly promising for Drug Target prediction. However, the quality of public data might be different than that of industry data due to different labs reporting measurements, different measurement techniques, fewer samples and less diverse and specialized assays. As part of a European funded project (ExCAPE), that brought together expertise from pharmaceutical industry, machine learning, and high-performance computing, we investigated how well machine learning models obtained from public data can be transferred to internal pharmaceutical industry data. Our results show that machine learning models trained on public data can indeed maintain their predictive power to a large degree when applied to industry data. Moreover, we observed that deep learning derived machine learning models outperformed comparable models, which were trained by other machine learning algorithms, when applied to internal pharmaceutical company datasets. To our knowledge, this is the first large-scale study evaluating the potential of machine learning and especially deep learning directly at the level of industry-scale settings and moreover investigating the transferability of publicly learned target prediction models towards industrial bioactivity prediction pipelines.</p>
    </div>
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">ICLR</abbr>
    
  
  </div>

  <div id="ramsauerHopfieldNetworksAll2020" class="col-sm-8">
    
      <div class="title">Hopfield Networks Is All You Need</div>
      <div class="author">
        
          
            
              
                
                  Ramsauer, H.,
                
              
            
          
        
          
            
              
                
                  Schäfl, B.,
                
              
            
          
        
          
            
              
                
                  Lehner, J.,
                
              
            
          
        
          
            
              
                
                  Seidl, P.,
                
              
            
          
        
          
            
              
                
                  Widrich, M.,
                
              
            
          
        
          
            
              
                
                  Gruber, L.,
                
              
            
          
        
          
            
              
                
                  Holzleitner, M.,
                
              
            
          
        
          
            
              
                
                  Pavlović, M.,
                
              
            
          
        
          
            
              
                
                  Sandve, G.,
                
              
            
          
        
          
            
              
                
                  Greiff, V.,
                
              
            
          
        
          
            
              
                
                  Kreil, D.,
                
              
            
          
        
          
            
              
                
                  Kopp, M.,
                
              
            
          
        
          
            
              
                
                  Klambauer, G.,
                
              
            
          
        
          
            
              
                
                  Brandstetter, J.,
                
              
            
          
        
          
            
              
                
                  and Hochreiter, S.
                
              
            
          
        
      </div>

      <div class="periodical">
      
      
        2020
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
      <a href="http://arxiv.org/abs/2008.02217" class="btn btn-sm z-depth-0" role="button" target="_blank">url</a>
    
    
    
    
    
      <a href="https://ml-jku.github.io/hopfield-layers/" class="btn btn-sm z-depth-0" role="button" target="_blank">Blog</a>
    
    
      <a href="https://github.com/ml-jku/hopfield-layers" class="btn btn-sm z-depth-0" role="button" target="_blank">Code</a>
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>We show that the transformer attention mechanism is the update rule of a modern Hopfield network with continuous states. This new Hopfield network can store exponentially (with the dimension) many patterns, converges with one update, and has exponentially small retrieval errors. The number of stored patterns is traded off against convergence speed and retrieval error. The new Hopfield network has three types of energy minima (fixed points of the update): (1) global fixed point averaging over all patterns, (2) metastable states averaging over a subset of patterns, and (3) fixed points which store a single pattern. Transformer and BERT models operate in their first layers preferably in the global averaging regime, while they operate in higher layers in metastable states. The gradient in transformers is maximal for metastable states, is uniformly distributed for global averaging, and vanishes for a fixed point near a stored pattern. Using the Hopfield network interpretation, we analyzed learning of transformer and BERT models. Learning starts with attention heads that average and then most of them switch to metastable states. However, the majority of heads in the first layers still averages and can be replaced by averaging, e.g. our proposed Gaussian weighting. In contrast, heads in the last layers steadily learn and seem to use metastable states to collect information created in lower layers. These heads seem to be a promising target for improving transformers. Neural networks with Hopfield networks outperform other methods on immune repertoire classification, where the Hopfield net stores several hundreds of thousands of patterns. We provide a new PyTorch layer called "Hopfield", which allows to equip deep learning architectures with modern Hopfield networks as a new powerful concept comprising pooling, memory, and attention. GitHub: https://github.com/ml-jku/hopfield-layers</p>
    </div>
    
  </div>
</div>
</li></ol>

  <h2 class="year">2019</h2>
  <ol class="bibliography"><li><div class="row">
  <div class="col-sm-2 abbr">
  
  </div>

  <div id="renzUncertaintyEstimationMethods2019" class="col-sm-8">
    
      <div class="title">Uncertainty Estimation Methods to Support Decision-Making in Early Phases of Drug Discovery</div>
      <div class="author">
        
          
            
              
                
                  Renz, P.,
                
              
            
          
        
          
            
              
                
                  Hochreiter, S.,
                
              
            
          
        
          
            
              
                
                  and Klambauer, G.
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em></em>
      
      
        2019
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>It takes about a decade to develop a new drug by a process in which a large number of decisions have to be made. Those decisions are critical for the success or failure of a multi-million dollar drug discovery project, which could save many lives or increase life quality. Decisions in early phases of drug discovery, such as the selection of certain series of chemical compounds, are particularly impactful on the success rate. Machine learning models are increasingly used to inform the decision making process by predicting desired effects, undesired effects, such as toxicity, molecular properties, or which wet-lab test to perform next. Thus, accurately quantifying the uncertainties of the models’ outputs is critical, for example, in order to calculate expected utilities, to estimate the risk and the potential gain. In this work, we review, assess and compare recent uncertainty estimation methods with respect to their use in drug discovery projects. We test both, which methods give well calibrated prediction and which ones perform well at misclassification detection. For the latter, we find the entropy of the predictive distribution performs best. Finally, we discuss the problem of defining out-of-distribution samples for prediction tasks on chemical compounds.</p>
    </div>
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
  </div>

  <div id="arrasExplainingInterpretingLSTMs2019" class="col-sm-8">
    
      <div class="title">Explaining and Interpreting LSTMs</div>
      <div class="author">
        
          
            
              
                
                  Arras, L.,
                
              
            
          
        
          
            
              
                
                  Arjona-Medina, J.,
                
              
            
          
        
          
            
              
                
                  Widrich, M.,
                
              
            
          
        
          
            
              
                
                  Montavon, G.,
                
              
            
          
        
          
            
              
                
                  Gillhofer, M.,
                
              
            
          
        
          
            
              
                
                  Müller, K.,
                
              
            
          
        
          
            
              
                
                  Hochreiter, S.,
                
              
            
          
        
          
            
              
                
                  and Samek, W.
                
              
            
          
        
      </div>

      <div class="periodical">
      
      
        2019
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
      <a href="https://doi.org/10.1007/978-3-030-28954-6_11" class="btn btn-sm z-depth-0" role="button" target="_blank">url</a>
    
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>While neural networks have acted as a strong unifying force in the design of modern AI systems, the neural network architectures themselves remain highly heterogeneous due to the variety of tasks to be solved. In this chapter, we explore how to adapt the Layer-wise Relevance Propagation (LRP) technique used for explaining the predictions of feed-forward networks to the LSTM architecture used for sequential data modeling and forecasting. The special accumulators and gated interactions present in the LSTM require both a new propagation scheme and an extension of the underlying theoretical framework to deliver faithful explanations.</p>
    </div>
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">Springer</abbr>
    
  
  </div>

  <div id="hofmarcherVisualSceneUnderstanding2019" class="col-sm-8">
    
      <div class="title">Visual Scene Understanding for Autonomous Driving Using Semantic Segmentation</div>
      <div class="author">
        
          
            
              
                
                  Hofmarcher, M.,
                
              
            
          
        
          
            
              
                
                  Unterthiner, T.,
                
              
            
          
        
          
            
              
                
                  Arjona-Medina, J.,
                
              
            
          
        
          
            
              
                
                  Klambauer, G.,
                
              
            
          
        
          
            
              
                
                  Hochreiter, S.,
                
              
            
          
        
          
            
              
                
                  and Nessler, B.
                
              
            
          
        
      </div>

      <div class="periodical">
      
      
        2019
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
      <a href="https://doi.org/10.1007/978-3-030-28954-6_15" class="btn btn-sm z-depth-0" role="button" target="_blank">url</a>
    
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Deep neural networks are an increasingly important technique for autonomous driving, especially as a visual perception component. Deployment in a real environment necessitates the explainability and inspectability of the algorithms controlling the vehicle. Such insightful explanations are relevant not only for legal issues and insurance matters but also for engineers and developers in order to achieve provable functional quality guarantees. This applies to all scenarios where the results of deep networks control potentially life threatening machines. We suggest the use of a tiered approach, whose main component is a semantic segmentation model, over an end-to-end approach for an autonomous driving system. In order for a system to provide meaningful explanations for its decisions it is necessary to give an explanation about the semantics that it attributes to the complex sensory inputs that it perceives. In the context of high-dimensional visual input this attribution is done as a pixel-wise classification process that assigns an object class to every pixel in the image. This process is called semantic segmentation.We propose an architecture that delivers real-time viable segmentation performance and which conforms to the limitations in computational power that is available in production vehicles. The output of such a semantic segmentation model can be used as an input for an interpretable autonomous driving system.</p>
    </div>
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
  </div>

  <div id="kimeswengerDetectingCutaneousBasal2019" class="col-sm-8">
    
      <div class="title">Detecting Cutaneous Basal Cell Carcinomas in Ultra-High Resolution and Weakly Labelled Histopathological Images</div>
      <div class="author">
        
          
            
              
                
                  Kimeswenger, S.,
                
              
            
          
        
          
            
              
                
                  Rumetshofer, E.,
                
              
            
          
        
          
            
              
                
                  Hofmarcher, M.,
                
              
            
          
        
          
            
              
                
                  Tschandl, P.,
                
              
            
          
        
          
            
              
                
                  Kittler, H.,
                
              
            
          
        
          
            
              
                
                  Hochreiter, S.,
                
              
            
          
        
          
            
              
                
                  Hötzenecker, W.,
                
              
            
          
        
          
            
              
                
                  and Klambauer, G.
                
              
            
          
        
      </div>

      <div class="periodical">
      
      
        2019
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
      <a href="http://arxiv.org/abs/1911.06616" class="btn btn-sm z-depth-0" role="button" target="_blank">url</a>
    
    
    
      
      <a href="https://arxiv.org/pdf/1911.06616.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Diagnosing basal cell carcinomas (BCC), one of the most common cutaneous malignancies in humans, is a task regularly performed by pathologists and dermato-pathologists. Improving histological diagnosis by providing diagnosis suggestions, i.e. computer-assisted diagnoses is actively researched to improve safety, quality and efficiency. Increasingly, machine learning methods are applied due to their superior performance. However, typical images obtained by scanning histological sections often have a resolution that is prohibitive for processing with current state-of-the-art neural networks. Furthermore, the data pose a problem of weak labels, since only a tiny fraction of the image is indicative of the disease class, whereas a large fraction of the image is highly similar to the non-disease class. The aim of this study is to evaluate whether it is possible to detect basal cell carcinomas in histological sections using attention-based deep learning models and to overcome the ultra-high resolution and the weak labels of whole slide images. We demonstrate that attention-based models can indeed yield almost perfect classification performance with an AUC of 0.99.</p>
    </div>
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
  </div>

  <div id="klambauerMachineLearningDrug2019" class="col-sm-8">
    
      <div class="title">Machine Learning in Drug Discovery</div>
      <div class="author">
        
          
            
              
                
                  Klambauer, G.,
                
              
            
          
        
          
            
              
                
                  Hochreiter, S.,
                
              
            
          
        
          
            
              
                
                  and Rarey, M.
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em></em>
      
      
        2019
      
      </div>
    

    <div class="links">
    
    
    
      <a href="https://doi.org/10.1021/acs.jcim.9b00136" class="btn btn-sm z-depth-0" role="button" target="_blank">url</a>
    
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">WRR</abbr>
    
  
  </div>

  <div id="kratzertImprovedPredictionsUngauged2019" class="col-sm-8">
    
      <div class="title">Toward Improved Predictions in Ungauged Basins: Exploiting the Power of Machine Learning</div>
      <div class="author">
        
          
            
              
                
                  Kratzert, F.,
                
              
            
          
        
          
            
              
                
                  Klotz, D.,
                
              
            
          
        
          
            
              
                
                  Herrnegger, M.,
                
              
            
          
        
          
            
              
                
                  Sampson, A.,
                
              
            
          
        
          
            
              
                
                  Hochreiter, S.,
                
              
            
          
        
          
            
              
                
                  and Nearing, G.
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em></em>
      
      
        2019
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
      <a href="https://doi.org/10.1029/2019WR026065" class="btn btn-sm z-depth-0" role="button" target="_blank">url</a>
    
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Long short-term memory (LSTM) networks offer unprecedented accuracy for prediction in ungauged basins. We trained and tested several LSTMs on 531 basins from the CAMELS data set using k-fold validation, so that predictions were made in basins that supplied no training data. The training and test data set included ∼30 years of daily rainfall-runoff data from catchments in the United States ranging in size from 4 to 2,000 km2 with aridity index from 0.22 to 5.20, and including 12 of the 13 IGPB vegetated land cover classifications. This effectively “ungauged” model was benchmarked over a 15-year validation period against the Sacramento Soil Moisture Accounting (SAC-SMA) model and also against the NOAA National Water Model reanalysis. SAC-SMA was calibrated separately for each basin using 15 years of daily data. The out-of-sample LSTM had higher median Nash-Sutcliffe Efficiencies across the 531 basins (0.69) than either the calibrated SAC-SMA (0.64) or the National Water Model (0.58). This indicates that there is (typically) sufficient information in available catchment attributes data about similarities and differences between catchment-level rainfall-runoff behaviors to provide out-of-sample simulations that are generally more accurate than current models under ideal (i.e., calibrated) conditions. We found evidence that adding physical constraints to the LSTM models might improve simulations, which we suggest motivates future research related to physics-guided machine learning.</p>
    </div>
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">HESS</abbr>
    
  
  </div>

  <div id="kratzertLearningUniversalRegional2019" class="col-sm-8">
    
      <div class="title">Towards Learning Universal, Regional, and Local Hydrological Behaviors via Machine Learning Applied to Large-Sample Datasets</div>
      <div class="author">
        
          
            
              
                
                  Kratzert, F.,
                
              
            
          
        
          
            
              
                
                  Klotz, D.,
                
              
            
          
        
          
            
              
                
                  Shalev, G.,
                
              
            
          
        
          
            
              
                
                  Klambauer, G.,
                
              
            
          
        
          
            
              
                
                  Hochreiter, S.,
                
              
            
          
        
          
            
              
                
                  and Nearing, G.
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em></em>
      
      
        2019
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
      <a href="https://doi.org/10.5194/hess-23-5089-2019" class="btn btn-sm z-depth-0" role="button" target="_blank">url</a>
    
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p><p><strong>Abstract.</strong> Regional rainfall–runoff modeling is an old but still mostly outstanding problem in the hydrological sciences. The problem currently is that traditional hydrological models degrade significantly in performance when calibrated for multiple basins together instead of for a single basin alone. In this paper, we propose a novel, data-driven approach using Long Short-Term Memory networks (LSTMs) and demonstrate that under a “big data” paradigm, this is not necessarily the case. By training a single LSTM model on 531 basins from the CAMELS dataset using meteorological time series data and static catchment attributes, we were able to significantly improve performance compared to a set of several different hydrological benchmark models. Our proposed approach not only significantly outperforms hydrological models that were calibrated regionally, but also achieves better performance than hydrological models that were calibrated for each basin individually. Furthermore, we propose an adaption to the standard LSTM architecture, which we call an Entity-Aware-LSTM (EA-LSTM), that allows for learning catchment similarities as a feature layer in a deep learning model. We show that these learned catchment similarities correspond well to what we would expect from prior hydrological understanding.</p></p>
    </div>
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">Springer</abbr>
    
  
  </div>

  <div id="kratzertNeuralHydrologyInterpretingLSTMs2019" class="col-sm-8">
    
      <div class="title">NeuralHydrology – Interpreting LSTMs in Hydrology</div>
      <div class="author">
        
          
            
              
                
                  Kratzert, F.,
                
              
            
          
        
          
            
              
                
                  Herrnegger, M.,
                
              
            
          
        
          
            
              
                
                  Klotz, D.,
                
              
            
          
        
          
            
              
                
                  Hochreiter, S.,
                
              
            
          
        
          
            
              
                
                  and Klambauer, G.
                
              
            
          
        
      </div>

      <div class="periodical">
      
      
        2019
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
      <a href="https://doi.org/10.1007/978-3-030-28954-6_19" class="btn btn-sm z-depth-0" role="button" target="_blank">url</a>
    
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Despite the huge success of Long Short-Term Memory networks, their applications in environmental sciences are scarce. We argue that one reason is the difficulty to interpret the internals of trained networks. In this study, we look at the application of LSTMs for rainfall-runoff forecasting, one of the central tasks in the field of hydrology, in which the river discharge has to be predicted from meteorological observations. LSTMs are particularly well-suited for this problem since memory cells can represent dynamic reservoirs and storages, which are essential components in state-space modelling approaches of the hydrological system. On basis of two different catchments, one with snow influence and one without, we demonstrate how the trained model can be analyzed and interpreted. In the process, we show that the network internally learns to represent patterns that are consistent with our qualitative understanding of the hydrological system.</p>
    </div>
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
  </div>

  <div id="mendenCommunityAssessmentAdvance2019" class="col-sm-8">
    
      <div class="title">Community Assessment to Advance Computational Prediction of Cancer Drug Combinations in a Pharmacogenomic Screen</div>
      <div class="author">
        
          
            
              
                
                  Menden, M.,
                
              
            
          
        
          
            
              
                
                  Wang, D.,
                
              
            
          
        
          
            
              
                
                  Mason, M.,
                
              
            
          
        
          
            
              
                
                  Szalai, B.,
                
              
            
          
        
          
            
              
                
                  Bulusu, K.,
                
              
            
          
        
          
            
              
                
                  Guan, Y.,
                
              
            
          
        
          
            
              
                
                  Yu, T.,
                
              
            
          
        
          
            
              
                
                  Kang, J.,
                
              
            
          
        
          
            
              
                
                  Jeon, M.,
                
              
            
          
        
          
            
              
                
                  Wolfinger, R.,
                
              
            
          
        
          
            
              
                
                  Nguyen, T.,
                
              
            
          
        
          
            
              
                
                  Zaslavskiy, M.,
                
              
            
          
        
          
            
              
                
                  Jang, I.,
                
              
            
          
        
          
            
              
                
                  Ghazoui, Z.,
                
              
            
          
        
          
            
              
                
                  Ahsen, M.,
                
              
            
          
        
          
            
              
                
                  Vogel, R.,
                
              
            
          
        
          
            
              
                
                  Neto, E.,
                
              
            
          
        
          
            
              
                
                  Norman, T.,
                
              
            
          
        
          
            
              
                
                  Tang, E.,
                
              
            
          
        
          
            
              
                
                  Garnett, M.,
                
              
            
          
        
          
            
              
                
                  Veroli, G.,
                
              
            
          
        
          
            
              
                
                  Fawell, S.,
                
              
            
          
        
          
            
              
                
                  Stolovitzky, G.,
                
              
            
          
        
          
            
              
                
                  Guinney, J.,
                
              
            
          
        
          
            
              
                
                  Dry, J.,
                
              
            
          
        
          
            
              
                
                  and Saez-Rodriguez, J.
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em></em>
      
      
        2019
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
      <a href="https://doi.org/10.1038/s41467-019-09799-2" class="btn btn-sm z-depth-0" role="button" target="_blank">url</a>
    
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>The effectiveness of most cancer targeted therapies is short-lived. Tumors often develop resistance that might be overcome with drug combinations. However, the number of possible combinations is vast, necessitating data-driven approaches to find optimal patient-specific treatments. Here we report AstraZeneca’s large drug combination dataset, consisting of 11,576 experiments from 910 combinations across 85 molecularly characterized cancer cell lines, and results of a DREAM Challenge to evaluate computational strategies for predicting synergistic drug pairs and biomarkers. 160 teams participated to provide a comprehensive methodological development and benchmarking. Winning methods incorporate prior knowledge of drug-target interactions. Synergy is predicted with an accuracy matching biological replicates for &gt;60% of combinations. However, 20% of drug combinations are poorly predicted by all methods. Genomic rationale for synergy predictions are identified, including ADAM17 inhibitor antagonism when combined with PIK3CB/D inhibition contrasting to synergy when combined with other PI3K-pathway inhibitors in PIK3CA mutant cells.</p>
    </div>
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
  </div>

  <div id="preuerInterpretableDeepLearning2019" class="col-sm-8">
    
      <div class="title">Interpretable Deep Learning in Drug Discovery</div>
      <div class="author">
        
          
            
              
                
                  Preuer, K.,
                
              
            
          
        
          
            
              
                
                  Klambauer, G.,
                
              
            
          
        
          
            
              
                
                  Rippmann, F.,
                
              
            
          
        
          
            
              
                
                  Hochreiter, S.,
                
              
            
          
        
          
            
              
                
                  and Unterthiner, T.
                
              
            
          
        
      </div>

      <div class="periodical">
      
      
        2019
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
      <a href="https://doi.org/10.1007/978-3-030-28954-6_18" class="btn btn-sm z-depth-0" role="button" target="_blank">url</a>
    
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Without any means of interpretation, neural networks that predict molecular properties and bioactivities are merely black boxes. We will unravel these black boxes and will demonstrate approaches to understand the learned representations which are hidden inside these models. We show how single neurons can be interpreted as classifiers which determine the presence or absence of pharmacophore- or toxicophore-like structures, thereby generating new insights and relevant knowledge for chemistry, pharmacology and biochemistry. We further discuss how these novel pharmacophores/toxicophores can be determined from the network by identifying the most relevant components of a compound for the prediction of the network. Additionally, we propose a method which can be used to extract new pharmacophores from a model and will show that these extracted structures are consistent with literature findings. We envision that having access to such interpretable knowledge is a crucial aid in the development and design of new pharmaceutically active molecules, and helps to investigate and understand failures and successes of current methods.</p>
    </div>
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">NeurIPS</abbr>
    
  
  </div>

  <div id="Arjona:19" class="col-sm-8">
    
      <div class="title">RUDDER: Return Decomposition for Delayed Rewards</div>
      <div class="author">
        
          
            
              
                
                  Arjona-Medina, J.,
                
              
            
          
        
          
            
              
                
                  Gillhofer, M.,
                
              
            
          
        
          
            
              
                
                  Widrich, M.,
                
              
            
          
        
          
            
              
                
                  Unterthiner, T.,
                
              
            
          
        
          
            
              
                
                  Brandstetter, J.,
                
              
            
          
        
          
            
              
                
                  and Hochreiter, S.
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>In Advances in Neural Information Processing Systems 32</em>
      
      
        2019
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
      <a href="https://arxiv.org/abs/2009.14108" class="btn btn-sm z-depth-0" role="button" target="_blank">url</a>
    
    
    
    
    
      <a href="https://ml-jku.github.io/rudder/" class="btn btn-sm z-depth-0" role="button" target="_blank">Blog</a>
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>We propose RUDDER, a novel reinforcement learning approach for delayed rewards in finite Markov decision processes (MDPs). In MDPs the Q-values are equal to the expected immediate reward plus the expected future rewards. The latter are related to bias problems in temporal difference (TD) learning and to high variance problems in Monte Carlo (MC) learning. Both problems are even more severe when rewards are delayed. RUDDER aims at making the expected future rewards zero, which simplifies Q-value estimation to computing the mean of the immediate reward. We propose the following two new concepts to push the expected future rewards toward zero. (i) Reward redistribution that leads to return-equivalent decision processes with the same optimal policies and, when optimal, zero expected future rewards. (ii) Return decomposition via contribution analysis which transforms the reinforcement learning task into a regression task at which deep learning excels. On artificial tasks with delayed rewards, RUDDER is significantly faster than MC and exponentially faster than Monte Carlo Tree Search (MCTS), TD({λ}), and reward shaping approaches. At Atari games, RUDDER on top of a Proximal Policy Optimization (PPO) baseline improves the scores, which is most prominent at games with delayed rewards. Source code is available at \url{https://github.com/ml-jku/rudder} and demonstration videos at \url{https://goo.gl/EQerZV}.</p>
    </div>
    
  </div>
</div>
</li></ol>

  <h2 class="year">2018</h2>
  <ol class="bibliography"><li><div class="row">
  <div class="col-sm-2 abbr">
  
  </div>

  <div id="unterthinerCoulombGANsProvably2018" class="col-sm-8">
    
      <div class="title">Coulomb GANs: Provably Optimal Nash Equilibria via Potential Fields</div>
      <div class="author">
        
          
            
              
                
                  Unterthiner, T.,
                
              
            
          
        
          
            
              
                
                  Nessler, B.,
                
              
            
          
        
          
            
              
                
                  Seward, C.,
                
              
            
          
        
          
            
              
                
                  Klambauer, G.,
                
              
            
          
        
          
            
              
                
                  Heusel, M.,
                
              
            
          
        
          
            
              
                
                  Ramsauer, H.,
                
              
            
          
        
          
            
              
                
                  and Hochreiter, S.
                
              
            
          
        
      </div>

      <div class="periodical">
      
      
        2018
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
      <a href="http://arxiv.org/abs/1708.08819" class="btn btn-sm z-depth-0" role="button" target="_blank">url</a>
    
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Generative adversarial networks (GANs) evolved into one of the most successful unsupervised techniques for generating realistic images. Even though it has recently been shown that GAN training converges, GAN models often end up in local Nash equilibria that are associated with mode collapse or otherwise fail to model the target distribution. We introduce Coulomb GANs, which pose the GAN learning problem as a potential field of charged particles, where generated samples are attracted to training set samples but repel each other. The discriminator learns a potential field while the generator decreases the energy by moving its samples along the vector (force) field determined by the gradient of the potential field. Through decreasing the energy, the GAN model learns to generate samples according to the whole target distribution and does not only cover some of its modes. We prove that Coulomb GANs possess only one Nash equilibrium which is optimal in the sense that the model distribution equals the target distribution. We show the efficacy of Coulomb GANs on a variety of image datasets. On LSUN and celebA, Coulomb GANs set a new state of the art and produce a previously unseen variety of different samples.</p>
    </div>
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
  </div>

  <div id="hochreiterMachineLearningDrug2018" class="col-sm-8">
    
      <div class="title">Machine Learning in Drug Discovery</div>
      <div class="author">
        
          
            
              
                
                  Hochreiter, S.,
                
              
            
          
        
          
            
              
                
                  Klambauer, G.,
                
              
            
          
        
          
            
              
                
                  and Rarey, M.
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em></em>
      
      
        2018
      
      </div>
    

    <div class="links">
    
    
    
      <a href="https://doi.org/10.1021/acs.jcim.8b00478" class="btn btn-sm z-depth-0" role="button" target="_blank">url</a>
    
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
  </div>

  <div id="mayrLargescaleComparisonMachine2018" class="col-sm-8">
    
      <div class="title">Large-Scale Comparison of Machine Learning Methods for Drug Target Prediction on ChEMBL</div>
      <div class="author">
        
          
            
              
                
                  Mayr, A.,
                
              
            
          
        
          
            
              
                
                  Klambauer, G.,
                
              
            
          
        
          
            
              
                
                  Unterthiner, T.,
                
              
            
          
        
          
            
              
                
                  Steijaert, M.,
                
              
            
          
        
          
            
              
                
                  Wegner, J.,
                
              
            
          
        
          
            
              
                
                  Ceulemans, H.,
                
              
            
          
        
          
            
              
                
                  Clevert, D.,
                
              
            
          
        
          
            
              
                
                  and Hochreiter, S.
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em></em>
      
      
        2018
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
      <a href="https://doi.org/10.1039/C8SC00148K" class="btn btn-sm z-depth-0" role="button" target="_blank">url</a>
    
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Deep learning is currently the most successful machine learning technique in a wide range of application areas and has recently been applied successfully in drug discovery research to predict potential drug targets and to screen for active molecules. However, due to (1) the lack of large-scale studies, (2) the compound series bias that is characteristic of drug discovery datasets and (3) the hyperparameter selection bias that comes with the high number of potential deep learning architectures, it remains unclear whether deep learning can indeed outperform existing computational methods in drug discovery tasks. We therefore assessed the performance of several deep learning methods on a large-scale drug discovery dataset and compared the results with those of other machine learning and target prediction methods. To avoid potential biases from hyperparameter selection or compound series, we used a nested cluster-cross-validation strategy. We found (1) that deep learning methods significantly outperform all competing methods and (2) that the predictive performance of deep learning is in many cases comparable to that of tests performed in wet labs (i.e., in vitro assays).</p>
    </div>
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
  </div>

  <div id="preuerDeepSynergyPredictingAnticancer2018" class="col-sm-8">
    
      <div class="title">DeepSynergy: Predicting Anti-Cancer Drug Synergy with Deep Learning</div>
      <div class="author">
        
          
            
              
                
                  Preuer, K.,
                
              
            
          
        
          
            
              
                
                  Lewis, R.,
                
              
            
          
        
          
            
              
                
                  Hochreiter, S.,
                
              
            
          
        
          
            
              
                
                  Bender, A.,
                
              
            
          
        
          
            
              
                
                  Bulusu, K.,
                
              
            
          
        
          
            
              
                
                  and Klambauer, G.
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em></em>
      
      
        2018
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
      <a href="https://doi.org/10.1093/bioinformatics/btx806" class="btn btn-sm z-depth-0" role="button" target="_blank">url</a>
    
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>While drug combination therapies are a well-established concept in cancer treatment, identifying novel synergistic combinations is challenging due to the size of combinatorial space. However, computational approaches have emerged as a time- and cost-efficient way to prioritize combinations to test, based on recently available large-scale combination screening data. Recently, Deep Learning has had an impact in many research areas by achieving new state-of-the-art model performance. However, Deep Learning has not yet been applied to drug synergy prediction, which is the approach we present here, termed DeepSynergy. DeepSynergy uses chemical and genomic information as input information, a normalization strategy to account for input data heterogeneity, and conical layers to model drug synergies.DeepSynergy was compared to other machine learning methods such as Gradient Boosting Machines, Random Forests, Support Vector Machines and Elastic Nets on the largest publicly available synergy dataset with respect to mean squared error. DeepSynergy significantly outperformed the other methods with an improvement of 7.2% over the second best method at the prediction of novel drug combinations within the space of explored drugs and cell lines. At this task, the mean Pearson correlation coefficient between the measured and the predicted values of DeepSynergy was 0.73. Applying DeepSynergy for classification of these novel drug combinations resulted in a high predictive performance of an AUC of 0.90. Furthermore, we found that all compared methods exhibit low predictive performance when extrapolating to unexplored drugs or cell lines, which we suggest is due to limitations in the size and diversity of the dataset. We envision that DeepSynergy could be a valuable tool for selecting novel synergistic drug combinations.DeepSynergy is available via www.bioinf.jku.at/software/DeepSynergy.Supplementary data are available at Bioinformatics online.</p>
    </div>
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
  </div>

  <div id="preuerFrechetChemNetDistance2018" class="col-sm-8">
    
      <div class="title">Fréchet ChemNet Distance: A Metric for Generative Models for Molecules in Drug Discovery</div>
      <div class="author">
        
          
            
              
                
                  Preuer, K.,
                
              
            
          
        
          
            
              
                
                  Renz, P.,
                
              
            
          
        
          
            
              
                
                  Unterthiner, T.,
                
              
            
          
        
          
            
              
                
                  Hochreiter, S.,
                
              
            
          
        
          
            
              
                
                  and Klambauer, G.
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em></em>
      
      
        2018
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
      <a href="https://doi.org/10.1021/acs.jcim.8b00234" class="btn btn-sm z-depth-0" role="button" target="_blank">url</a>
    
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>The new wave of successful generative models in machine learning has increased the interest in deep learning driven de novo drug design. However, method comparison is difficult because of various flaws of the currently employed evaluation metrics. We propose an evaluation metric for generative models called Fréchet ChemNet distance (FCD). The advantage of the FCD over previous metrics is that it can detect whether generated molecules are diverse and have similar chemical and biological properties as real molecules.</p>
    </div>
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">ICLR</abbr>
    
  
  </div>

  <div id="rumetshoferHumanlevelProteinLocalization2018" class="col-sm-8">
    
      <div class="title">Human-Level Protein Localization with Convolutional Neural Networks</div>
      <div class="author">
        
          
            
              
                
                  Rumetshofer, E.,
                
              
            
          
        
          
            
              
                
                  Hofmarcher, M.,
                
              
            
          
        
          
            
              
                
                  Röhrl, C.,
                
              
            
          
        
          
            
              
                
                  Hochreiter, S.,
                
              
            
          
        
          
            
              
                
                  and Klambauer, G.
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>In </em>
      
      
        2018
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
      <a href="https://openreview.net/forum?id=ryl5khRcKm" class="btn btn-sm z-depth-0" role="button" target="_blank">url</a>
    
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Localizing a specific protein in a human cell is essential for understanding cellular functions and biological processes of underlying diseases. A promising, low-cost,and time-efficient...</p>
    </div>
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
  </div>

  <div id="sewardFirstOrderGenerative2018" class="col-sm-8">
    
      <div class="title">First Order Generative Adversarial Networks</div>
      <div class="author">
        
          
            
              
                
                  Seward, C.,
                
              
            
          
        
          
            
              
                
                  Unterthiner, T.,
                
              
            
          
        
          
            
              
                
                  Bergmann, U.,
                
              
            
          
        
          
            
              
                
                  Jetchev, N.,
                
              
            
          
        
          
            
              
                
                  and Hochreiter, S.
                
              
            
          
        
      </div>

      <div class="periodical">
      
      
        2018
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
      <a href="http://arxiv.org/abs/1802.04591" class="btn btn-sm z-depth-0" role="button" target="_blank">url</a>
    
    
    
      
      <a href="https://arxiv.org/pdf/1802.04591.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>GANs excel at learning high dimensional distributions, but they can update generator parameters in directions that do not correspond to the steepest descent direction of the objective. Prominent examples of problematic update directions include those used in both Goodfellow’s original GAN and the WGAN-GP. To formally describe an optimal update direction, we introduce a theoretical framework which allows the derivation of requirements on both the divergence and corresponding method for determining an update direction, with these requirements guaranteeing unbiased mini-batch updates in the direction of steepest descent. We propose a novel divergence which approximates the Wasserstein distance while regularizing the critic’s first order information. Together with an accompanying update direction, this divergence fulfills the requirements for unbiased steepest descent updates. We verify our method, the First Order GAN, with image generation on CelebA, LSUN and CIFAR-10 and set a new state of the art on the One Billion Word language generation task. Code to reproduce experiments is available.</p>
    </div>
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
  </div>

  <div id="steinwandterMultivariateAnalyticsChromatographic2018" class="col-sm-8">
    
      <div class="title">Multivariate Analytics of Chromatographic Data: Visual Computing Based on Moving Window Factor Models</div>
      <div class="author">
        
          
            
              
                
                  Steinwandter, V.,
                
              
            
          
        
          
            
              
                
                  Šišmiš, M.,
                
              
            
          
        
          
            
              
                
                  Sagmeister, P.,
                
              
            
          
        
          
            
              
                
                  Bodenhofer, U.,
                
              
            
          
        
          
            
              
                
                  and Herwig, C.
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em></em>
      
      
        2018
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
      <a href="https://doi.org/10.1016/j.jchromb.2018.06.010" class="btn btn-sm z-depth-0" role="button" target="_blank">url</a>
    
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Chromatography is one of the most versatile unit operations in the biotechnological industry. Regulatory initiatives like Process Analytical Technology and Quality by Design led to the implementation of new chromatographic devices. Those represent an almost inexhaustible source of data. However, the analysis of large datasets is complicated, and significant amounts of information stay hidden in big data. Here we present a new, top-down approach for the systematic analysis of chromatographic datasets. It is the goal of this approach to analyze the dataset as a whole, starting with the most important, global information. The workflow should highlight interesting regions (outliers, drifts, data inconsistencies), and help to localize those regions within a multi-dimensional space in a straightforward way. Moving window factor models were used to extract the most important information, focusing on the differences between samples. The prototype was implemented as an interactive visualization tool for the explorative analysis of complex datasets. We found that the tool makes it convenient to localize variances in a multidimensional dataset and allows to differentiate between explainable and unexplainable variance. Starting with one global difference descriptor per sample, the analysis ends up with highly resolute temporally dependent difference descriptor values, thought as a starting point for the detailed analysis of the underlying raw data.</p>
    </div>
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
  </div>

  <div id="fischerDefiningObjectiveClusters2018" class="col-sm-8">
    
      <div class="title">Defining Objective Clusters for Rabies Virus Sequences Using Affinity Propagation Clustering</div>
      <div class="author">
        
          
            
              
                
                  Fischer, S.,
                
              
            
          
        
          
            
              
                
                  Freuling, C.,
                
              
            
          
        
          
            
              
                
                  Müller, T.,
                
              
            
          
        
          
            
              
                
                  Pfaff, F.,
                
              
            
          
        
          
            
              
                
                  Bodenhofer, U.,
                
              
            
          
        
          
            
              
                
                  Höper, D.,
                
              
            
          
        
          
            
              
                
                  Fischer, M.,
                
              
            
          
        
          
            
              
                
                  Marston, D.,
                
              
            
          
        
          
            
              
                
                  Fooks, A.,
                
              
            
          
        
          
            
              
                
                  Mettenleiter, T.,
                
              
            
          
        
          
            
              
                
                  Conraths, F.,
                
              
            
          
        
          
            
              
                
                  and Homeier-Bachmann, T.
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em></em>
      
      
        2018
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
      <a href="https://doi.org/10.1371/journal.pntd.0006182" class="btn btn-sm z-depth-0" role="button" target="_blank">url</a>
    
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Rabies is caused by lyssaviruses, and is one of the oldest known zoonoses. In recent years, more than 21,000 nucleotide sequences of rabies viruses (RABV), from the prototype species rabies lyssavirus, have been deposited in public databases. Subsequent phylogenetic analyses in combination with metadata suggest geographic distributions of RABV. However, these analyses somewhat experience technical difficulties in defining verifiable criteria for cluster allocations in phylogenetic trees inviting for a more rational approach. Therefore, we applied a relatively new mathematical clustering algorythm named ‘affinity propagation clustering’ (AP) to propose a standardized sub-species classification utilizing full-genome RABV sequences. Because AP has the advantage that it is computationally fast and works for any meaningful measure of similarity between data samples, it has previously been applied successfully in bioinformatics, for analysis of microarray and gene expression data, however, cluster analysis of sequences is still in its infancy. Existing (516) and original (46) full genome RABV sequences were used to demonstrate the application of AP for RABV clustering. On a global scale, AP proposed four clusters, i.e. New World cluster, Arctic/Arctic-like, Cosmopolitan, and Asian as previously assigned by phylogenetic studies. By combining AP with established phylogenetic analyses, it is possible to resolve phylogenetic relationships between verifiably determined clusters and sequences. This workflow will be useful in confirming cluster distributions in a uniform transparent manner, not only for RABV, but also for other comparative sequence analyses.</p>
    </div>
    
  </div>
</div>
</li></ol>

  <h2 class="year">2017</h2>
  <ol class="bibliography"><li><div class="row">
  <div class="col-sm-2 abbr">
  
  </div>

  <div id="clevertRectifiedFactorNetworks2017" class="col-sm-8">
    
      <div class="title">Rectified Factor Networks for Biclustering of Omics Data</div>
      <div class="author">
        
          
            
              
                
                  Clevert, D.,
                
              
            
          
        
          
            
              
                
                  Unterthiner, T.,
                
              
            
          
        
          
            
              
                
                  Povysil, G.,
                
              
            
          
        
          
            
              
                
                  and Hochreiter, S.
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em></em>
      
      
        2017
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
      <a href="https://doi.org/10.1093/bioinformatics/btx226" class="btn btn-sm z-depth-0" role="button" target="_blank">url</a>
    
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Biclustering has become a major tool for analyzing large datasets given as matrix of samples times features and has been successfully applied in life sciences and e-commerce for drug design and recommender systems, respectively. Factor Analysis for Bicluster Acquisition (FABIA), one of the most successful biclustering methods, is a generative model that represents each bicluster by two sparse membership vectors: one for the samples and one for the features. However, FABIA is restricted to about 20 code units because of the high computational complexity of computing the posterior. Furthermore, code units are sometimes insufficiently decorrelated and sample membership is difficult to determine. We propose to use the recently introduced unsupervised Deep Learning approach Rectified Factor Networks (RFNs) to overcome the drawbacks of existing biclustering methods. RFNs efficiently construct very sparse, non-linear, high-dimensional representations of the input via their posterior means. RFN learning is a generalized alternating minimization algorithm based on the posterior regularization method which enforces non-negative and normalized posterior means. Each code unit represents a bicluster, where samples for which the code unit is active belong to the bicluster and features that have activating weights to the code unit belong to the bicluster.On 400 benchmark datasets and on three gene expression datasets with known clusters, RFN outperformed 13 other biclustering methods including FABIA. On data of the 1000 Genomes Project, RFN could identify DNA segments which indicate, that interbreeding with other hominins starting already before ancestors of modern humans left Africa.https://github.com/bioinf-jku/librfn</p>
    </div>
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
  </div>

  <div id="greiffLearningHighDimensionalImmunogenomic2017" class="col-sm-8">
    
      <div class="title">Learning the High-Dimensional Immunogenomic Features That Predict Public and Private Antibody Repertoires</div>
      <div class="author">
        
          
            
              
                
                  Greiff, V.,
                
              
            
          
        
          
            
              
                
                  Weber, C.,
                
              
            
          
        
          
            
              
                
                  Palme, J.,
                
              
            
          
        
          
            
              
                
                  Bodenhofer, U.,
                
              
            
          
        
          
            
              
                
                  Miho, E.,
                
              
            
          
        
          
            
              
                
                  Menzel, U.,
                
              
            
          
        
          
            
              
                
                  and Reddy, S.
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em></em>
      
      
        2017
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
      <a href="https://doi.org/10.4049/jimmunol.1700594" class="btn btn-sm z-depth-0" role="button" target="_blank">url</a>
    
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Recent studies have revealed that immune repertoires contain a substantial fraction of public clones, which may be defined as Ab or TCR clonal sequences shared across individuals. It has remained unclear whether public clones possess predictable sequence features that differentiate them from private clones, which are believed to be generated largely stochastically. This knowledge gap represents a lack of insight into the shaping of immune repertoire diversity. Leveraging a machine learning approach capable of capturing the high-dimensional compositional information of each clonal sequence (defined by CDR3), we detected predictive public clone and private clone–specific immunogenomic differences concentrated in CDR3’s N1–D–N2 region, which allowed the prediction of public and private status with 80% accuracy in humans and mice. Our results unexpectedly demonstrate that public, as well as private, clones possess predictable high-dimensional immunogenomic features. Our support vector machine model could be trained effectively on large published datasets (3 million clonal sequences) and was sufficiently robust for public clone prediction across individuals and studies prepared with different library preparation and high-throughput sequencing protocols. In summary, we have uncovered the existence of high-dimensional immunogenomic rules that shape immune repertoire diversity in a predictable fashion. Our approach may pave the way for the construction of a comprehensive atlas of public mouse and human immune repertoires with potential applications in rational vaccine design and immunotherapeutics.</p>
    </div>
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
  </div>

  <div id="heuselGANsTrainedTwo2017" class="col-sm-8">
    
      <div class="title">GANs Trained by a Two Time-Scale Update Rule Converge to a Local Nash Equilibrium</div>
      <div class="author">
        
          
            
              
                
                  Heusel, M.,
                
              
            
          
        
          
            
              
                
                  Ramsauer, H.,
                
              
            
          
        
          
            
              
                
                  Unterthiner, T.,
                
              
            
          
        
          
            
              
                
                  Nessler, B.,
                
              
            
          
        
          
            
              
                
                  and Hochreiter, S.
                
              
            
          
        
      </div>

      <div class="periodical">
      
      
        2017
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
      <a href="http://arxiv.org/abs/1706.08500" class="btn btn-sm z-depth-0" role="button" target="_blank">url</a>
    
    
    
      
      <a href="https://arxiv.org/pdf/1706.08500.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Generative Adversarial Networks (GANs) excel at creating realistic images with complex models for which maximum likelihood is infeasible. However, the convergence of GAN training has still not been proved. We propose a two time-scale update rule (TTUR) for training GANs with stochastic gradient descent on arbitrary GAN loss functions. TTUR has an individual learning rate for both the discriminator and the generator. Using the theory of stochastic approximation, we prove that the TTUR converges under mild assumptions to a stationary local Nash equilibrium. The convergence carries over to the popular Adam optimization, for which we prove that it follows the dynamics of a heavy ball with friction and thus prefers flat minima in the objective landscape. For the evaluation of the performance of GANs at image generation, we introduce the "Fr\’echet Inception Distance" (FID) which captures the similarity of generated images to real ones better than the Inception Score. In experiments, TTUR improves learning for DCGANs and Improved Wasserstein GANs (WGAN-GP) outperforming conventional GAN training on CelebA, CIFAR-10, SVHN, LSUN Bedrooms, and the One Billion Word Benchmark.</p>
    </div>
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">NeurIPS</abbr>
    
  
  </div>

  <div id="klambauerSelfNormalizingNeuralNetworks2017" class="col-sm-8">
    
      <div class="title">Self-Normalizing Neural Networks</div>
      <div class="author">
        
          
            
              
                
                  Klambauer, G.,
                
              
            
          
        
          
            
              
                
                  Unterthiner, T.,
                
              
            
          
        
          
            
              
                
                  Mayr, A.,
                
              
            
          
        
          
            
              
                
                  and Hochreiter, S.
                
              
            
          
        
      </div>

      <div class="periodical">
      
      
        2017
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
      <a href="http://arxiv.org/abs/1706.02515" class="btn btn-sm z-depth-0" role="button" target="_blank">url</a>
    
    
    
      
      <a href="https://arxiv.org/pdf/1706.02515.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Deep Learning has revolutionized vision via convolutional neural networks (CNNs) and natural language processing via recurrent neural networks (RNNs). However, success stories of Deep Learning with standard feed-forward neural networks (FNNs) are rare. FNNs that perform well are typically shallow and, therefore cannot exploit many levels of abstract representations. We introduce self-normalizing neural networks (SNNs) to enable high-level abstract representations. While batch normalization requires explicit normalization, neuron activations of SNNs automatically converge towards zero mean and unit variance. The activation function of SNNs are "scaled exponential linear units" (SELUs), which induce self-normalizing properties. Using the Banach fixed-point theorem, we prove that activations close to zero mean and unit variance that are propagated through many network layers will converge towards zero mean and unit variance – even under the presence of noise and perturbations. This convergence property of SNNs allows to (1) train deep networks with many layers, (2) employ strong regularization, and (3) to make learning highly robust. Furthermore, for activations not close to unit variance, we prove an upper and lower bound on the variance, thus, vanishing and exploding gradients are impossible. We compared SNNs on (a) 121 tasks from the UCI machine learning repository, on (b) drug discovery benchmarks, and on (c) astronomy tasks with standard FNNs and other machine learning methods such as random forests and support vector machines. SNNs significantly outperformed all competing FNN methods at 121 UCI tasks, outperformed all competing methods at the Tox21 dataset, and set a new record at an astronomy data set. The winning SNN architectures are often very deep. Implementations are available at: github.com/bioinf-jku/SNNs.</p>
    </div>
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
  </div>

  <div id="povysilPanelcnMOPSCopynumber2017" class="col-sm-8">
    
      <div class="title">Panelcn.MOPS: Copy-Number Detection in Targeted NGS Panel Data for Clinical Diagnostics</div>
      <div class="author">
        
          
            
              
                
                  Povysil, G.,
                
              
            
          
        
          
            
              
                
                  Tzika, A.,
                
              
            
          
        
          
            
              
                
                  Vogt, J.,
                
              
            
          
        
          
            
              
                
                  Haunschmid, V.,
                
              
            
          
        
          
            
              
                
                  Messiaen, L.,
                
              
            
          
        
          
            
              
                
                  Zschocke, J.,
                
              
            
          
        
          
            
              
                
                  Klambauer, G.,
                
              
            
          
        
          
            
              
                
                  Hochreiter, S.,
                
              
            
          
        
          
            
              
                
                  and Wimmer, K.
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em></em>
      
      
        2017
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
      <a href="https://doi.org/10.1002/humu.23237" class="btn btn-sm z-depth-0" role="button" target="_blank">url</a>
    
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Targeted next-generation-sequencing (NGS) panels have largely replaced Sanger sequencing in clinical diagnostics. They allow for the detection of copy-number variations (CNVs) in addition to single-nucleotide variants and small insertions/deletions. However, existing computational CNV detection methods have shortcomings regarding accuracy, quality control (QC), incidental findings, and user-friendliness. We developed panelcn.MOPS, a novel pipeline for detecting CNVs in targeted NGS panel data. Using data from 180 samples, we compared panelcn.MOPS with five state-of-the-art methods. With panelcn.MOPS leading the field, most methods achieved comparably high accuracy. panelcn.MOPS reliably detected CNVs ranging in size from part of a region of interest (ROI), to whole genes, which may comprise all ROIs investigated in a given sample. The latter is enabled by analyzing reads from all ROIs of the panel, but presenting results exclusively for user-selected genes, thus avoiding incidental findings. Additionally, panelcn.MOPS offers QC criteria not only for samples, but also for individual ROIs within a sample, which increases the confidence in called CNVs. panelcn.MOPS is freely available both as R package and standalone software with graphical user interface that is easy to use for clinical geneticists without any programming experience. panelcn.MOPS combines high sensitivity and specificity with user-friendliness rendering it highly suitable for routine clinical diagnostics.</p>
    </div>
    
  </div>
</div>
</li></ol>


</div>

  </div>
  </article>

</div>

    </div>

    <!-- Footer -->

    
<footer class="fixed-bottom">
  <div class="container mt-0">
    &copy; Copyright 2021 Institute for Machine Learning @ JKU.
    Powered by <a href="http://jekyllrb.com/" target="_blank">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank">GitHub Pages</a>.

    
  </div>
</footer>



  </body>

  <!-- jQuery -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script>

  <!-- Bootsrap & MDB scripts -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/2.4.4/umd/popper.min.js" integrity="sha512-eUQ9hGdLjBjY3F41CScH3UX+4JDSI9zXeroz7hJ+RteoCaY+GP/LDoM8AO+Pt+DRFw3nXqsjh9Zsts8hnYv8/A==" crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/js/bootstrap.min.js" integrity="sha512-M5KW3ztuIICmVIhjSqXe01oV2bpe248gOxqmlcYrEzAvws7Pw3z6BK0iGbrwvdrUQUhi3eXgtxp5I8PDo9YfjQ==" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.19.1/js/mdb.min.js" integrity="sha512-Mug9KHKmroQFMLm93zGrjhibM2z2Obg9l6qFG2qKjXEXkMp/VDkI4uju9m4QKPjWSwQ6O2qzZEnJDEeCw0Blcw==" crossorigin="anonymous"></script>

  
<!-- Mansory & imagesLoaded -->
<script defer src="https://unpkg.com/masonry-layout@4/dist/masonry.pkgd.min.js"></script>
<script defer src="https://unpkg.com/imagesloaded@4/imagesloaded.pkgd.min.js"></script>
<script defer src="/assets/js/mansory.js" type="text/javascript"></script>


  


<!-- Load Common JS -->
<script src="/assets/js/common.js"></script>

<!-- Load DarkMode JS -->
<script src="/assets/js/dark_mode.js"></script>


</html>
